I0622 18:35:46.609520 33249 caffe.cpp:185] Using GPUs 1
I0622 18:35:47.068563 33249 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0622 18:35:47.382261 33249 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 200
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 16000
snapshot_prefix: "snapshots/res_ide16"
solver_mode: GPU
device_id: 1
net: "./res_ide16_train_test.prototxt"
stepvalue: 32000
stepvalue: 48000
I0622 18:35:47.382437 33249 solver.cpp:91] Creating training net from net file: ./res_ide16_train_test.prototxt
I0622 18:35:47.383827 33249 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer resnet
I0622 18:35:47.383893 33249 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0622 18:35:47.384232 33249 net.cpp:49] Initializing net from parameters: 
name: "ResNet"
state {
  phase: TRAIN
}
layer {
  name: "resnet"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/home/takeki/caffe/examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/takeki/caffe/examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_1"
  type: "BatchNorm"
  bottom: "conv0"
  top: "bn_a_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_1"
  type: "ReLU"
  bottom: "bn_a_1_1"
  top: "relu_a_1_1"
}
layer {
  name: "conv_a_1_1"
  type: "Convolution"
  bottom: "relu_a_1_1"
  top: "conv_a_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_2"
  type: "BatchNorm"
  bottom: "conv_a_1_1"
  top: "bn_a_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_2"
  type: "ReLU"
  bottom: "bn_a_1_2"
  top: "relu_a_1_2"
}
layer {
  name: "conv_a_1_2"
  type: "Convolution"
  bottom: "relu_a_1_2"
  top: "conv_a_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_a"
  type: "Convolution"
  bottom: "conv0"
  top: "res_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_1"
  type: "Eltwise"
  bottom: "res_a"
  bottom: "conv_a_1_2"
  top: "elt_a_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_a_2_1"
  type: "BatchNorm"
  bottom: "elt_a_1"
  top: "bn_a_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_1"
  type: "ReLU"
  bottom: "bn_a_2_1"
  top: "relu_a_2_1"
}
layer {
  name: "conv_a_2_1"
  type: "Convolution"
  bottom: "relu_a_2_1"
  top: "conv_a_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_2_2"
  type: "BatchNorm"
  bottom: "conv_a_2_1"
  top: "bn_a_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_2"
  type: "ReLU"
  bottom: "bn_a_2_2"
  top: "relu_a_2_2"
}
layer {
  name: "conv_a_2_2"
  type: "Convolution"
  bottom: "relu_a_2_2"
  top: "conv_a_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_2"
  type: "Eltwise"
  bottom: "elt_a_1"
  bottom: "conv_a_2_2"
  top: "elt_a_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_1_1"
  type: "BatchNorm"
  bottom: "elt_a_2"
  top: "bn_d_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_1"
  type: "ReLU"
  bottom: "bn_d_1_1"
  top: "relu_d_1_1"
}
layer {
  name: "conv_d_1_1"
  type: "Convolution"
  bottom: "relu_d_1_1"
  top: "conv_d_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_1_2"
  type: "BatchNorm"
  bottom: "conv_d_1_1"
  top: "bn_d_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_2"
  type: "ReLU"
  bottom: "bn_d_1_2"
  top: "relu_d_1_2"
}
layer {
  name: "conv_d_1_2"
  type: "Convolution"
  bottom: "relu_d_1_2"
  top: "conv_d_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_d"
  type: "Convolution"
  bottom: "elt_a_2"
  top: "res_d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_1"
  type: "Eltwise"
  bottom: "res_d"
  bottom: "conv_d_1_2"
  top: "elt_d_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_2_1"
  type: "BatchNorm"
  bottom: "elt_d_1"
  top: "bn_d_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_1"
  type: "ReLU"
  bottom: "bn_d_2_1"
  top: "relu_d_2_1"
}
layer {
  name: "conv_d_2_1"
  type: "Convolution"
  bottom: "relu_d_2_1"
  top: "conv_d_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_2_2"
  type: "BatchNorm"
  bottom: "conv_d_2_1"
  top: "bn_d_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_2"
  type: "ReLU"
  bottom: "bn_d_2_2"
  top: "relu_d_2_2"
}
layer {
  name: "conv_d_2_2"
  type: "Convolution"
  bottom: "relu_d_2_2"
  top: "conv_d_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_2"
  type: "Eltwise"
  bottom: "elt_d_1"
  bottom: "conv_d_2_2"
  top: "elt_d_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_1_1"
  type: "BatchNorm"
  bottom: "elt_d_2"
  top: "bn_j_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_1"
  type: "ReLU"
  bottom: "bn_j_1_1"
  top: "relu_j_1_1"
}
layer {
  name: "conv_j_1_1"
  type: "Convolution"
  bottom: "relu_j_1_1"
  top: "conv_j_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_1_2"
  type: "BatchNorm"
  bottom: "conv_j_1_1"
  top: "bn_j_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_2"
  type: "ReLU"
  bottom: "bn_j_1_2"
  top: "relu_j_1_2"
}
layer {
  name: "conv_j_1_2"
  type: "Convolution"
  bottom: "relu_j_1_2"
  top: "conv_j_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_j"
  type: "Convolution"
  bottom: "elt_d_2"
  top: "res_j"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_1"
  type: "Eltwise"
  bottom: "res_j"
  bottom: "conv_j_1_2"
  top: "elt_j_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_2_1"
  type: "BatchNorm"
  bottom: "elt_j_1"
  top: "bn_j_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_1"
  type: "ReLU"
  bottom: "bn_j_2_1"
  top: "relu_j_2_1"
}
layer {
  name: "conv_j_2_1"
  type: "Convolution"
  bottom: "relu_j_2_1"
  top: "conv_j_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_2_2"
  type: "BatchNorm"
  bottom: "conv_j_2_1"
  top: "bn_j_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_2"
  type: "ReLU"
  bottom: "bn_j_2_2"
  top: "relu_j_2_2"
}
layer {
  name: "conv_j_2_2"
  type: "Convolution"
  bottom: "relu_j_2_2"
  top: "conv_j_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_2"
  type: "Eltwise"
  bottom: "elt_j_1"
  bottom: "conv_j_2_2"
  top: "elt_j_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_m_1_1"
  type: "BatchNorm"
  bottom: "elt_j_2"
  top: "bn_m_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_m_1_1"
  type: "ReLU"
  bottom: "bn_m_1_1"
  top: "relu_m_1_1"
}
layer {
  name: "gap"
  type: "Pooling"
  bottom: "relu_m_1_1"
  top: "gap"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "gap"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0622 18:35:47.384582 33249 layer_factory.hpp:77] Creating layer resnet
I0622 18:35:47.385119 33249 net.cpp:91] Creating Layer resnet
I0622 18:35:47.385150 33249 net.cpp:399] resnet -> data
I0622 18:35:47.385193 33249 net.cpp:399] resnet -> label
I0622 18:35:47.385221 33249 data_transformer.cpp:25] Loading mean file from: /home/takeki/caffe/examples/cifar10/mean.binaryproto
I0622 18:35:47.386548 33292 db_lmdb.cpp:35] Opened lmdb /home/takeki/caffe/examples/cifar10/cifar10_train_lmdb
I0622 18:35:47.397889 33249 data_layer.cpp:41] output data size: 100,3,32,32
I0622 18:35:47.400517 33249 net.cpp:141] Setting up resnet
I0622 18:35:47.400555 33249 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0622 18:35:47.400564 33249 net.cpp:148] Top shape: 100 (100)
I0622 18:35:47.400569 33249 net.cpp:156] Memory required for data: 1229200
I0622 18:35:47.400578 33249 layer_factory.hpp:77] Creating layer conv0
I0622 18:35:47.400601 33249 net.cpp:91] Creating Layer conv0
I0622 18:35:47.400611 33249 net.cpp:425] conv0 <- data
I0622 18:35:47.400627 33249 net.cpp:399] conv0 -> conv0
I0622 18:35:47.583689 33249 net.cpp:141] Setting up conv0
I0622 18:35:47.583746 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.583753 33249 net.cpp:156] Memory required for data: 7782800
I0622 18:35:47.583777 33249 layer_factory.hpp:77] Creating layer conv0_conv0_0_split
I0622 18:35:47.583814 33249 net.cpp:91] Creating Layer conv0_conv0_0_split
I0622 18:35:47.583825 33249 net.cpp:425] conv0_conv0_0_split <- conv0
I0622 18:35:47.583835 33249 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_0
I0622 18:35:47.583852 33249 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_1
I0622 18:35:47.583899 33249 net.cpp:141] Setting up conv0_conv0_0_split
I0622 18:35:47.583910 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.583917 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.583925 33249 net.cpp:156] Memory required for data: 20890000
I0622 18:35:47.583930 33249 layer_factory.hpp:77] Creating layer bn_a_1_1
I0622 18:35:47.583941 33249 net.cpp:91] Creating Layer bn_a_1_1
I0622 18:35:47.583948 33249 net.cpp:425] bn_a_1_1 <- conv0_conv0_0_split_0
I0622 18:35:47.583956 33249 net.cpp:399] bn_a_1_1 -> bn_a_1_1
I0622 18:35:47.584131 33249 net.cpp:141] Setting up bn_a_1_1
I0622 18:35:47.584142 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.584151 33249 net.cpp:156] Memory required for data: 27443600
I0622 18:35:47.584166 33249 layer_factory.hpp:77] Creating layer relu_a_1_1
I0622 18:35:47.584177 33249 net.cpp:91] Creating Layer relu_a_1_1
I0622 18:35:47.584183 33249 net.cpp:425] relu_a_1_1 <- bn_a_1_1
I0622 18:35:47.584190 33249 net.cpp:399] relu_a_1_1 -> relu_a_1_1
I0622 18:35:47.584483 33249 net.cpp:141] Setting up relu_a_1_1
I0622 18:35:47.584499 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.584506 33249 net.cpp:156] Memory required for data: 33997200
I0622 18:35:47.584512 33249 layer_factory.hpp:77] Creating layer conv_a_1_1
I0622 18:35:47.584528 33249 net.cpp:91] Creating Layer conv_a_1_1
I0622 18:35:47.584535 33249 net.cpp:425] conv_a_1_1 <- relu_a_1_1
I0622 18:35:47.584544 33249 net.cpp:399] conv_a_1_1 -> conv_a_1_1
I0622 18:35:47.586113 33249 net.cpp:141] Setting up conv_a_1_1
I0622 18:35:47.586129 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.586148 33249 net.cpp:156] Memory required for data: 60211600
I0622 18:35:47.586158 33249 layer_factory.hpp:77] Creating layer bn_a_1_2
I0622 18:35:47.586169 33249 net.cpp:91] Creating Layer bn_a_1_2
I0622 18:35:47.586176 33249 net.cpp:425] bn_a_1_2 <- conv_a_1_1
I0622 18:35:47.586184 33249 net.cpp:399] bn_a_1_2 -> bn_a_1_2
I0622 18:35:47.586376 33249 net.cpp:141] Setting up bn_a_1_2
I0622 18:35:47.586410 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.586418 33249 net.cpp:156] Memory required for data: 86426000
I0622 18:35:47.586432 33249 layer_factory.hpp:77] Creating layer relu_a_1_2
I0622 18:35:47.586442 33249 net.cpp:91] Creating Layer relu_a_1_2
I0622 18:35:47.586449 33249 net.cpp:425] relu_a_1_2 <- bn_a_1_2
I0622 18:35:47.586457 33249 net.cpp:399] relu_a_1_2 -> relu_a_1_2
I0622 18:35:47.586756 33249 net.cpp:141] Setting up relu_a_1_2
I0622 18:35:47.586772 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.586777 33249 net.cpp:156] Memory required for data: 112640400
I0622 18:35:47.586783 33249 layer_factory.hpp:77] Creating layer conv_a_1_2
I0622 18:35:47.586796 33249 net.cpp:91] Creating Layer conv_a_1_2
I0622 18:35:47.586817 33249 net.cpp:425] conv_a_1_2 <- relu_a_1_2
I0622 18:35:47.586825 33249 net.cpp:399] conv_a_1_2 -> conv_a_1_2
I0622 18:35:47.589231 33249 net.cpp:141] Setting up conv_a_1_2
I0622 18:35:47.589259 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.589267 33249 net.cpp:156] Memory required for data: 138854800
I0622 18:35:47.589275 33249 layer_factory.hpp:77] Creating layer res_a
I0622 18:35:47.589287 33249 net.cpp:91] Creating Layer res_a
I0622 18:35:47.589293 33249 net.cpp:425] res_a <- conv0_conv0_0_split_1
I0622 18:35:47.589301 33249 net.cpp:399] res_a -> res_a
I0622 18:35:47.590214 33249 net.cpp:141] Setting up res_a
I0622 18:35:47.590229 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.590248 33249 net.cpp:156] Memory required for data: 165069200
I0622 18:35:47.590256 33249 layer_factory.hpp:77] Creating layer elt_a_1
I0622 18:35:47.590266 33249 net.cpp:91] Creating Layer elt_a_1
I0622 18:35:47.590271 33249 net.cpp:425] elt_a_1 <- res_a
I0622 18:35:47.590277 33249 net.cpp:425] elt_a_1 <- conv_a_1_2
I0622 18:35:47.590284 33249 net.cpp:399] elt_a_1 -> elt_a_1
I0622 18:35:47.590330 33249 net.cpp:141] Setting up elt_a_1
I0622 18:35:47.590342 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.590347 33249 net.cpp:156] Memory required for data: 191283600
I0622 18:35:47.590353 33249 layer_factory.hpp:77] Creating layer elt_a_1_elt_a_1_0_split
I0622 18:35:47.590359 33249 net.cpp:91] Creating Layer elt_a_1_elt_a_1_0_split
I0622 18:35:47.590365 33249 net.cpp:425] elt_a_1_elt_a_1_0_split <- elt_a_1
I0622 18:35:47.590373 33249 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_0
I0622 18:35:47.590383 33249 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_1
I0622 18:35:47.590418 33249 net.cpp:141] Setting up elt_a_1_elt_a_1_0_split
I0622 18:35:47.590428 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.590435 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.590440 33249 net.cpp:156] Memory required for data: 243712400
I0622 18:35:47.590445 33249 layer_factory.hpp:77] Creating layer bn_a_2_1
I0622 18:35:47.590453 33249 net.cpp:91] Creating Layer bn_a_2_1
I0622 18:35:47.590461 33249 net.cpp:425] bn_a_2_1 <- elt_a_1_elt_a_1_0_split_0
I0622 18:35:47.590467 33249 net.cpp:399] bn_a_2_1 -> bn_a_2_1
I0622 18:35:47.590653 33249 net.cpp:141] Setting up bn_a_2_1
I0622 18:35:47.590665 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.590672 33249 net.cpp:156] Memory required for data: 269926800
I0622 18:35:47.590692 33249 layer_factory.hpp:77] Creating layer relu_a_2_1
I0622 18:35:47.590703 33249 net.cpp:91] Creating Layer relu_a_2_1
I0622 18:35:47.590708 33249 net.cpp:425] relu_a_2_1 <- bn_a_2_1
I0622 18:35:47.590715 33249 net.cpp:399] relu_a_2_1 -> relu_a_2_1
I0622 18:35:47.590893 33249 net.cpp:141] Setting up relu_a_2_1
I0622 18:35:47.590909 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.590914 33249 net.cpp:156] Memory required for data: 296141200
I0622 18:35:47.590920 33249 layer_factory.hpp:77] Creating layer conv_a_2_1
I0622 18:35:47.590932 33249 net.cpp:91] Creating Layer conv_a_2_1
I0622 18:35:47.590939 33249 net.cpp:425] conv_a_2_1 <- relu_a_2_1
I0622 18:35:47.590947 33249 net.cpp:399] conv_a_2_1 -> conv_a_2_1
I0622 18:35:47.592892 33249 net.cpp:141] Setting up conv_a_2_1
I0622 18:35:47.592908 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.592928 33249 net.cpp:156] Memory required for data: 322355600
I0622 18:35:47.592937 33249 layer_factory.hpp:77] Creating layer bn_a_2_2
I0622 18:35:47.592948 33249 net.cpp:91] Creating Layer bn_a_2_2
I0622 18:35:47.592955 33249 net.cpp:425] bn_a_2_2 <- conv_a_2_1
I0622 18:35:47.592963 33249 net.cpp:399] bn_a_2_2 -> bn_a_2_2
I0622 18:35:47.593158 33249 net.cpp:141] Setting up bn_a_2_2
I0622 18:35:47.593171 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.593178 33249 net.cpp:156] Memory required for data: 348570000
I0622 18:35:47.593188 33249 layer_factory.hpp:77] Creating layer relu_a_2_2
I0622 18:35:47.593199 33249 net.cpp:91] Creating Layer relu_a_2_2
I0622 18:35:47.593205 33249 net.cpp:425] relu_a_2_2 <- bn_a_2_2
I0622 18:35:47.593214 33249 net.cpp:399] relu_a_2_2 -> relu_a_2_2
I0622 18:35:47.593391 33249 net.cpp:141] Setting up relu_a_2_2
I0622 18:35:47.593405 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.593411 33249 net.cpp:156] Memory required for data: 374784400
I0622 18:35:47.593417 33249 layer_factory.hpp:77] Creating layer conv_a_2_2
I0622 18:35:47.593430 33249 net.cpp:91] Creating Layer conv_a_2_2
I0622 18:35:47.593436 33249 net.cpp:425] conv_a_2_2 <- relu_a_2_2
I0622 18:35:47.593446 33249 net.cpp:399] conv_a_2_2 -> conv_a_2_2
I0622 18:35:47.595573 33249 net.cpp:141] Setting up conv_a_2_2
I0622 18:35:47.595590 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.595609 33249 net.cpp:156] Memory required for data: 400998800
I0622 18:35:47.595619 33249 layer_factory.hpp:77] Creating layer elt_a_2
I0622 18:35:47.595633 33249 net.cpp:91] Creating Layer elt_a_2
I0622 18:35:47.595639 33249 net.cpp:425] elt_a_2 <- elt_a_1_elt_a_1_0_split_1
I0622 18:35:47.595646 33249 net.cpp:425] elt_a_2 <- conv_a_2_2
I0622 18:35:47.595654 33249 net.cpp:399] elt_a_2 -> elt_a_2
I0622 18:35:47.595698 33249 net.cpp:141] Setting up elt_a_2
I0622 18:35:47.595710 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.595715 33249 net.cpp:156] Memory required for data: 427213200
I0622 18:35:47.595721 33249 layer_factory.hpp:77] Creating layer elt_a_2_elt_a_2_0_split
I0622 18:35:47.595727 33249 net.cpp:91] Creating Layer elt_a_2_elt_a_2_0_split
I0622 18:35:47.595733 33249 net.cpp:425] elt_a_2_elt_a_2_0_split <- elt_a_2
I0622 18:35:47.595742 33249 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_0
I0622 18:35:47.595752 33249 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_1
I0622 18:35:47.595793 33249 net.cpp:141] Setting up elt_a_2_elt_a_2_0_split
I0622 18:35:47.595806 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.595814 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.595819 33249 net.cpp:156] Memory required for data: 479642000
I0622 18:35:47.595824 33249 layer_factory.hpp:77] Creating layer bn_d_1_1
I0622 18:35:47.595832 33249 net.cpp:91] Creating Layer bn_d_1_1
I0622 18:35:47.595839 33249 net.cpp:425] bn_d_1_1 <- elt_a_2_elt_a_2_0_split_0
I0622 18:35:47.595849 33249 net.cpp:399] bn_d_1_1 -> bn_d_1_1
I0622 18:35:47.596041 33249 net.cpp:141] Setting up bn_d_1_1
I0622 18:35:47.596053 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.596060 33249 net.cpp:156] Memory required for data: 505856400
I0622 18:35:47.596071 33249 layer_factory.hpp:77] Creating layer relu_d_1_1
I0622 18:35:47.596082 33249 net.cpp:91] Creating Layer relu_d_1_1
I0622 18:35:47.596089 33249 net.cpp:425] relu_d_1_1 <- bn_d_1_1
I0622 18:35:47.596096 33249 net.cpp:399] relu_d_1_1 -> relu_d_1_1
I0622 18:35:47.596403 33249 net.cpp:141] Setting up relu_d_1_1
I0622 18:35:47.596418 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.596426 33249 net.cpp:156] Memory required for data: 532070800
I0622 18:35:47.596431 33249 layer_factory.hpp:77] Creating layer conv_d_1_1
I0622 18:35:47.596446 33249 net.cpp:91] Creating Layer conv_d_1_1
I0622 18:35:47.596467 33249 net.cpp:425] conv_d_1_1 <- relu_d_1_1
I0622 18:35:47.596479 33249 net.cpp:399] conv_d_1_1 -> conv_d_1_1
I0622 18:35:47.600131 33249 net.cpp:141] Setting up conv_d_1_1
I0622 18:35:47.600147 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.600172 33249 net.cpp:156] Memory required for data: 545178000
I0622 18:35:47.600181 33249 layer_factory.hpp:77] Creating layer bn_d_1_2
I0622 18:35:47.600194 33249 net.cpp:91] Creating Layer bn_d_1_2
I0622 18:35:47.600201 33249 net.cpp:425] bn_d_1_2 <- conv_d_1_1
I0622 18:35:47.600209 33249 net.cpp:399] bn_d_1_2 -> bn_d_1_2
I0622 18:35:47.600414 33249 net.cpp:141] Setting up bn_d_1_2
I0622 18:35:47.600427 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.600432 33249 net.cpp:156] Memory required for data: 558285200
I0622 18:35:47.600443 33249 layer_factory.hpp:77] Creating layer relu_d_1_2
I0622 18:35:47.600455 33249 net.cpp:91] Creating Layer relu_d_1_2
I0622 18:35:47.600462 33249 net.cpp:425] relu_d_1_2 <- bn_d_1_2
I0622 18:35:47.600469 33249 net.cpp:399] relu_d_1_2 -> relu_d_1_2
I0622 18:35:47.600667 33249 net.cpp:141] Setting up relu_d_1_2
I0622 18:35:47.600682 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.600688 33249 net.cpp:156] Memory required for data: 571392400
I0622 18:35:47.600693 33249 layer_factory.hpp:77] Creating layer conv_d_1_2
I0622 18:35:47.600708 33249 net.cpp:91] Creating Layer conv_d_1_2
I0622 18:35:47.600715 33249 net.cpp:425] conv_d_1_2 <- relu_d_1_2
I0622 18:35:47.600725 33249 net.cpp:399] conv_d_1_2 -> conv_d_1_2
I0622 18:35:47.606165 33249 net.cpp:141] Setting up conv_d_1_2
I0622 18:35:47.606186 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.606192 33249 net.cpp:156] Memory required for data: 584499600
I0622 18:35:47.606212 33249 layer_factory.hpp:77] Creating layer res_d
I0622 18:35:47.606225 33249 net.cpp:91] Creating Layer res_d
I0622 18:35:47.606233 33249 net.cpp:425] res_d <- elt_a_2_elt_a_2_0_split_1
I0622 18:35:47.606245 33249 net.cpp:399] res_d -> res_d
I0622 18:35:47.607502 33249 net.cpp:141] Setting up res_d
I0622 18:35:47.607519 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.607525 33249 net.cpp:156] Memory required for data: 597606800
I0622 18:35:47.607535 33249 layer_factory.hpp:77] Creating layer elt_d_1
I0622 18:35:47.607547 33249 net.cpp:91] Creating Layer elt_d_1
I0622 18:35:47.607553 33249 net.cpp:425] elt_d_1 <- res_d
I0622 18:35:47.607560 33249 net.cpp:425] elt_d_1 <- conv_d_1_2
I0622 18:35:47.607568 33249 net.cpp:399] elt_d_1 -> elt_d_1
I0622 18:35:47.607599 33249 net.cpp:141] Setting up elt_d_1
I0622 18:35:47.607609 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.607614 33249 net.cpp:156] Memory required for data: 610714000
I0622 18:35:47.607620 33249 layer_factory.hpp:77] Creating layer elt_d_1_elt_d_1_0_split
I0622 18:35:47.607630 33249 net.cpp:91] Creating Layer elt_d_1_elt_d_1_0_split
I0622 18:35:47.607636 33249 net.cpp:425] elt_d_1_elt_d_1_0_split <- elt_d_1
I0622 18:35:47.607643 33249 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_0
I0622 18:35:47.607657 33249 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_1
I0622 18:35:47.607699 33249 net.cpp:141] Setting up elt_d_1_elt_d_1_0_split
I0622 18:35:47.607713 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.607722 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.607727 33249 net.cpp:156] Memory required for data: 636928400
I0622 18:35:47.607731 33249 layer_factory.hpp:77] Creating layer bn_d_2_1
I0622 18:35:47.607739 33249 net.cpp:91] Creating Layer bn_d_2_1
I0622 18:35:47.607744 33249 net.cpp:425] bn_d_2_1 <- elt_d_1_elt_d_1_0_split_0
I0622 18:35:47.607754 33249 net.cpp:399] bn_d_2_1 -> bn_d_2_1
I0622 18:35:47.607942 33249 net.cpp:141] Setting up bn_d_2_1
I0622 18:35:47.607954 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.607960 33249 net.cpp:156] Memory required for data: 650035600
I0622 18:35:47.607970 33249 layer_factory.hpp:77] Creating layer relu_d_2_1
I0622 18:35:47.607996 33249 net.cpp:91] Creating Layer relu_d_2_1
I0622 18:35:47.608006 33249 net.cpp:425] relu_d_2_1 <- bn_d_2_1
I0622 18:35:47.608016 33249 net.cpp:399] relu_d_2_1 -> relu_d_2_1
I0622 18:35:47.608217 33249 net.cpp:141] Setting up relu_d_2_1
I0622 18:35:47.608230 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.608235 33249 net.cpp:156] Memory required for data: 663142800
I0622 18:35:47.608242 33249 layer_factory.hpp:77] Creating layer conv_d_2_1
I0622 18:35:47.608258 33249 net.cpp:91] Creating Layer conv_d_2_1
I0622 18:35:47.608264 33249 net.cpp:425] conv_d_2_1 <- relu_d_2_1
I0622 18:35:47.608273 33249 net.cpp:399] conv_d_2_1 -> conv_d_2_1
I0622 18:35:47.614197 33249 net.cpp:141] Setting up conv_d_2_1
I0622 18:35:47.614214 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.614220 33249 net.cpp:156] Memory required for data: 676250000
I0622 18:35:47.614229 33249 layer_factory.hpp:77] Creating layer bn_d_2_2
I0622 18:35:47.614248 33249 net.cpp:91] Creating Layer bn_d_2_2
I0622 18:35:47.614255 33249 net.cpp:425] bn_d_2_2 <- conv_d_2_1
I0622 18:35:47.614266 33249 net.cpp:399] bn_d_2_2 -> bn_d_2_2
I0622 18:35:47.614464 33249 net.cpp:141] Setting up bn_d_2_2
I0622 18:35:47.614476 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.614481 33249 net.cpp:156] Memory required for data: 689357200
I0622 18:35:47.614491 33249 layer_factory.hpp:77] Creating layer relu_d_2_2
I0622 18:35:47.614507 33249 net.cpp:91] Creating Layer relu_d_2_2
I0622 18:35:47.614514 33249 net.cpp:425] relu_d_2_2 <- bn_d_2_2
I0622 18:35:47.614522 33249 net.cpp:399] relu_d_2_2 -> relu_d_2_2
I0622 18:35:47.614842 33249 net.cpp:141] Setting up relu_d_2_2
I0622 18:35:47.614858 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.614864 33249 net.cpp:156] Memory required for data: 702464400
I0622 18:35:47.614871 33249 layer_factory.hpp:77] Creating layer conv_d_2_2
I0622 18:35:47.614886 33249 net.cpp:91] Creating Layer conv_d_2_2
I0622 18:35:47.614893 33249 net.cpp:425] conv_d_2_2 <- relu_d_2_2
I0622 18:35:47.614904 33249 net.cpp:399] conv_d_2_2 -> conv_d_2_2
I0622 18:35:47.620734 33249 net.cpp:141] Setting up conv_d_2_2
I0622 18:35:47.620753 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.620759 33249 net.cpp:156] Memory required for data: 715571600
I0622 18:35:47.620767 33249 layer_factory.hpp:77] Creating layer elt_d_2
I0622 18:35:47.620776 33249 net.cpp:91] Creating Layer elt_d_2
I0622 18:35:47.620782 33249 net.cpp:425] elt_d_2 <- elt_d_1_elt_d_1_0_split_1
I0622 18:35:47.620789 33249 net.cpp:425] elt_d_2 <- conv_d_2_2
I0622 18:35:47.620798 33249 net.cpp:399] elt_d_2 -> elt_d_2
I0622 18:35:47.620826 33249 net.cpp:141] Setting up elt_d_2
I0622 18:35:47.620838 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.620843 33249 net.cpp:156] Memory required for data: 728678800
I0622 18:35:47.620848 33249 layer_factory.hpp:77] Creating layer elt_d_2_elt_d_2_0_split
I0622 18:35:47.620858 33249 net.cpp:91] Creating Layer elt_d_2_elt_d_2_0_split
I0622 18:35:47.620867 33249 net.cpp:425] elt_d_2_elt_d_2_0_split <- elt_d_2
I0622 18:35:47.620873 33249 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_0
I0622 18:35:47.620882 33249 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_1
I0622 18:35:47.620928 33249 net.cpp:141] Setting up elt_d_2_elt_d_2_0_split
I0622 18:35:47.620939 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.620945 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.620950 33249 net.cpp:156] Memory required for data: 754893200
I0622 18:35:47.620955 33249 layer_factory.hpp:77] Creating layer bn_j_1_1
I0622 18:35:47.620966 33249 net.cpp:91] Creating Layer bn_j_1_1
I0622 18:35:47.620972 33249 net.cpp:425] bn_j_1_1 <- elt_d_2_elt_d_2_0_split_0
I0622 18:35:47.620980 33249 net.cpp:399] bn_j_1_1 -> bn_j_1_1
I0622 18:35:47.621170 33249 net.cpp:141] Setting up bn_j_1_1
I0622 18:35:47.621183 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.621207 33249 net.cpp:156] Memory required for data: 768000400
I0622 18:35:47.621219 33249 layer_factory.hpp:77] Creating layer relu_j_1_1
I0622 18:35:47.621228 33249 net.cpp:91] Creating Layer relu_j_1_1
I0622 18:35:47.621235 33249 net.cpp:425] relu_j_1_1 <- bn_j_1_1
I0622 18:35:47.621243 33249 net.cpp:399] relu_j_1_1 -> relu_j_1_1
I0622 18:35:47.621557 33249 net.cpp:141] Setting up relu_j_1_1
I0622 18:35:47.621572 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.621578 33249 net.cpp:156] Memory required for data: 781107600
I0622 18:35:47.621583 33249 layer_factory.hpp:77] Creating layer conv_j_1_1
I0622 18:35:47.621600 33249 net.cpp:91] Creating Layer conv_j_1_1
I0622 18:35:47.621608 33249 net.cpp:425] conv_j_1_1 <- relu_j_1_1
I0622 18:35:47.621618 33249 net.cpp:399] conv_j_1_1 -> conv_j_1_1
I0622 18:35:47.631753 33249 net.cpp:141] Setting up conv_j_1_1
I0622 18:35:47.631784 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.631791 33249 net.cpp:156] Memory required for data: 787661200
I0622 18:35:47.631800 33249 layer_factory.hpp:77] Creating layer bn_j_1_2
I0622 18:35:47.631809 33249 net.cpp:91] Creating Layer bn_j_1_2
I0622 18:35:47.631815 33249 net.cpp:425] bn_j_1_2 <- conv_j_1_1
I0622 18:35:47.631825 33249 net.cpp:399] bn_j_1_2 -> bn_j_1_2
I0622 18:35:47.632048 33249 net.cpp:141] Setting up bn_j_1_2
I0622 18:35:47.632061 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.632067 33249 net.cpp:156] Memory required for data: 794214800
I0622 18:35:47.632077 33249 layer_factory.hpp:77] Creating layer relu_j_1_2
I0622 18:35:47.632088 33249 net.cpp:91] Creating Layer relu_j_1_2
I0622 18:35:47.632098 33249 net.cpp:425] relu_j_1_2 <- bn_j_1_2
I0622 18:35:47.632105 33249 net.cpp:399] relu_j_1_2 -> relu_j_1_2
I0622 18:35:47.632302 33249 net.cpp:141] Setting up relu_j_1_2
I0622 18:35:47.632315 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.632320 33249 net.cpp:156] Memory required for data: 800768400
I0622 18:35:47.632326 33249 layer_factory.hpp:77] Creating layer conv_j_1_2
I0622 18:35:47.632340 33249 net.cpp:91] Creating Layer conv_j_1_2
I0622 18:35:47.632349 33249 net.cpp:425] conv_j_1_2 <- relu_j_1_2
I0622 18:35:47.632359 33249 net.cpp:399] conv_j_1_2 -> conv_j_1_2
I0622 18:35:47.651433 33249 net.cpp:141] Setting up conv_j_1_2
I0622 18:35:47.651454 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.651460 33249 net.cpp:156] Memory required for data: 807322000
I0622 18:35:47.651482 33249 layer_factory.hpp:77] Creating layer res_j
I0622 18:35:47.651504 33249 net.cpp:91] Creating Layer res_j
I0622 18:35:47.651511 33249 net.cpp:425] res_j <- elt_d_2_elt_d_2_0_split_1
I0622 18:35:47.651522 33249 net.cpp:399] res_j -> res_j
I0622 18:35:47.653537 33249 net.cpp:141] Setting up res_j
I0622 18:35:47.653554 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.653560 33249 net.cpp:156] Memory required for data: 813875600
I0622 18:35:47.653584 33249 layer_factory.hpp:77] Creating layer elt_j_1
I0622 18:35:47.653596 33249 net.cpp:91] Creating Layer elt_j_1
I0622 18:35:47.653604 33249 net.cpp:425] elt_j_1 <- res_j
I0622 18:35:47.653611 33249 net.cpp:425] elt_j_1 <- conv_j_1_2
I0622 18:35:47.653619 33249 net.cpp:399] elt_j_1 -> elt_j_1
I0622 18:35:47.653657 33249 net.cpp:141] Setting up elt_j_1
I0622 18:35:47.653669 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.653676 33249 net.cpp:156] Memory required for data: 820429200
I0622 18:35:47.653681 33249 layer_factory.hpp:77] Creating layer elt_j_1_elt_j_1_0_split
I0622 18:35:47.653688 33249 net.cpp:91] Creating Layer elt_j_1_elt_j_1_0_split
I0622 18:35:47.653693 33249 net.cpp:425] elt_j_1_elt_j_1_0_split <- elt_j_1
I0622 18:35:47.653703 33249 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_0
I0622 18:35:47.653713 33249 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_1
I0622 18:35:47.653758 33249 net.cpp:141] Setting up elt_j_1_elt_j_1_0_split
I0622 18:35:47.653769 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.653791 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.653797 33249 net.cpp:156] Memory required for data: 833536400
I0622 18:35:47.653802 33249 layer_factory.hpp:77] Creating layer bn_j_2_1
I0622 18:35:47.653815 33249 net.cpp:91] Creating Layer bn_j_2_1
I0622 18:35:47.653821 33249 net.cpp:425] bn_j_2_1 <- elt_j_1_elt_j_1_0_split_0
I0622 18:35:47.653832 33249 net.cpp:399] bn_j_2_1 -> bn_j_2_1
I0622 18:35:47.654036 33249 net.cpp:141] Setting up bn_j_2_1
I0622 18:35:47.654048 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.654053 33249 net.cpp:156] Memory required for data: 840090000
I0622 18:35:47.654063 33249 layer_factory.hpp:77] Creating layer relu_j_2_1
I0622 18:35:47.654072 33249 net.cpp:91] Creating Layer relu_j_2_1
I0622 18:35:47.654079 33249 net.cpp:425] relu_j_2_1 <- bn_j_2_1
I0622 18:35:47.654088 33249 net.cpp:399] relu_j_2_1 -> relu_j_2_1
I0622 18:35:47.654287 33249 net.cpp:141] Setting up relu_j_2_1
I0622 18:35:47.654301 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.654306 33249 net.cpp:156] Memory required for data: 846643600
I0622 18:35:47.654312 33249 layer_factory.hpp:77] Creating layer conv_j_2_1
I0622 18:35:47.654328 33249 net.cpp:91] Creating Layer conv_j_2_1
I0622 18:35:47.654336 33249 net.cpp:425] conv_j_2_1 <- relu_j_2_1
I0622 18:35:47.654347 33249 net.cpp:399] conv_j_2_1 -> conv_j_2_1
I0622 18:35:47.673398 33249 net.cpp:141] Setting up conv_j_2_1
I0622 18:35:47.673426 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.673434 33249 net.cpp:156] Memory required for data: 853197200
I0622 18:35:47.673442 33249 layer_factory.hpp:77] Creating layer bn_j_2_2
I0622 18:35:47.673454 33249 net.cpp:91] Creating Layer bn_j_2_2
I0622 18:35:47.673460 33249 net.cpp:425] bn_j_2_2 <- conv_j_2_1
I0622 18:35:47.673468 33249 net.cpp:399] bn_j_2_2 -> bn_j_2_2
I0622 18:35:47.673696 33249 net.cpp:141] Setting up bn_j_2_2
I0622 18:35:47.673709 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.673714 33249 net.cpp:156] Memory required for data: 859750800
I0622 18:35:47.673739 33249 layer_factory.hpp:77] Creating layer relu_j_2_2
I0622 18:35:47.673753 33249 net.cpp:91] Creating Layer relu_j_2_2
I0622 18:35:47.673760 33249 net.cpp:425] relu_j_2_2 <- bn_j_2_2
I0622 18:35:47.673768 33249 net.cpp:399] relu_j_2_2 -> relu_j_2_2
I0622 18:35:47.674088 33249 net.cpp:141] Setting up relu_j_2_2
I0622 18:35:47.674103 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.674108 33249 net.cpp:156] Memory required for data: 866304400
I0622 18:35:47.674114 33249 layer_factory.hpp:77] Creating layer conv_j_2_2
I0622 18:35:47.674129 33249 net.cpp:91] Creating Layer conv_j_2_2
I0622 18:35:47.674136 33249 net.cpp:425] conv_j_2_2 <- relu_j_2_2
I0622 18:35:47.674147 33249 net.cpp:399] conv_j_2_2 -> conv_j_2_2
I0622 18:35:47.693127 33249 net.cpp:141] Setting up conv_j_2_2
I0622 18:35:47.693147 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.693152 33249 net.cpp:156] Memory required for data: 872858000
I0622 18:35:47.693161 33249 layer_factory.hpp:77] Creating layer elt_j_2
I0622 18:35:47.693169 33249 net.cpp:91] Creating Layer elt_j_2
I0622 18:35:47.693176 33249 net.cpp:425] elt_j_2 <- elt_j_1_elt_j_1_0_split_1
I0622 18:35:47.693197 33249 net.cpp:425] elt_j_2 <- conv_j_2_2
I0622 18:35:47.693204 33249 net.cpp:399] elt_j_2 -> elt_j_2
I0622 18:35:47.693235 33249 net.cpp:141] Setting up elt_j_2
I0622 18:35:47.693248 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.693253 33249 net.cpp:156] Memory required for data: 879411600
I0622 18:35:47.693258 33249 layer_factory.hpp:77] Creating layer bn_m_1_1
I0622 18:35:47.693267 33249 net.cpp:91] Creating Layer bn_m_1_1
I0622 18:35:47.693274 33249 net.cpp:425] bn_m_1_1 <- elt_j_2
I0622 18:35:47.693284 33249 net.cpp:399] bn_m_1_1 -> bn_m_1_1
I0622 18:35:47.693485 33249 net.cpp:141] Setting up bn_m_1_1
I0622 18:35:47.693496 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.693501 33249 net.cpp:156] Memory required for data: 885965200
I0622 18:35:47.693542 33249 layer_factory.hpp:77] Creating layer relu_m_1_1
I0622 18:35:47.693552 33249 net.cpp:91] Creating Layer relu_m_1_1
I0622 18:35:47.693557 33249 net.cpp:425] relu_m_1_1 <- bn_m_1_1
I0622 18:35:47.693564 33249 net.cpp:399] relu_m_1_1 -> relu_m_1_1
I0622 18:35:47.693765 33249 net.cpp:141] Setting up relu_m_1_1
I0622 18:35:47.693779 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.693784 33249 net.cpp:156] Memory required for data: 892518800
I0622 18:35:47.693789 33249 layer_factory.hpp:77] Creating layer gap
I0622 18:35:47.693799 33249 net.cpp:91] Creating Layer gap
I0622 18:35:47.693806 33249 net.cpp:425] gap <- relu_m_1_1
I0622 18:35:47.693815 33249 net.cpp:399] gap -> gap
I0622 18:35:47.694149 33249 net.cpp:141] Setting up gap
I0622 18:35:47.694164 33249 net.cpp:148] Top shape: 100 256 1 1 (25600)
I0622 18:35:47.694169 33249 net.cpp:156] Memory required for data: 892621200
I0622 18:35:47.694175 33249 layer_factory.hpp:77] Creating layer ip1
I0622 18:35:47.694186 33249 net.cpp:91] Creating Layer ip1
I0622 18:35:47.694193 33249 net.cpp:425] ip1 <- gap
I0622 18:35:47.694201 33249 net.cpp:399] ip1 -> ip1
I0622 18:35:47.694399 33249 net.cpp:141] Setting up ip1
I0622 18:35:47.694411 33249 net.cpp:148] Top shape: 100 10 (1000)
I0622 18:35:47.694416 33249 net.cpp:156] Memory required for data: 892625200
I0622 18:35:47.694424 33249 layer_factory.hpp:77] Creating layer loss
I0622 18:35:47.694432 33249 net.cpp:91] Creating Layer loss
I0622 18:35:47.694438 33249 net.cpp:425] loss <- ip1
I0622 18:35:47.694444 33249 net.cpp:425] loss <- label
I0622 18:35:47.694455 33249 net.cpp:399] loss -> loss
I0622 18:35:47.694489 33249 layer_factory.hpp:77] Creating layer loss
I0622 18:35:47.694808 33249 net.cpp:141] Setting up loss
I0622 18:35:47.694823 33249 net.cpp:148] Top shape: (1)
I0622 18:35:47.694828 33249 net.cpp:151]     with loss weight 1
I0622 18:35:47.694854 33249 net.cpp:156] Memory required for data: 892625204
I0622 18:35:47.694859 33249 net.cpp:217] loss needs backward computation.
I0622 18:35:47.694864 33249 net.cpp:217] ip1 needs backward computation.
I0622 18:35:47.694869 33249 net.cpp:217] gap needs backward computation.
I0622 18:35:47.694888 33249 net.cpp:217] relu_m_1_1 needs backward computation.
I0622 18:35:47.694893 33249 net.cpp:217] bn_m_1_1 needs backward computation.
I0622 18:35:47.694897 33249 net.cpp:217] elt_j_2 needs backward computation.
I0622 18:35:47.694903 33249 net.cpp:217] conv_j_2_2 needs backward computation.
I0622 18:35:47.694908 33249 net.cpp:217] relu_j_2_2 needs backward computation.
I0622 18:35:47.694912 33249 net.cpp:217] bn_j_2_2 needs backward computation.
I0622 18:35:47.694917 33249 net.cpp:217] conv_j_2_1 needs backward computation.
I0622 18:35:47.694922 33249 net.cpp:217] relu_j_2_1 needs backward computation.
I0622 18:35:47.694927 33249 net.cpp:217] bn_j_2_1 needs backward computation.
I0622 18:35:47.694932 33249 net.cpp:217] elt_j_1_elt_j_1_0_split needs backward computation.
I0622 18:35:47.694936 33249 net.cpp:217] elt_j_1 needs backward computation.
I0622 18:35:47.694941 33249 net.cpp:217] res_j needs backward computation.
I0622 18:35:47.694947 33249 net.cpp:217] conv_j_1_2 needs backward computation.
I0622 18:35:47.694952 33249 net.cpp:217] relu_j_1_2 needs backward computation.
I0622 18:35:47.694957 33249 net.cpp:217] bn_j_1_2 needs backward computation.
I0622 18:35:47.694962 33249 net.cpp:217] conv_j_1_1 needs backward computation.
I0622 18:35:47.694967 33249 net.cpp:217] relu_j_1_1 needs backward computation.
I0622 18:35:47.694970 33249 net.cpp:217] bn_j_1_1 needs backward computation.
I0622 18:35:47.694975 33249 net.cpp:217] elt_d_2_elt_d_2_0_split needs backward computation.
I0622 18:35:47.694983 33249 net.cpp:217] elt_d_2 needs backward computation.
I0622 18:35:47.694989 33249 net.cpp:217] conv_d_2_2 needs backward computation.
I0622 18:35:47.695008 33249 net.cpp:217] relu_d_2_2 needs backward computation.
I0622 18:35:47.695013 33249 net.cpp:217] bn_d_2_2 needs backward computation.
I0622 18:35:47.695017 33249 net.cpp:217] conv_d_2_1 needs backward computation.
I0622 18:35:47.695036 33249 net.cpp:217] relu_d_2_1 needs backward computation.
I0622 18:35:47.695042 33249 net.cpp:217] bn_d_2_1 needs backward computation.
I0622 18:35:47.695047 33249 net.cpp:217] elt_d_1_elt_d_1_0_split needs backward computation.
I0622 18:35:47.695052 33249 net.cpp:217] elt_d_1 needs backward computation.
I0622 18:35:47.695058 33249 net.cpp:217] res_d needs backward computation.
I0622 18:35:47.695063 33249 net.cpp:217] conv_d_1_2 needs backward computation.
I0622 18:35:47.695067 33249 net.cpp:217] relu_d_1_2 needs backward computation.
I0622 18:35:47.695072 33249 net.cpp:217] bn_d_1_2 needs backward computation.
I0622 18:35:47.695077 33249 net.cpp:217] conv_d_1_1 needs backward computation.
I0622 18:35:47.695082 33249 net.cpp:217] relu_d_1_1 needs backward computation.
I0622 18:35:47.695086 33249 net.cpp:217] bn_d_1_1 needs backward computation.
I0622 18:35:47.695091 33249 net.cpp:217] elt_a_2_elt_a_2_0_split needs backward computation.
I0622 18:35:47.695096 33249 net.cpp:217] elt_a_2 needs backward computation.
I0622 18:35:47.695101 33249 net.cpp:217] conv_a_2_2 needs backward computation.
I0622 18:35:47.695106 33249 net.cpp:217] relu_a_2_2 needs backward computation.
I0622 18:35:47.695111 33249 net.cpp:217] bn_a_2_2 needs backward computation.
I0622 18:35:47.695116 33249 net.cpp:217] conv_a_2_1 needs backward computation.
I0622 18:35:47.695121 33249 net.cpp:217] relu_a_2_1 needs backward computation.
I0622 18:35:47.695125 33249 net.cpp:217] bn_a_2_1 needs backward computation.
I0622 18:35:47.695129 33249 net.cpp:217] elt_a_1_elt_a_1_0_split needs backward computation.
I0622 18:35:47.695134 33249 net.cpp:217] elt_a_1 needs backward computation.
I0622 18:35:47.695139 33249 net.cpp:217] res_a needs backward computation.
I0622 18:35:47.695144 33249 net.cpp:217] conv_a_1_2 needs backward computation.
I0622 18:35:47.695149 33249 net.cpp:217] relu_a_1_2 needs backward computation.
I0622 18:35:47.695154 33249 net.cpp:217] bn_a_1_2 needs backward computation.
I0622 18:35:47.695159 33249 net.cpp:217] conv_a_1_1 needs backward computation.
I0622 18:35:47.695168 33249 net.cpp:217] relu_a_1_1 needs backward computation.
I0622 18:35:47.695173 33249 net.cpp:217] bn_a_1_1 needs backward computation.
I0622 18:35:47.695178 33249 net.cpp:217] conv0_conv0_0_split needs backward computation.
I0622 18:35:47.695183 33249 net.cpp:217] conv0 needs backward computation.
I0622 18:35:47.695188 33249 net.cpp:219] resnet does not need backward computation.
I0622 18:35:47.695193 33249 net.cpp:261] This network produces output loss
I0622 18:35:47.695248 33249 net.cpp:274] Network initialization done.
I0622 18:35:47.696737 33249 solver.cpp:181] Creating test net (#0) specified by net file: ./res_ide16_train_test.prototxt
I0622 18:35:47.696815 33249 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer resnet
I0622 18:35:47.697177 33249 net.cpp:49] Initializing net from parameters: 
name: "ResNet"
state {
  phase: TEST
}
layer {
  name: "resnet"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/takeki/caffe/examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/takeki/caffe/examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_1"
  type: "BatchNorm"
  bottom: "conv0"
  top: "bn_a_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_1"
  type: "ReLU"
  bottom: "bn_a_1_1"
  top: "relu_a_1_1"
}
layer {
  name: "conv_a_1_1"
  type: "Convolution"
  bottom: "relu_a_1_1"
  top: "conv_a_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_2"
  type: "BatchNorm"
  bottom: "conv_a_1_1"
  top: "bn_a_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_2"
  type: "ReLU"
  bottom: "bn_a_1_2"
  top: "relu_a_1_2"
}
layer {
  name: "conv_a_1_2"
  type: "Convolution"
  bottom: "relu_a_1_2"
  top: "conv_a_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_a"
  type: "Convolution"
  bottom: "conv0"
  top: "res_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_1"
  type: "Eltwise"
  bottom: "res_a"
  bottom: "conv_a_1_2"
  top: "elt_a_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_a_2_1"
  type: "BatchNorm"
  bottom: "elt_a_1"
  top: "bn_a_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_1"
  type: "ReLU"
  bottom: "bn_a_2_1"
  top: "relu_a_2_1"
}
layer {
  name: "conv_a_2_1"
  type: "Convolution"
  bottom: "relu_a_2_1"
  top: "conv_a_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_2_2"
  type: "BatchNorm"
  bottom: "conv_a_2_1"
  top: "bn_a_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_2"
  type: "ReLU"
  bottom: "bn_a_2_2"
  top: "relu_a_2_2"
}
layer {
  name: "conv_a_2_2"
  type: "Convolution"
  bottom: "relu_a_2_2"
  top: "conv_a_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_2"
  type: "Eltwise"
  bottom: "elt_a_1"
  bottom: "conv_a_2_2"
  top: "elt_a_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_1_1"
  type: "BatchNorm"
  bottom: "elt_a_2"
  top: "bn_d_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_1"
  type: "ReLU"
  bottom: "bn_d_1_1"
  top: "relu_d_1_1"
}
layer {
  name: "conv_d_1_1"
  type: "Convolution"
  bottom: "relu_d_1_1"
  top: "conv_d_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_1_2"
  type: "BatchNorm"
  bottom: "conv_d_1_1"
  top: "bn_d_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_2"
  type: "ReLU"
  bottom: "bn_d_1_2"
  top: "relu_d_1_2"
}
layer {
  name: "conv_d_1_2"
  type: "Convolution"
  bottom: "relu_d_1_2"
  top: "conv_d_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_d"
  type: "Convolution"
  bottom: "elt_a_2"
  top: "res_d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_1"
  type: "Eltwise"
  bottom: "res_d"
  bottom: "conv_d_1_2"
  top: "elt_d_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_2_1"
  type: "BatchNorm"
  bottom: "elt_d_1"
  top: "bn_d_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_1"
  type: "ReLU"
  bottom: "bn_d_2_1"
  top: "relu_d_2_1"
}
layer {
  name: "conv_d_2_1"
  type: "Convolution"
  bottom: "relu_d_2_1"
  top: "conv_d_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_2_2"
  type: "BatchNorm"
  bottom: "conv_d_2_1"
  top: "bn_d_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_2"
  type: "ReLU"
  bottom: "bn_d_2_2"
  top: "relu_d_2_2"
}
layer {
  name: "conv_d_2_2"
  type: "Convolution"
  bottom: "relu_d_2_2"
  top: "conv_d_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_2"
  type: "Eltwise"
  bottom: "elt_d_1"
  bottom: "conv_d_2_2"
  top: "elt_d_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_1_1"
  type: "BatchNorm"
  bottom: "elt_d_2"
  top: "bn_j_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_1"
  type: "ReLU"
  bottom: "bn_j_1_1"
  top: "relu_j_1_1"
}
layer {
  name: "conv_j_1_1"
  type: "Convolution"
  bottom: "relu_j_1_1"
  top: "conv_j_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_1_2"
  type: "BatchNorm"
  bottom: "conv_j_1_1"
  top: "bn_j_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_2"
  type: "ReLU"
  bottom: "bn_j_1_2"
  top: "relu_j_1_2"
}
layer {
  name: "conv_j_1_2"
  type: "Convolution"
  bottom: "relu_j_1_2"
  top: "conv_j_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_j"
  type: "Convolution"
  bottom: "elt_d_2"
  top: "res_j"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_1"
  type: "Eltwise"
  bottom: "res_j"
  bottom: "conv_j_1_2"
  top: "elt_j_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_2_1"
  type: "BatchNorm"
  bottom: "elt_j_1"
  top: "bn_j_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_1"
  type: "ReLU"
  bottom: "bn_j_2_1"
  top: "relu_j_2_1"
}
layer {
  name: "conv_j_2_1"
  type: "Convolution"
  bottom: "relu_j_2_1"
  top: "conv_j_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_2_2"
  type: "BatchNorm"
  bottom: "conv_j_2_1"
  top: "bn_j_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_2"
  type: "ReLU"
  bottom: "bn_j_2_2"
  top: "relu_j_2_2"
}
layer {
  name: "conv_j_2_2"
  type: "Convolution"
  bottom: "relu_j_2_2"
  top: "conv_j_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_2"
  type: "Eltwise"
  bottom: "elt_j_1"
  bottom: "conv_j_2_2"
  top: "elt_j_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_m_1_1"
  type: "BatchNorm"
  bottom: "elt_j_2"
  top: "bn_m_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_m_1_1"
  type: "ReLU"
  bottom: "bn_m_1_1"
  top: "relu_m_1_1"
}
layer {
  name: "gap"
  type: "Pooling"
  bottom: "relu_m_1_1"
  top: "gap"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "gap"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0622 18:35:47.697444 33249 layer_factory.hpp:77] Creating layer resnet
I0622 18:35:47.698359 33249 net.cpp:91] Creating Layer resnet
I0622 18:35:47.698371 33249 net.cpp:399] resnet -> data
I0622 18:35:47.698382 33249 net.cpp:399] resnet -> label
I0622 18:35:47.698392 33249 data_transformer.cpp:25] Loading mean file from: /home/takeki/caffe/examples/cifar10/mean.binaryproto
I0622 18:35:47.700140 33294 db_lmdb.cpp:35] Opened lmdb /home/takeki/caffe/examples/cifar10/cifar10_test_lmdb
I0622 18:35:47.700278 33249 data_layer.cpp:41] output data size: 100,3,32,32
I0622 18:35:47.703173 33249 net.cpp:141] Setting up resnet
I0622 18:35:47.703202 33249 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0622 18:35:47.703209 33249 net.cpp:148] Top shape: 100 (100)
I0622 18:35:47.703214 33249 net.cpp:156] Memory required for data: 1229200
I0622 18:35:47.703220 33249 layer_factory.hpp:77] Creating layer label_resnet_1_split
I0622 18:35:47.703268 33249 net.cpp:91] Creating Layer label_resnet_1_split
I0622 18:35:47.703276 33249 net.cpp:425] label_resnet_1_split <- label
I0622 18:35:47.703284 33249 net.cpp:399] label_resnet_1_split -> label_resnet_1_split_0
I0622 18:35:47.703294 33249 net.cpp:399] label_resnet_1_split -> label_resnet_1_split_1
I0622 18:35:47.703395 33249 net.cpp:141] Setting up label_resnet_1_split
I0622 18:35:47.703408 33249 net.cpp:148] Top shape: 100 (100)
I0622 18:35:47.703415 33249 net.cpp:148] Top shape: 100 (100)
I0622 18:35:47.703420 33249 net.cpp:156] Memory required for data: 1230000
I0622 18:35:47.703440 33249 layer_factory.hpp:77] Creating layer conv0
I0622 18:35:47.703459 33249 net.cpp:91] Creating Layer conv0
I0622 18:35:47.703467 33249 net.cpp:425] conv0 <- data
I0622 18:35:47.703479 33249 net.cpp:399] conv0 -> conv0
I0622 18:35:47.704921 33249 net.cpp:141] Setting up conv0
I0622 18:35:47.704952 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.704958 33249 net.cpp:156] Memory required for data: 7783600
I0622 18:35:47.704970 33249 layer_factory.hpp:77] Creating layer conv0_conv0_0_split
I0622 18:35:47.704980 33249 net.cpp:91] Creating Layer conv0_conv0_0_split
I0622 18:35:47.704987 33249 net.cpp:425] conv0_conv0_0_split <- conv0
I0622 18:35:47.704993 33249 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_0
I0622 18:35:47.705005 33249 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_1
I0622 18:35:47.705067 33249 net.cpp:141] Setting up conv0_conv0_0_split
I0622 18:35:47.705077 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.705085 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.705088 33249 net.cpp:156] Memory required for data: 20890800
I0622 18:35:47.705093 33249 layer_factory.hpp:77] Creating layer bn_a_1_1
I0622 18:35:47.705102 33249 net.cpp:91] Creating Layer bn_a_1_1
I0622 18:35:47.705107 33249 net.cpp:425] bn_a_1_1 <- conv0_conv0_0_split_0
I0622 18:35:47.705121 33249 net.cpp:399] bn_a_1_1 -> bn_a_1_1
I0622 18:35:47.705353 33249 net.cpp:141] Setting up bn_a_1_1
I0622 18:35:47.705368 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.705373 33249 net.cpp:156] Memory required for data: 27444400
I0622 18:35:47.705391 33249 layer_factory.hpp:77] Creating layer relu_a_1_1
I0622 18:35:47.705401 33249 net.cpp:91] Creating Layer relu_a_1_1
I0622 18:35:47.705409 33249 net.cpp:425] relu_a_1_1 <- bn_a_1_1
I0622 18:35:47.705416 33249 net.cpp:399] relu_a_1_1 -> relu_a_1_1
I0622 18:35:47.705739 33249 net.cpp:141] Setting up relu_a_1_1
I0622 18:35:47.705756 33249 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 18:35:47.705762 33249 net.cpp:156] Memory required for data: 33998000
I0622 18:35:47.705767 33249 layer_factory.hpp:77] Creating layer conv_a_1_1
I0622 18:35:47.705781 33249 net.cpp:91] Creating Layer conv_a_1_1
I0622 18:35:47.705790 33249 net.cpp:425] conv_a_1_1 <- relu_a_1_1
I0622 18:35:47.705801 33249 net.cpp:399] conv_a_1_1 -> conv_a_1_1
I0622 18:35:47.707144 33249 net.cpp:141] Setting up conv_a_1_1
I0622 18:35:47.707172 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.707178 33249 net.cpp:156] Memory required for data: 60212400
I0622 18:35:47.707187 33249 layer_factory.hpp:77] Creating layer bn_a_1_2
I0622 18:35:47.707196 33249 net.cpp:91] Creating Layer bn_a_1_2
I0622 18:35:47.707201 33249 net.cpp:425] bn_a_1_2 <- conv_a_1_1
I0622 18:35:47.707212 33249 net.cpp:399] bn_a_1_2 -> bn_a_1_2
I0622 18:35:47.707458 33249 net.cpp:141] Setting up bn_a_1_2
I0622 18:35:47.707473 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.707478 33249 net.cpp:156] Memory required for data: 86426800
I0622 18:35:47.707494 33249 layer_factory.hpp:77] Creating layer relu_a_1_2
I0622 18:35:47.707504 33249 net.cpp:91] Creating Layer relu_a_1_2
I0622 18:35:47.707510 33249 net.cpp:425] relu_a_1_2 <- bn_a_1_2
I0622 18:35:47.707517 33249 net.cpp:399] relu_a_1_2 -> relu_a_1_2
I0622 18:35:47.707830 33249 net.cpp:141] Setting up relu_a_1_2
I0622 18:35:47.707849 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.707854 33249 net.cpp:156] Memory required for data: 112641200
I0622 18:35:47.707860 33249 layer_factory.hpp:77] Creating layer conv_a_1_2
I0622 18:35:47.707878 33249 net.cpp:91] Creating Layer conv_a_1_2
I0622 18:35:47.707887 33249 net.cpp:425] conv_a_1_2 <- relu_a_1_2
I0622 18:35:47.707903 33249 net.cpp:399] conv_a_1_2 -> conv_a_1_2
I0622 18:35:47.709975 33249 net.cpp:141] Setting up conv_a_1_2
I0622 18:35:47.709991 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.709997 33249 net.cpp:156] Memory required for data: 138855600
I0622 18:35:47.710019 33249 layer_factory.hpp:77] Creating layer res_a
I0622 18:35:47.710052 33249 net.cpp:91] Creating Layer res_a
I0622 18:35:47.710074 33249 net.cpp:425] res_a <- conv0_conv0_0_split_1
I0622 18:35:47.710084 33249 net.cpp:399] res_a -> res_a
I0622 18:35:47.711076 33249 net.cpp:141] Setting up res_a
I0622 18:35:47.711092 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.711112 33249 net.cpp:156] Memory required for data: 165070000
I0622 18:35:47.711120 33249 layer_factory.hpp:77] Creating layer elt_a_1
I0622 18:35:47.711132 33249 net.cpp:91] Creating Layer elt_a_1
I0622 18:35:47.711138 33249 net.cpp:425] elt_a_1 <- res_a
I0622 18:35:47.711144 33249 net.cpp:425] elt_a_1 <- conv_a_1_2
I0622 18:35:47.711151 33249 net.cpp:399] elt_a_1 -> elt_a_1
I0622 18:35:47.711200 33249 net.cpp:141] Setting up elt_a_1
I0622 18:35:47.711212 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.711217 33249 net.cpp:156] Memory required for data: 191284400
I0622 18:35:47.711222 33249 layer_factory.hpp:77] Creating layer elt_a_1_elt_a_1_0_split
I0622 18:35:47.711228 33249 net.cpp:91] Creating Layer elt_a_1_elt_a_1_0_split
I0622 18:35:47.711233 33249 net.cpp:425] elt_a_1_elt_a_1_0_split <- elt_a_1
I0622 18:35:47.711243 33249 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_0
I0622 18:35:47.711252 33249 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_1
I0622 18:35:47.711304 33249 net.cpp:141] Setting up elt_a_1_elt_a_1_0_split
I0622 18:35:47.711315 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.711323 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.711328 33249 net.cpp:156] Memory required for data: 243713200
I0622 18:35:47.711333 33249 layer_factory.hpp:77] Creating layer bn_a_2_1
I0622 18:35:47.711344 33249 net.cpp:91] Creating Layer bn_a_2_1
I0622 18:35:47.711349 33249 net.cpp:425] bn_a_2_1 <- elt_a_1_elt_a_1_0_split_0
I0622 18:35:47.711357 33249 net.cpp:399] bn_a_2_1 -> bn_a_2_1
I0622 18:35:47.711572 33249 net.cpp:141] Setting up bn_a_2_1
I0622 18:35:47.711585 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.711591 33249 net.cpp:156] Memory required for data: 269927600
I0622 18:35:47.711603 33249 layer_factory.hpp:77] Creating layer relu_a_2_1
I0622 18:35:47.711616 33249 net.cpp:91] Creating Layer relu_a_2_1
I0622 18:35:47.711621 33249 net.cpp:425] relu_a_2_1 <- bn_a_2_1
I0622 18:35:47.711628 33249 net.cpp:399] relu_a_2_1 -> relu_a_2_1
I0622 18:35:47.711935 33249 net.cpp:141] Setting up relu_a_2_1
I0622 18:35:47.711949 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.711956 33249 net.cpp:156] Memory required for data: 296142000
I0622 18:35:47.711961 33249 layer_factory.hpp:77] Creating layer conv_a_2_1
I0622 18:35:47.711974 33249 net.cpp:91] Creating Layer conv_a_2_1
I0622 18:35:47.711982 33249 net.cpp:425] conv_a_2_1 <- relu_a_2_1
I0622 18:35:47.711992 33249 net.cpp:399] conv_a_2_1 -> conv_a_2_1
I0622 18:35:47.714022 33249 net.cpp:141] Setting up conv_a_2_1
I0622 18:35:47.714038 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.714058 33249 net.cpp:156] Memory required for data: 322356400
I0622 18:35:47.714067 33249 layer_factory.hpp:77] Creating layer bn_a_2_2
I0622 18:35:47.714082 33249 net.cpp:91] Creating Layer bn_a_2_2
I0622 18:35:47.714089 33249 net.cpp:425] bn_a_2_2 <- conv_a_2_1
I0622 18:35:47.714099 33249 net.cpp:399] bn_a_2_2 -> bn_a_2_2
I0622 18:35:47.714328 33249 net.cpp:141] Setting up bn_a_2_2
I0622 18:35:47.714339 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.714344 33249 net.cpp:156] Memory required for data: 348570800
I0622 18:35:47.714354 33249 layer_factory.hpp:77] Creating layer relu_a_2_2
I0622 18:35:47.714375 33249 net.cpp:91] Creating Layer relu_a_2_2
I0622 18:35:47.714382 33249 net.cpp:425] relu_a_2_2 <- bn_a_2_2
I0622 18:35:47.714390 33249 net.cpp:399] relu_a_2_2 -> relu_a_2_2
I0622 18:35:47.714747 33249 net.cpp:141] Setting up relu_a_2_2
I0622 18:35:47.714764 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.714769 33249 net.cpp:156] Memory required for data: 374785200
I0622 18:35:47.714790 33249 layer_factory.hpp:77] Creating layer conv_a_2_2
I0622 18:35:47.714805 33249 net.cpp:91] Creating Layer conv_a_2_2
I0622 18:35:47.714812 33249 net.cpp:425] conv_a_2_2 <- relu_a_2_2
I0622 18:35:47.714824 33249 net.cpp:399] conv_a_2_2 -> conv_a_2_2
I0622 18:35:47.717023 33249 net.cpp:141] Setting up conv_a_2_2
I0622 18:35:47.717052 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.717058 33249 net.cpp:156] Memory required for data: 400999600
I0622 18:35:47.717067 33249 layer_factory.hpp:77] Creating layer elt_a_2
I0622 18:35:47.717075 33249 net.cpp:91] Creating Layer elt_a_2
I0622 18:35:47.717082 33249 net.cpp:425] elt_a_2 <- elt_a_1_elt_a_1_0_split_1
I0622 18:35:47.717092 33249 net.cpp:425] elt_a_2 <- conv_a_2_2
I0622 18:35:47.717100 33249 net.cpp:399] elt_a_2 -> elt_a_2
I0622 18:35:47.717135 33249 net.cpp:141] Setting up elt_a_2
I0622 18:35:47.717146 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.717151 33249 net.cpp:156] Memory required for data: 427214000
I0622 18:35:47.717156 33249 layer_factory.hpp:77] Creating layer elt_a_2_elt_a_2_0_split
I0622 18:35:47.717166 33249 net.cpp:91] Creating Layer elt_a_2_elt_a_2_0_split
I0622 18:35:47.717172 33249 net.cpp:425] elt_a_2_elt_a_2_0_split <- elt_a_2
I0622 18:35:47.717193 33249 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_0
I0622 18:35:47.717206 33249 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_1
I0622 18:35:47.717253 33249 net.cpp:141] Setting up elt_a_2_elt_a_2_0_split
I0622 18:35:47.717265 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.717272 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.717278 33249 net.cpp:156] Memory required for data: 479642800
I0622 18:35:47.717283 33249 layer_factory.hpp:77] Creating layer bn_d_1_1
I0622 18:35:47.717293 33249 net.cpp:91] Creating Layer bn_d_1_1
I0622 18:35:47.717299 33249 net.cpp:425] bn_d_1_1 <- elt_a_2_elt_a_2_0_split_0
I0622 18:35:47.717308 33249 net.cpp:399] bn_d_1_1 -> bn_d_1_1
I0622 18:35:47.717548 33249 net.cpp:141] Setting up bn_d_1_1
I0622 18:35:47.717561 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.717566 33249 net.cpp:156] Memory required for data: 505857200
I0622 18:35:47.717576 33249 layer_factory.hpp:77] Creating layer relu_d_1_1
I0622 18:35:47.717586 33249 net.cpp:91] Creating Layer relu_d_1_1
I0622 18:35:47.717592 33249 net.cpp:425] relu_d_1_1 <- bn_d_1_1
I0622 18:35:47.717598 33249 net.cpp:399] relu_d_1_1 -> relu_d_1_1
I0622 18:35:47.717916 33249 net.cpp:141] Setting up relu_d_1_1
I0622 18:35:47.717933 33249 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 18:35:47.717939 33249 net.cpp:156] Memory required for data: 532071600
I0622 18:35:47.717946 33249 layer_factory.hpp:77] Creating layer conv_d_1_1
I0622 18:35:47.717958 33249 net.cpp:91] Creating Layer conv_d_1_1
I0622 18:35:47.717965 33249 net.cpp:425] conv_d_1_1 <- relu_d_1_1
I0622 18:35:47.717974 33249 net.cpp:399] conv_d_1_1 -> conv_d_1_1
I0622 18:35:47.721019 33249 net.cpp:141] Setting up conv_d_1_1
I0622 18:35:47.721048 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.721056 33249 net.cpp:156] Memory required for data: 545178800
I0622 18:35:47.721065 33249 layer_factory.hpp:77] Creating layer bn_d_1_2
I0622 18:35:47.721073 33249 net.cpp:91] Creating Layer bn_d_1_2
I0622 18:35:47.721078 33249 net.cpp:425] bn_d_1_2 <- conv_d_1_1
I0622 18:35:47.721089 33249 net.cpp:399] bn_d_1_2 -> bn_d_1_2
I0622 18:35:47.721318 33249 net.cpp:141] Setting up bn_d_1_2
I0622 18:35:47.721330 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.721335 33249 net.cpp:156] Memory required for data: 558286000
I0622 18:35:47.721344 33249 layer_factory.hpp:77] Creating layer relu_d_1_2
I0622 18:35:47.721352 33249 net.cpp:91] Creating Layer relu_d_1_2
I0622 18:35:47.721359 33249 net.cpp:425] relu_d_1_2 <- bn_d_1_2
I0622 18:35:47.721365 33249 net.cpp:399] relu_d_1_2 -> relu_d_1_2
I0622 18:35:47.721674 33249 net.cpp:141] Setting up relu_d_1_2
I0622 18:35:47.721716 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.721724 33249 net.cpp:156] Memory required for data: 571393200
I0622 18:35:47.721730 33249 layer_factory.hpp:77] Creating layer conv_d_1_2
I0622 18:35:47.721743 33249 net.cpp:91] Creating Layer conv_d_1_2
I0622 18:35:47.721751 33249 net.cpp:425] conv_d_1_2 <- relu_d_1_2
I0622 18:35:47.721762 33249 net.cpp:399] conv_d_1_2 -> conv_d_1_2
I0622 18:35:47.727494 33249 net.cpp:141] Setting up conv_d_1_2
I0622 18:35:47.727527 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.727535 33249 net.cpp:156] Memory required for data: 584500400
I0622 18:35:47.727552 33249 layer_factory.hpp:77] Creating layer res_d
I0622 18:35:47.727567 33249 net.cpp:91] Creating Layer res_d
I0622 18:35:47.727576 33249 net.cpp:425] res_d <- elt_a_2_elt_a_2_0_split_1
I0622 18:35:47.727598 33249 net.cpp:399] res_d -> res_d
I0622 18:35:47.728859 33249 net.cpp:141] Setting up res_d
I0622 18:35:47.728875 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.728893 33249 net.cpp:156] Memory required for data: 597607600
I0622 18:35:47.728902 33249 layer_factory.hpp:77] Creating layer elt_d_1
I0622 18:35:47.728910 33249 net.cpp:91] Creating Layer elt_d_1
I0622 18:35:47.728915 33249 net.cpp:425] elt_d_1 <- res_d
I0622 18:35:47.728922 33249 net.cpp:425] elt_d_1 <- conv_d_1_2
I0622 18:35:47.728931 33249 net.cpp:399] elt_d_1 -> elt_d_1
I0622 18:35:47.728978 33249 net.cpp:141] Setting up elt_d_1
I0622 18:35:47.728991 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.728994 33249 net.cpp:156] Memory required for data: 610714800
I0622 18:35:47.728999 33249 layer_factory.hpp:77] Creating layer elt_d_1_elt_d_1_0_split
I0622 18:35:47.729009 33249 net.cpp:91] Creating Layer elt_d_1_elt_d_1_0_split
I0622 18:35:47.729017 33249 net.cpp:425] elt_d_1_elt_d_1_0_split <- elt_d_1
I0622 18:35:47.729023 33249 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_0
I0622 18:35:47.729032 33249 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_1
I0622 18:35:47.729079 33249 net.cpp:141] Setting up elt_d_1_elt_d_1_0_split
I0622 18:35:47.729090 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.729096 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.729102 33249 net.cpp:156] Memory required for data: 636929200
I0622 18:35:47.729107 33249 layer_factory.hpp:77] Creating layer bn_d_2_1
I0622 18:35:47.729115 33249 net.cpp:91] Creating Layer bn_d_2_1
I0622 18:35:47.729120 33249 net.cpp:425] bn_d_2_1 <- elt_d_1_elt_d_1_0_split_0
I0622 18:35:47.729130 33249 net.cpp:399] bn_d_2_1 -> bn_d_2_1
I0622 18:35:47.729348 33249 net.cpp:141] Setting up bn_d_2_1
I0622 18:35:47.729360 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.729365 33249 net.cpp:156] Memory required for data: 650036400
I0622 18:35:47.729375 33249 layer_factory.hpp:77] Creating layer relu_d_2_1
I0622 18:35:47.729387 33249 net.cpp:91] Creating Layer relu_d_2_1
I0622 18:35:47.729394 33249 net.cpp:425] relu_d_2_1 <- bn_d_2_1
I0622 18:35:47.729401 33249 net.cpp:399] relu_d_2_1 -> relu_d_2_1
I0622 18:35:47.729601 33249 net.cpp:141] Setting up relu_d_2_1
I0622 18:35:47.729617 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.729624 33249 net.cpp:156] Memory required for data: 663143600
I0622 18:35:47.729630 33249 layer_factory.hpp:77] Creating layer conv_d_2_1
I0622 18:35:47.729646 33249 net.cpp:91] Creating Layer conv_d_2_1
I0622 18:35:47.729655 33249 net.cpp:425] conv_d_2_1 <- relu_d_2_1
I0622 18:35:47.729665 33249 net.cpp:399] conv_d_2_1 -> conv_d_2_1
I0622 18:35:47.735369 33249 net.cpp:141] Setting up conv_d_2_1
I0622 18:35:47.735388 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.735410 33249 net.cpp:156] Memory required for data: 676250800
I0622 18:35:47.735420 33249 layer_factory.hpp:77] Creating layer bn_d_2_2
I0622 18:35:47.735432 33249 net.cpp:91] Creating Layer bn_d_2_2
I0622 18:35:47.735440 33249 net.cpp:425] bn_d_2_2 <- conv_d_2_1
I0622 18:35:47.735448 33249 net.cpp:399] bn_d_2_2 -> bn_d_2_2
I0622 18:35:47.735709 33249 net.cpp:141] Setting up bn_d_2_2
I0622 18:35:47.735723 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.735728 33249 net.cpp:156] Memory required for data: 689358000
I0622 18:35:47.735738 33249 layer_factory.hpp:77] Creating layer relu_d_2_2
I0622 18:35:47.735749 33249 net.cpp:91] Creating Layer relu_d_2_2
I0622 18:35:47.735754 33249 net.cpp:425] relu_d_2_2 <- bn_d_2_2
I0622 18:35:47.735762 33249 net.cpp:399] relu_d_2_2 -> relu_d_2_2
I0622 18:35:47.735980 33249 net.cpp:141] Setting up relu_d_2_2
I0622 18:35:47.735996 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.736001 33249 net.cpp:156] Memory required for data: 702465200
I0622 18:35:47.736006 33249 layer_factory.hpp:77] Creating layer conv_d_2_2
I0622 18:35:47.736019 33249 net.cpp:91] Creating Layer conv_d_2_2
I0622 18:35:47.736027 33249 net.cpp:425] conv_d_2_2 <- relu_d_2_2
I0622 18:35:47.736035 33249 net.cpp:399] conv_d_2_2 -> conv_d_2_2
I0622 18:35:47.741644 33249 net.cpp:141] Setting up conv_d_2_2
I0622 18:35:47.741660 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.741667 33249 net.cpp:156] Memory required for data: 715572400
I0622 18:35:47.741688 33249 layer_factory.hpp:77] Creating layer elt_d_2
I0622 18:35:47.741701 33249 net.cpp:91] Creating Layer elt_d_2
I0622 18:35:47.741708 33249 net.cpp:425] elt_d_2 <- elt_d_1_elt_d_1_0_split_1
I0622 18:35:47.741715 33249 net.cpp:425] elt_d_2 <- conv_d_2_2
I0622 18:35:47.741725 33249 net.cpp:399] elt_d_2 -> elt_d_2
I0622 18:35:47.741756 33249 net.cpp:141] Setting up elt_d_2
I0622 18:35:47.741767 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.741772 33249 net.cpp:156] Memory required for data: 728679600
I0622 18:35:47.741778 33249 layer_factory.hpp:77] Creating layer elt_d_2_elt_d_2_0_split
I0622 18:35:47.741786 33249 net.cpp:91] Creating Layer elt_d_2_elt_d_2_0_split
I0622 18:35:47.741793 33249 net.cpp:425] elt_d_2_elt_d_2_0_split <- elt_d_2
I0622 18:35:47.741803 33249 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_0
I0622 18:35:47.741813 33249 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_1
I0622 18:35:47.741861 33249 net.cpp:141] Setting up elt_d_2_elt_d_2_0_split
I0622 18:35:47.741873 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.741878 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.741883 33249 net.cpp:156] Memory required for data: 754894000
I0622 18:35:47.741888 33249 layer_factory.hpp:77] Creating layer bn_j_1_1
I0622 18:35:47.741899 33249 net.cpp:91] Creating Layer bn_j_1_1
I0622 18:35:47.741905 33249 net.cpp:425] bn_j_1_1 <- elt_d_2_elt_d_2_0_split_0
I0622 18:35:47.741914 33249 net.cpp:399] bn_j_1_1 -> bn_j_1_1
I0622 18:35:47.742139 33249 net.cpp:141] Setting up bn_j_1_1
I0622 18:35:47.742152 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.742158 33249 net.cpp:156] Memory required for data: 768001200
I0622 18:35:47.742168 33249 layer_factory.hpp:77] Creating layer relu_j_1_1
I0622 18:35:47.742177 33249 net.cpp:91] Creating Layer relu_j_1_1
I0622 18:35:47.742183 33249 net.cpp:425] relu_j_1_1 <- bn_j_1_1
I0622 18:35:47.742190 33249 net.cpp:399] relu_j_1_1 -> relu_j_1_1
I0622 18:35:47.742507 33249 net.cpp:141] Setting up relu_j_1_1
I0622 18:35:47.742522 33249 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 18:35:47.742529 33249 net.cpp:156] Memory required for data: 781108400
I0622 18:35:47.742534 33249 layer_factory.hpp:77] Creating layer conv_j_1_1
I0622 18:35:47.742550 33249 net.cpp:91] Creating Layer conv_j_1_1
I0622 18:35:47.742558 33249 net.cpp:425] conv_j_1_1 <- relu_j_1_1
I0622 18:35:47.742566 33249 net.cpp:399] conv_j_1_1 -> conv_j_1_1
I0622 18:35:47.752190 33249 net.cpp:141] Setting up conv_j_1_1
I0622 18:35:47.752207 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.752213 33249 net.cpp:156] Memory required for data: 787662000
I0622 18:35:47.752234 33249 layer_factory.hpp:77] Creating layer bn_j_1_2
I0622 18:35:47.752249 33249 net.cpp:91] Creating Layer bn_j_1_2
I0622 18:35:47.752269 33249 net.cpp:425] bn_j_1_2 <- conv_j_1_1
I0622 18:35:47.752300 33249 net.cpp:399] bn_j_1_2 -> bn_j_1_2
I0622 18:35:47.752549 33249 net.cpp:141] Setting up bn_j_1_2
I0622 18:35:47.752563 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.752568 33249 net.cpp:156] Memory required for data: 794215600
I0622 18:35:47.752578 33249 layer_factory.hpp:77] Creating layer relu_j_1_2
I0622 18:35:47.752605 33249 net.cpp:91] Creating Layer relu_j_1_2
I0622 18:35:47.752612 33249 net.cpp:425] relu_j_1_2 <- bn_j_1_2
I0622 18:35:47.752620 33249 net.cpp:399] relu_j_1_2 -> relu_j_1_2
I0622 18:35:47.752822 33249 net.cpp:141] Setting up relu_j_1_2
I0622 18:35:47.752836 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.752841 33249 net.cpp:156] Memory required for data: 800769200
I0622 18:35:47.752846 33249 layer_factory.hpp:77] Creating layer conv_j_1_2
I0622 18:35:47.752861 33249 net.cpp:91] Creating Layer conv_j_1_2
I0622 18:35:47.752868 33249 net.cpp:425] conv_j_1_2 <- relu_j_1_2
I0622 18:35:47.752878 33249 net.cpp:399] conv_j_1_2 -> conv_j_1_2
I0622 18:35:47.771602 33249 net.cpp:141] Setting up conv_j_1_2
I0622 18:35:47.771625 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.771631 33249 net.cpp:156] Memory required for data: 807322800
I0622 18:35:47.771641 33249 layer_factory.hpp:77] Creating layer res_j
I0622 18:35:47.771656 33249 net.cpp:91] Creating Layer res_j
I0622 18:35:47.771663 33249 net.cpp:425] res_j <- elt_d_2_elt_d_2_0_split_1
I0622 18:35:47.771674 33249 net.cpp:399] res_j -> res_j
I0622 18:35:47.774253 33249 net.cpp:141] Setting up res_j
I0622 18:35:47.774271 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.774276 33249 net.cpp:156] Memory required for data: 813876400
I0622 18:35:47.774286 33249 layer_factory.hpp:77] Creating layer elt_j_1
I0622 18:35:47.774294 33249 net.cpp:91] Creating Layer elt_j_1
I0622 18:35:47.774301 33249 net.cpp:425] elt_j_1 <- res_j
I0622 18:35:47.774309 33249 net.cpp:425] elt_j_1 <- conv_j_1_2
I0622 18:35:47.774317 33249 net.cpp:399] elt_j_1 -> elt_j_1
I0622 18:35:47.774356 33249 net.cpp:141] Setting up elt_j_1
I0622 18:35:47.774369 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.774374 33249 net.cpp:156] Memory required for data: 820430000
I0622 18:35:47.774379 33249 layer_factory.hpp:77] Creating layer elt_j_1_elt_j_1_0_split
I0622 18:35:47.774386 33249 net.cpp:91] Creating Layer elt_j_1_elt_j_1_0_split
I0622 18:35:47.774391 33249 net.cpp:425] elt_j_1_elt_j_1_0_split <- elt_j_1
I0622 18:35:47.774399 33249 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_0
I0622 18:35:47.774413 33249 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_1
I0622 18:35:47.774464 33249 net.cpp:141] Setting up elt_j_1_elt_j_1_0_split
I0622 18:35:47.774476 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.774482 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.774492 33249 net.cpp:156] Memory required for data: 833537200
I0622 18:35:47.774497 33249 layer_factory.hpp:77] Creating layer bn_j_2_1
I0622 18:35:47.774507 33249 net.cpp:91] Creating Layer bn_j_2_1
I0622 18:35:47.774514 33249 net.cpp:425] bn_j_2_1 <- elt_j_1_elt_j_1_0_split_0
I0622 18:35:47.774525 33249 net.cpp:399] bn_j_2_1 -> bn_j_2_1
I0622 18:35:47.774781 33249 net.cpp:141] Setting up bn_j_2_1
I0622 18:35:47.774796 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.774801 33249 net.cpp:156] Memory required for data: 840090800
I0622 18:35:47.774811 33249 layer_factory.hpp:77] Creating layer relu_j_2_1
I0622 18:35:47.774821 33249 net.cpp:91] Creating Layer relu_j_2_1
I0622 18:35:47.774827 33249 net.cpp:425] relu_j_2_1 <- bn_j_2_1
I0622 18:35:47.774834 33249 net.cpp:399] relu_j_2_1 -> relu_j_2_1
I0622 18:35:47.775089 33249 net.cpp:141] Setting up relu_j_2_1
I0622 18:35:47.775104 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.775110 33249 net.cpp:156] Memory required for data: 846644400
I0622 18:35:47.775116 33249 layer_factory.hpp:77] Creating layer conv_j_2_1
I0622 18:35:47.775146 33249 net.cpp:91] Creating Layer conv_j_2_1
I0622 18:35:47.775154 33249 net.cpp:425] conv_j_2_1 <- relu_j_2_1
I0622 18:35:47.775163 33249 net.cpp:399] conv_j_2_1 -> conv_j_2_1
I0622 18:35:47.794246 33249 net.cpp:141] Setting up conv_j_2_1
I0622 18:35:47.794263 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.794270 33249 net.cpp:156] Memory required for data: 853198000
I0622 18:35:47.794280 33249 layer_factory.hpp:77] Creating layer bn_j_2_2
I0622 18:35:47.794296 33249 net.cpp:91] Creating Layer bn_j_2_2
I0622 18:35:47.794303 33249 net.cpp:425] bn_j_2_2 <- conv_j_2_1
I0622 18:35:47.794312 33249 net.cpp:399] bn_j_2_2 -> bn_j_2_2
I0622 18:35:47.794566 33249 net.cpp:141] Setting up bn_j_2_2
I0622 18:35:47.794579 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.794584 33249 net.cpp:156] Memory required for data: 859751600
I0622 18:35:47.794612 33249 layer_factory.hpp:77] Creating layer relu_j_2_2
I0622 18:35:47.794622 33249 net.cpp:91] Creating Layer relu_j_2_2
I0622 18:35:47.794632 33249 net.cpp:425] relu_j_2_2 <- bn_j_2_2
I0622 18:35:47.794641 33249 net.cpp:399] relu_j_2_2 -> relu_j_2_2
I0622 18:35:47.794971 33249 net.cpp:141] Setting up relu_j_2_2
I0622 18:35:47.794989 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.794996 33249 net.cpp:156] Memory required for data: 866305200
I0622 18:35:47.795001 33249 layer_factory.hpp:77] Creating layer conv_j_2_2
I0622 18:35:47.795016 33249 net.cpp:91] Creating Layer conv_j_2_2
I0622 18:35:47.795023 33249 net.cpp:425] conv_j_2_2 <- relu_j_2_2
I0622 18:35:47.795032 33249 net.cpp:399] conv_j_2_2 -> conv_j_2_2
I0622 18:35:47.813709 33249 net.cpp:141] Setting up conv_j_2_2
I0622 18:35:47.813729 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.813736 33249 net.cpp:156] Memory required for data: 872858800
I0622 18:35:47.813745 33249 layer_factory.hpp:77] Creating layer elt_j_2
I0622 18:35:47.813753 33249 net.cpp:91] Creating Layer elt_j_2
I0622 18:35:47.813772 33249 net.cpp:425] elt_j_2 <- elt_j_1_elt_j_1_0_split_1
I0622 18:35:47.813779 33249 net.cpp:425] elt_j_2 <- conv_j_2_2
I0622 18:35:47.813786 33249 net.cpp:399] elt_j_2 -> elt_j_2
I0622 18:35:47.813824 33249 net.cpp:141] Setting up elt_j_2
I0622 18:35:47.813837 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.813840 33249 net.cpp:156] Memory required for data: 879412400
I0622 18:35:47.813845 33249 layer_factory.hpp:77] Creating layer bn_m_1_1
I0622 18:35:47.813855 33249 net.cpp:91] Creating Layer bn_m_1_1
I0622 18:35:47.813863 33249 net.cpp:425] bn_m_1_1 <- elt_j_2
I0622 18:35:47.813869 33249 net.cpp:399] bn_m_1_1 -> bn_m_1_1
I0622 18:35:47.814126 33249 net.cpp:141] Setting up bn_m_1_1
I0622 18:35:47.814137 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.814142 33249 net.cpp:156] Memory required for data: 885966000
I0622 18:35:47.814152 33249 layer_factory.hpp:77] Creating layer relu_m_1_1
I0622 18:35:47.814162 33249 net.cpp:91] Creating Layer relu_m_1_1
I0622 18:35:47.814167 33249 net.cpp:425] relu_m_1_1 <- bn_m_1_1
I0622 18:35:47.814173 33249 net.cpp:399] relu_m_1_1 -> relu_m_1_1
I0622 18:35:47.814498 33249 net.cpp:141] Setting up relu_m_1_1
I0622 18:35:47.814513 33249 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 18:35:47.814518 33249 net.cpp:156] Memory required for data: 892519600
I0622 18:35:47.814524 33249 layer_factory.hpp:77] Creating layer gap
I0622 18:35:47.814533 33249 net.cpp:91] Creating Layer gap
I0622 18:35:47.814540 33249 net.cpp:425] gap <- relu_m_1_1
I0622 18:35:47.814550 33249 net.cpp:399] gap -> gap
I0622 18:35:47.814781 33249 net.cpp:141] Setting up gap
I0622 18:35:47.814796 33249 net.cpp:148] Top shape: 100 256 1 1 (25600)
I0622 18:35:47.814801 33249 net.cpp:156] Memory required for data: 892622000
I0622 18:35:47.814807 33249 layer_factory.hpp:77] Creating layer ip1
I0622 18:35:47.814821 33249 net.cpp:91] Creating Layer ip1
I0622 18:35:47.814826 33249 net.cpp:425] ip1 <- gap
I0622 18:35:47.814836 33249 net.cpp:399] ip1 -> ip1
I0622 18:35:47.815057 33249 net.cpp:141] Setting up ip1
I0622 18:35:47.815086 33249 net.cpp:148] Top shape: 100 10 (1000)
I0622 18:35:47.815093 33249 net.cpp:156] Memory required for data: 892626000
I0622 18:35:47.815102 33249 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0622 18:35:47.815111 33249 net.cpp:91] Creating Layer ip1_ip1_0_split
I0622 18:35:47.815119 33249 net.cpp:425] ip1_ip1_0_split <- ip1
I0622 18:35:47.815125 33249 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0622 18:35:47.815134 33249 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0622 18:35:47.815187 33249 net.cpp:141] Setting up ip1_ip1_0_split
I0622 18:35:47.815199 33249 net.cpp:148] Top shape: 100 10 (1000)
I0622 18:35:47.815206 33249 net.cpp:148] Top shape: 100 10 (1000)
I0622 18:35:47.815210 33249 net.cpp:156] Memory required for data: 892634000
I0622 18:35:47.815215 33249 layer_factory.hpp:77] Creating layer accuracy
I0622 18:35:47.815224 33249 net.cpp:91] Creating Layer accuracy
I0622 18:35:47.815229 33249 net.cpp:425] accuracy <- ip1_ip1_0_split_0
I0622 18:35:47.815235 33249 net.cpp:425] accuracy <- label_resnet_1_split_0
I0622 18:35:47.815245 33249 net.cpp:399] accuracy -> accuracy
I0622 18:35:47.815259 33249 net.cpp:141] Setting up accuracy
I0622 18:35:47.815266 33249 net.cpp:148] Top shape: (1)
I0622 18:35:47.815271 33249 net.cpp:156] Memory required for data: 892634004
I0622 18:35:47.815276 33249 layer_factory.hpp:77] Creating layer loss
I0622 18:35:47.815284 33249 net.cpp:91] Creating Layer loss
I0622 18:35:47.815294 33249 net.cpp:425] loss <- ip1_ip1_0_split_1
I0622 18:35:47.815299 33249 net.cpp:425] loss <- label_resnet_1_split_1
I0622 18:35:47.815306 33249 net.cpp:399] loss -> loss
I0622 18:35:47.815317 33249 layer_factory.hpp:77] Creating layer loss
I0622 18:35:47.815744 33249 net.cpp:141] Setting up loss
I0622 18:35:47.815758 33249 net.cpp:148] Top shape: (1)
I0622 18:35:47.815763 33249 net.cpp:151]     with loss weight 1
I0622 18:35:47.815778 33249 net.cpp:156] Memory required for data: 892634008
I0622 18:35:47.815783 33249 net.cpp:217] loss needs backward computation.
I0622 18:35:47.815788 33249 net.cpp:219] accuracy does not need backward computation.
I0622 18:35:47.815793 33249 net.cpp:217] ip1_ip1_0_split needs backward computation.
I0622 18:35:47.815798 33249 net.cpp:217] ip1 needs backward computation.
I0622 18:35:47.815803 33249 net.cpp:217] gap needs backward computation.
I0622 18:35:47.815807 33249 net.cpp:217] relu_m_1_1 needs backward computation.
I0622 18:35:47.815811 33249 net.cpp:217] bn_m_1_1 needs backward computation.
I0622 18:35:47.815816 33249 net.cpp:217] elt_j_2 needs backward computation.
I0622 18:35:47.815821 33249 net.cpp:217] conv_j_2_2 needs backward computation.
I0622 18:35:47.815826 33249 net.cpp:217] relu_j_2_2 needs backward computation.
I0622 18:35:47.815831 33249 net.cpp:217] bn_j_2_2 needs backward computation.
I0622 18:35:47.815835 33249 net.cpp:217] conv_j_2_1 needs backward computation.
I0622 18:35:47.815840 33249 net.cpp:217] relu_j_2_1 needs backward computation.
I0622 18:35:47.815845 33249 net.cpp:217] bn_j_2_1 needs backward computation.
I0622 18:35:47.815850 33249 net.cpp:217] elt_j_1_elt_j_1_0_split needs backward computation.
I0622 18:35:47.815853 33249 net.cpp:217] elt_j_1 needs backward computation.
I0622 18:35:47.815858 33249 net.cpp:217] res_j needs backward computation.
I0622 18:35:47.815863 33249 net.cpp:217] conv_j_1_2 needs backward computation.
I0622 18:35:47.815867 33249 net.cpp:217] relu_j_1_2 needs backward computation.
I0622 18:35:47.815872 33249 net.cpp:217] bn_j_1_2 needs backward computation.
I0622 18:35:47.815876 33249 net.cpp:217] conv_j_1_1 needs backward computation.
I0622 18:35:47.815881 33249 net.cpp:217] relu_j_1_1 needs backward computation.
I0622 18:35:47.815886 33249 net.cpp:217] bn_j_1_1 needs backward computation.
I0622 18:35:47.815891 33249 net.cpp:217] elt_d_2_elt_d_2_0_split needs backward computation.
I0622 18:35:47.815896 33249 net.cpp:217] elt_d_2 needs backward computation.
I0622 18:35:47.815901 33249 net.cpp:217] conv_d_2_2 needs backward computation.
I0622 18:35:47.815906 33249 net.cpp:217] relu_d_2_2 needs backward computation.
I0622 18:35:47.815923 33249 net.cpp:217] bn_d_2_2 needs backward computation.
I0622 18:35:47.815933 33249 net.cpp:217] conv_d_2_1 needs backward computation.
I0622 18:35:47.815938 33249 net.cpp:217] relu_d_2_1 needs backward computation.
I0622 18:35:47.815943 33249 net.cpp:217] bn_d_2_1 needs backward computation.
I0622 18:35:47.815948 33249 net.cpp:217] elt_d_1_elt_d_1_0_split needs backward computation.
I0622 18:35:47.815953 33249 net.cpp:217] elt_d_1 needs backward computation.
I0622 18:35:47.815958 33249 net.cpp:217] res_d needs backward computation.
I0622 18:35:47.815963 33249 net.cpp:217] conv_d_1_2 needs backward computation.
I0622 18:35:47.815968 33249 net.cpp:217] relu_d_1_2 needs backward computation.
I0622 18:35:47.815973 33249 net.cpp:217] bn_d_1_2 needs backward computation.
I0622 18:35:47.815979 33249 net.cpp:217] conv_d_1_1 needs backward computation.
I0622 18:35:47.815982 33249 net.cpp:217] relu_d_1_1 needs backward computation.
I0622 18:35:47.815987 33249 net.cpp:217] bn_d_1_1 needs backward computation.
I0622 18:35:47.815992 33249 net.cpp:217] elt_a_2_elt_a_2_0_split needs backward computation.
I0622 18:35:47.815997 33249 net.cpp:217] elt_a_2 needs backward computation.
I0622 18:35:47.816002 33249 net.cpp:217] conv_a_2_2 needs backward computation.
I0622 18:35:47.816007 33249 net.cpp:217] relu_a_2_2 needs backward computation.
I0622 18:35:47.816011 33249 net.cpp:217] bn_a_2_2 needs backward computation.
I0622 18:35:47.816016 33249 net.cpp:217] conv_a_2_1 needs backward computation.
I0622 18:35:47.816021 33249 net.cpp:217] relu_a_2_1 needs backward computation.
I0622 18:35:47.816026 33249 net.cpp:217] bn_a_2_1 needs backward computation.
I0622 18:35:47.816031 33249 net.cpp:217] elt_a_1_elt_a_1_0_split needs backward computation.
I0622 18:35:47.816035 33249 net.cpp:217] elt_a_1 needs backward computation.
I0622 18:35:47.816041 33249 net.cpp:217] res_a needs backward computation.
I0622 18:35:47.816046 33249 net.cpp:217] conv_a_1_2 needs backward computation.
I0622 18:35:47.816051 33249 net.cpp:217] relu_a_1_2 needs backward computation.
I0622 18:35:47.816056 33249 net.cpp:217] bn_a_1_2 needs backward computation.
I0622 18:35:47.816061 33249 net.cpp:217] conv_a_1_1 needs backward computation.
I0622 18:35:47.816064 33249 net.cpp:217] relu_a_1_1 needs backward computation.
I0622 18:35:47.816069 33249 net.cpp:217] bn_a_1_1 needs backward computation.
I0622 18:35:47.816074 33249 net.cpp:217] conv0_conv0_0_split needs backward computation.
I0622 18:35:47.816079 33249 net.cpp:217] conv0 needs backward computation.
I0622 18:35:47.816084 33249 net.cpp:219] label_resnet_1_split does not need backward computation.
I0622 18:35:47.816090 33249 net.cpp:219] resnet does not need backward computation.
I0622 18:35:47.816094 33249 net.cpp:261] This network produces output accuracy
I0622 18:35:47.816099 33249 net.cpp:261] This network produces output loss
I0622 18:35:47.816146 33249 net.cpp:274] Network initialization done.
I0622 18:35:47.816409 33249 solver.cpp:60] Solver scaffolding done.
I0622 18:35:47.819476 33249 caffe.cpp:219] Starting Optimization
I0622 18:35:47.819489 33249 solver.cpp:279] Solving ResNet
I0622 18:35:47.819494 33249 solver.cpp:280] Learning Rate Policy: multistep
I0622 18:35:47.822022 33249 solver.cpp:337] Iteration 0, Testing net (#0)
I0622 18:35:51.527704 33249 solver.cpp:404]     Test net output #0: accuracy = 0.0989
I0622 18:35:51.527752 33249 solver.cpp:404]     Test net output #1: loss = 2.47965 (* 1 = 2.47965 loss)
I0622 18:35:51.580534 33249 solver.cpp:228] Iteration 0, loss = 2.38509
I0622 18:35:51.580579 33249 solver.cpp:244]     Train net output #0: loss = 2.38509 (* 1 = 2.38509 loss)
I0622 18:35:51.580605 33249 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0622 18:36:15.134799 33249 solver.cpp:228] Iteration 200, loss = 1.89236
I0622 18:36:15.134866 33249 solver.cpp:244]     Train net output #0: loss = 1.89236 (* 1 = 1.89236 loss)
I0622 18:36:15.134876 33249 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0622 18:36:38.851325 33249 solver.cpp:228] Iteration 400, loss = 1.77529
I0622 18:36:38.851743 33249 solver.cpp:244]     Train net output #0: loss = 1.77529 (* 1 = 1.77529 loss)
I0622 18:36:38.851793 33249 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0622 18:37:02.793954 33249 solver.cpp:228] Iteration 600, loss = 1.66807
I0622 18:37:02.794024 33249 solver.cpp:244]     Train net output #0: loss = 1.66807 (* 1 = 1.66807 loss)
I0622 18:37:02.794037 33249 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0622 18:37:28.071069 33249 solver.cpp:228] Iteration 800, loss = 1.80419
I0622 18:37:28.071338 33249 solver.cpp:244]     Train net output #0: loss = 1.80419 (* 1 = 1.80419 loss)
I0622 18:37:28.071362 33249 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0622 18:37:53.193227 33249 solver.cpp:337] Iteration 1000, Testing net (#0)
I0622 18:37:57.082526 33249 solver.cpp:404]     Test net output #0: accuracy = 0.3576
I0622 18:37:57.082582 33249 solver.cpp:404]     Test net output #1: loss = 1.76324 (* 1 = 1.76324 loss)
I0622 18:37:57.129207 33249 solver.cpp:228] Iteration 1000, loss = 1.95166
I0622 18:37:57.129299 33249 solver.cpp:244]     Train net output #0: loss = 1.95166 (* 1 = 1.95166 loss)
I0622 18:37:57.129367 33249 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0622 18:38:22.326870 33249 solver.cpp:228] Iteration 1200, loss = 1.84009
I0622 18:38:22.327185 33249 solver.cpp:244]     Train net output #0: loss = 1.84009 (* 1 = 1.84009 loss)
I0622 18:38:22.327250 33249 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0622 18:38:47.660830 33249 solver.cpp:228] Iteration 1400, loss = 1.70256
I0622 18:38:47.660962 33249 solver.cpp:244]     Train net output #0: loss = 1.70256 (* 1 = 1.70256 loss)
I0622 18:38:47.660987 33249 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0622 18:39:12.976174 33249 solver.cpp:228] Iteration 1600, loss = 1.58302
I0622 18:39:12.976428 33249 solver.cpp:244]     Train net output #0: loss = 1.58302 (* 1 = 1.58302 loss)
I0622 18:39:12.976451 33249 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0622 18:39:38.270831 33249 solver.cpp:228] Iteration 1800, loss = 1.7024
I0622 18:39:38.270901 33249 solver.cpp:244]     Train net output #0: loss = 1.7024 (* 1 = 1.7024 loss)
I0622 18:39:38.270911 33249 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0622 18:40:03.484519 33249 solver.cpp:337] Iteration 2000, Testing net (#0)
I0622 18:40:07.364095 33249 solver.cpp:404]     Test net output #0: accuracy = 0.3832
I0622 18:40:07.364143 33249 solver.cpp:404]     Test net output #1: loss = 1.69777 (* 1 = 1.69777 loss)
I0622 18:40:07.405055 33249 solver.cpp:228] Iteration 2000, loss = 1.87797
I0622 18:40:07.405093 33249 solver.cpp:244]     Train net output #0: loss = 1.87797 (* 1 = 1.87797 loss)
I0622 18:40:07.405105 33249 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0622 18:40:32.592670 33249 solver.cpp:228] Iteration 2200, loss = 1.73661
I0622 18:40:32.592743 33249 solver.cpp:244]     Train net output #0: loss = 1.73661 (* 1 = 1.73661 loss)
I0622 18:40:32.592757 33249 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0622 18:40:57.885007 33249 solver.cpp:228] Iteration 2400, loss = 1.55583
I0622 18:40:57.885313 33249 solver.cpp:244]     Train net output #0: loss = 1.55583 (* 1 = 1.55583 loss)
I0622 18:40:57.885365 33249 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0622 18:41:23.191254 33249 solver.cpp:228] Iteration 2600, loss = 1.50538
I0622 18:41:23.191326 33249 solver.cpp:244]     Train net output #0: loss = 1.50538 (* 1 = 1.50538 loss)
I0622 18:41:23.191340 33249 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0622 18:41:48.478359 33249 solver.cpp:228] Iteration 2800, loss = 1.64421
I0622 18:41:48.478588 33249 solver.cpp:244]     Train net output #0: loss = 1.64421 (* 1 = 1.64421 loss)
I0622 18:41:48.478612 33249 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0622 18:42:13.768055 33249 solver.cpp:337] Iteration 3000, Testing net (#0)
I0622 18:42:17.666015 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4043
I0622 18:42:17.666072 33249 solver.cpp:404]     Test net output #1: loss = 1.63502 (* 1 = 1.63502 loss)
I0622 18:42:17.707551 33249 solver.cpp:228] Iteration 3000, loss = 1.74346
I0622 18:42:17.707579 33249 solver.cpp:244]     Train net output #0: loss = 1.74346 (* 1 = 1.74346 loss)
I0622 18:42:17.707597 33249 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0622 18:42:43.010088 33249 solver.cpp:228] Iteration 3200, loss = 1.74386
I0622 18:42:43.010375 33249 solver.cpp:244]     Train net output #0: loss = 1.74386 (* 1 = 1.74386 loss)
I0622 18:42:43.010391 33249 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0622 18:43:08.329185 33249 solver.cpp:228] Iteration 3400, loss = 1.52549
I0622 18:43:08.329243 33249 solver.cpp:244]     Train net output #0: loss = 1.52549 (* 1 = 1.52549 loss)
I0622 18:43:08.329254 33249 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0622 18:43:33.634300 33249 solver.cpp:228] Iteration 3600, loss = 1.47228
I0622 18:43:33.634563 33249 solver.cpp:244]     Train net output #0: loss = 1.47228 (* 1 = 1.47228 loss)
I0622 18:43:33.634596 33249 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0622 18:43:59.166064 33249 solver.cpp:228] Iteration 3800, loss = 1.67691
I0622 18:43:59.166121 33249 solver.cpp:244]     Train net output #0: loss = 1.67691 (* 1 = 1.67691 loss)
I0622 18:43:59.166131 33249 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0622 18:44:24.511287 33249 solver.cpp:337] Iteration 4000, Testing net (#0)
I0622 18:44:28.412662 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4159
I0622 18:44:28.412729 33249 solver.cpp:404]     Test net output #1: loss = 1.60263 (* 1 = 1.60263 loss)
I0622 18:44:28.454681 33249 solver.cpp:228] Iteration 4000, loss = 1.70217
I0622 18:44:28.454780 33249 solver.cpp:244]     Train net output #0: loss = 1.70217 (* 1 = 1.70217 loss)
I0622 18:44:28.454797 33249 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0622 18:44:53.836997 33249 solver.cpp:228] Iteration 4200, loss = 1.68035
I0622 18:44:53.837059 33249 solver.cpp:244]     Train net output #0: loss = 1.68035 (* 1 = 1.68035 loss)
I0622 18:44:53.837070 33249 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0622 18:45:19.505156 33249 solver.cpp:228] Iteration 4400, loss = 1.50439
I0622 18:45:19.505444 33249 solver.cpp:244]     Train net output #0: loss = 1.50439 (* 1 = 1.50439 loss)
I0622 18:45:19.505468 33249 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0622 18:45:45.145210 33249 solver.cpp:228] Iteration 4600, loss = 1.45629
I0622 18:45:45.145273 33249 solver.cpp:244]     Train net output #0: loss = 1.45629 (* 1 = 1.45629 loss)
I0622 18:45:45.145287 33249 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0622 18:46:10.469168 33249 solver.cpp:228] Iteration 4800, loss = 1.53389
I0622 18:46:10.469388 33249 solver.cpp:244]     Train net output #0: loss = 1.53389 (* 1 = 1.53389 loss)
I0622 18:46:10.469403 33249 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0622 18:46:35.992754 33249 solver.cpp:337] Iteration 5000, Testing net (#0)
I0622 18:46:39.938393 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4324
I0622 18:46:39.938454 33249 solver.cpp:404]     Test net output #1: loss = 1.56054 (* 1 = 1.56054 loss)
I0622 18:46:39.980080 33249 solver.cpp:228] Iteration 5000, loss = 1.71156
I0622 18:46:39.980105 33249 solver.cpp:244]     Train net output #0: loss = 1.71156 (* 1 = 1.71156 loss)
I0622 18:46:39.980119 33249 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0622 18:47:05.430557 33249 solver.cpp:228] Iteration 5200, loss = 1.65248
I0622 18:47:05.430779 33249 solver.cpp:244]     Train net output #0: loss = 1.65248 (* 1 = 1.65248 loss)
I0622 18:47:05.430794 33249 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0622 18:47:31.122875 33249 solver.cpp:228] Iteration 5400, loss = 1.48222
I0622 18:47:31.122922 33249 solver.cpp:244]     Train net output #0: loss = 1.48222 (* 1 = 1.48222 loss)
I0622 18:47:31.122933 33249 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0622 18:47:56.809469 33249 solver.cpp:228] Iteration 5600, loss = 1.45826
I0622 18:47:56.809707 33249 solver.cpp:244]     Train net output #0: loss = 1.45826 (* 1 = 1.45826 loss)
I0622 18:47:56.809747 33249 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0622 18:48:22.524260 33249 solver.cpp:228] Iteration 5800, loss = 1.57104
I0622 18:48:22.524313 33249 solver.cpp:244]     Train net output #0: loss = 1.57104 (* 1 = 1.57104 loss)
I0622 18:48:22.524324 33249 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0622 18:48:47.857803 33249 solver.cpp:337] Iteration 6000, Testing net (#0)
I0622 18:48:51.764276 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4353
I0622 18:48:51.764323 33249 solver.cpp:404]     Test net output #1: loss = 1.5445 (* 1 = 1.5445 loss)
I0622 18:48:51.806136 33249 solver.cpp:228] Iteration 6000, loss = 1.63435
I0622 18:48:51.806161 33249 solver.cpp:244]     Train net output #0: loss = 1.63435 (* 1 = 1.63435 loss)
I0622 18:48:51.806174 33249 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0622 18:49:17.246037 33249 solver.cpp:228] Iteration 6200, loss = 1.64356
I0622 18:49:17.246090 33249 solver.cpp:244]     Train net output #0: loss = 1.64356 (* 1 = 1.64356 loss)
I0622 18:49:17.246101 33249 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0622 18:49:42.920342 33249 solver.cpp:228] Iteration 6400, loss = 1.47319
I0622 18:49:42.920589 33249 solver.cpp:244]     Train net output #0: loss = 1.47319 (* 1 = 1.47319 loss)
I0622 18:49:42.920617 33249 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0622 18:50:08.533668 33249 solver.cpp:228] Iteration 6600, loss = 1.40333
I0622 18:50:08.533720 33249 solver.cpp:244]     Train net output #0: loss = 1.40333 (* 1 = 1.40333 loss)
I0622 18:50:08.533731 33249 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0622 18:50:33.855492 33249 solver.cpp:228] Iteration 6800, loss = 1.43854
I0622 18:50:33.855674 33249 solver.cpp:244]     Train net output #0: loss = 1.43854 (* 1 = 1.43854 loss)
I0622 18:50:33.855687 33249 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0622 18:50:59.404531 33249 solver.cpp:337] Iteration 7000, Testing net (#0)
I0622 18:51:03.329507 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4482
I0622 18:51:03.329557 33249 solver.cpp:404]     Test net output #1: loss = 1.52761 (* 1 = 1.52761 loss)
I0622 18:51:03.370968 33249 solver.cpp:228] Iteration 7000, loss = 1.58349
I0622 18:51:03.371001 33249 solver.cpp:244]     Train net output #0: loss = 1.58349 (* 1 = 1.58349 loss)
I0622 18:51:03.371013 33249 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0622 18:51:28.877781 33249 solver.cpp:228] Iteration 7200, loss = 1.56855
I0622 18:51:28.877957 33249 solver.cpp:244]     Train net output #0: loss = 1.56855 (* 1 = 1.56855 loss)
I0622 18:51:28.877970 33249 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0622 18:51:54.557958 33249 solver.cpp:228] Iteration 7400, loss = 1.42919
I0622 18:51:54.558012 33249 solver.cpp:244]     Train net output #0: loss = 1.42919 (* 1 = 1.42919 loss)
I0622 18:51:54.558022 33249 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0622 18:52:20.005579 33249 solver.cpp:228] Iteration 7600, loss = 1.37143
I0622 18:52:20.005774 33249 solver.cpp:244]     Train net output #0: loss = 1.37143 (* 1 = 1.37143 loss)
I0622 18:52:20.005786 33249 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0622 18:52:45.516666 33249 solver.cpp:228] Iteration 7800, loss = 1.4799
I0622 18:52:45.516718 33249 solver.cpp:244]     Train net output #0: loss = 1.4799 (* 1 = 1.4799 loss)
I0622 18:52:45.516728 33249 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0622 18:53:10.884474 33249 solver.cpp:337] Iteration 8000, Testing net (#0)
I0622 18:53:14.805624 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4576
I0622 18:53:14.805677 33249 solver.cpp:404]     Test net output #1: loss = 1.49177 (* 1 = 1.49177 loss)
I0622 18:53:14.847468 33249 solver.cpp:228] Iteration 8000, loss = 1.56187
I0622 18:53:14.847499 33249 solver.cpp:244]     Train net output #0: loss = 1.56187 (* 1 = 1.56187 loss)
I0622 18:53:14.847513 33249 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0622 18:53:40.172822 33249 solver.cpp:228] Iteration 8200, loss = 1.57101
I0622 18:53:40.172873 33249 solver.cpp:244]     Train net output #0: loss = 1.57101 (* 1 = 1.57101 loss)
I0622 18:53:40.172884 33249 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0622 18:54:05.480082 33249 solver.cpp:228] Iteration 8400, loss = 1.37337
I0622 18:54:05.480356 33249 solver.cpp:244]     Train net output #0: loss = 1.37337 (* 1 = 1.37337 loss)
I0622 18:54:05.480372 33249 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0622 18:54:30.795529 33249 solver.cpp:228] Iteration 8600, loss = 1.34722
I0622 18:54:30.795579 33249 solver.cpp:244]     Train net output #0: loss = 1.34722 (* 1 = 1.34722 loss)
I0622 18:54:30.795590 33249 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0622 18:54:56.104581 33249 solver.cpp:228] Iteration 8800, loss = 1.44211
I0622 18:54:56.104789 33249 solver.cpp:244]     Train net output #0: loss = 1.44211 (* 1 = 1.44211 loss)
I0622 18:54:56.104805 33249 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0622 18:55:21.354563 33249 solver.cpp:337] Iteration 9000, Testing net (#0)
I0622 18:55:25.255336 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4825
I0622 18:55:25.255390 33249 solver.cpp:404]     Test net output #1: loss = 1.43417 (* 1 = 1.43417 loss)
I0622 18:55:25.297348 33249 solver.cpp:228] Iteration 9000, loss = 1.51014
I0622 18:55:25.297385 33249 solver.cpp:244]     Train net output #0: loss = 1.51014 (* 1 = 1.51014 loss)
I0622 18:55:25.297408 33249 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0622 18:55:50.589370 33249 solver.cpp:228] Iteration 9200, loss = 1.53176
I0622 18:55:50.589696 33249 solver.cpp:244]     Train net output #0: loss = 1.53176 (* 1 = 1.53176 loss)
I0622 18:55:50.589768 33249 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0622 18:56:15.885766 33249 solver.cpp:228] Iteration 9400, loss = 1.32397
I0622 18:56:15.885819 33249 solver.cpp:244]     Train net output #0: loss = 1.32397 (* 1 = 1.32397 loss)
I0622 18:56:15.885830 33249 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0622 18:56:41.213855 33249 solver.cpp:228] Iteration 9600, loss = 1.26122
I0622 18:56:41.214049 33249 solver.cpp:244]     Train net output #0: loss = 1.26122 (* 1 = 1.26122 loss)
I0622 18:56:41.214063 33249 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0622 18:57:06.501225 33249 solver.cpp:228] Iteration 9800, loss = 1.27952
I0622 18:57:06.501278 33249 solver.cpp:244]     Train net output #0: loss = 1.27952 (* 1 = 1.27952 loss)
I0622 18:57:06.501289 33249 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0622 18:57:31.766448 33249 solver.cpp:337] Iteration 10000, Testing net (#0)
I0622 18:57:35.681378 33249 solver.cpp:404]     Test net output #0: accuracy = 0.4801
I0622 18:57:35.681428 33249 solver.cpp:404]     Test net output #1: loss = 1.425 (* 1 = 1.425 loss)
I0622 18:57:35.723328 33249 solver.cpp:228] Iteration 10000, loss = 1.55779
I0622 18:57:35.723354 33249 solver.cpp:244]     Train net output #0: loss = 1.55779 (* 1 = 1.55779 loss)
I0622 18:57:35.723367 33249 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0622 18:58:01.052414 33249 solver.cpp:228] Iteration 10200, loss = 1.45769
I0622 18:58:01.052475 33249 solver.cpp:244]     Train net output #0: loss = 1.45769 (* 1 = 1.45769 loss)
I0622 18:58:01.052486 33249 sgd_solver.cpp:106] Iteration 10200, lr = 0.1
I0622 18:58:26.347599 33249 solver.cpp:228] Iteration 10400, loss = 1.2291
I0622 18:58:26.347802 33249 solver.cpp:244]     Train net output #0: loss = 1.2291 (* 1 = 1.2291 loss)
I0622 18:58:26.347815 33249 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0622 18:58:51.665594 33249 solver.cpp:228] Iteration 10600, loss = 1.31058
I0622 18:58:51.665642 33249 solver.cpp:244]     Train net output #0: loss = 1.31058 (* 1 = 1.31058 loss)
I0622 18:58:51.665653 33249 sgd_solver.cpp:106] Iteration 10600, lr = 0.1
I0622 18:59:17.004904 33249 solver.cpp:228] Iteration 10800, loss = 1.37309
I0622 18:59:17.005115 33249 solver.cpp:244]     Train net output #0: loss = 1.37309 (* 1 = 1.37309 loss)
I0622 18:59:17.005134 33249 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0622 18:59:42.291679 33249 solver.cpp:337] Iteration 11000, Testing net (#0)
I0622 18:59:46.181918 33249 solver.cpp:404]     Test net output #0: accuracy = 0.5124
I0622 18:59:46.181967 33249 solver.cpp:404]     Test net output #1: loss = 1.35083 (* 1 = 1.35083 loss)
I0622 18:59:46.223362 33249 solver.cpp:228] Iteration 11000, loss = 1.40244
I0622 18:59:46.223388 33249 solver.cpp:244]     Train net output #0: loss = 1.40244 (* 1 = 1.40244 loss)
I0622 18:59:46.223402 33249 sgd_solver.cpp:106] Iteration 11000, lr = 0.1
I0622 19:00:11.440709 33249 solver.cpp:228] Iteration 11200, loss = 1.41917
I0622 19:00:11.441033 33249 solver.cpp:244]     Train net output #0: loss = 1.41917 (* 1 = 1.41917 loss)
I0622 19:00:11.441099 33249 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0622 19:00:36.701992 33249 solver.cpp:228] Iteration 11400, loss = 1.22433
I0622 19:00:36.702054 33249 solver.cpp:244]     Train net output #0: loss = 1.22433 (* 1 = 1.22433 loss)
I0622 19:00:36.702065 33249 sgd_solver.cpp:106] Iteration 11400, lr = 0.1
I0622 19:01:01.961840 33249 solver.cpp:228] Iteration 11600, loss = 1.19773
I0622 19:01:01.962043 33249 solver.cpp:244]     Train net output #0: loss = 1.19773 (* 1 = 1.19773 loss)
I0622 19:01:01.962059 33249 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0622 19:01:27.221910 33249 solver.cpp:228] Iteration 11800, loss = 1.14328
I0622 19:01:27.221958 33249 solver.cpp:244]     Train net output #0: loss = 1.14328 (* 1 = 1.14328 loss)
I0622 19:01:27.221969 33249 sgd_solver.cpp:106] Iteration 11800, lr = 0.1
I0622 19:01:52.443439 33249 solver.cpp:337] Iteration 12000, Testing net (#0)
I0622 19:01:56.337956 33249 solver.cpp:404]     Test net output #0: accuracy = 0.5154
I0622 19:01:56.338006 33249 solver.cpp:404]     Test net output #1: loss = 1.33692 (* 1 = 1.33692 loss)
I0622 19:01:56.379379 33249 solver.cpp:228] Iteration 12000, loss = 1.38033
I0622 19:01:56.379405 33249 solver.cpp:244]     Train net output #0: loss = 1.38033 (* 1 = 1.38033 loss)
I0622 19:01:56.379418 33249 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0622 19:02:21.543390 33249 solver.cpp:228] Iteration 12200, loss = 1.34678
I0622 19:02:21.543453 33249 solver.cpp:244]     Train net output #0: loss = 1.34678 (* 1 = 1.34678 loss)
I0622 19:02:21.543467 33249 sgd_solver.cpp:106] Iteration 12200, lr = 0.1
I0622 19:02:46.783720 33249 solver.cpp:228] Iteration 12400, loss = 1.11486
I0622 19:02:46.783929 33249 solver.cpp:244]     Train net output #0: loss = 1.11486 (* 1 = 1.11486 loss)
I0622 19:02:46.783962 33249 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0622 19:03:12.028375 33249 solver.cpp:228] Iteration 12600, loss = 1.03869
I0622 19:03:12.028427 33249 solver.cpp:244]     Train net output #0: loss = 1.03869 (* 1 = 1.03869 loss)
I0622 19:03:12.028439 33249 sgd_solver.cpp:106] Iteration 12600, lr = 0.1
I0622 19:03:37.272897 33249 solver.cpp:228] Iteration 12800, loss = 1.09734
I0622 19:03:37.273123 33249 solver.cpp:244]     Train net output #0: loss = 1.09734 (* 1 = 1.09734 loss)
I0622 19:03:37.273155 33249 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0622 19:04:02.466948 33249 solver.cpp:337] Iteration 13000, Testing net (#0)
I0622 19:04:06.342162 33249 solver.cpp:404]     Test net output #0: accuracy = 0.5264
I0622 19:04:06.342211 33249 solver.cpp:404]     Test net output #1: loss = 1.3246 (* 1 = 1.3246 loss)
I0622 19:04:06.383565 33249 solver.cpp:228] Iteration 13000, loss = 1.32183
I0622 19:04:06.383599 33249 solver.cpp:244]     Train net output #0: loss = 1.32183 (* 1 = 1.32183 loss)
I0622 19:04:06.383613 33249 sgd_solver.cpp:106] Iteration 13000, lr = 0.1
I0622 19:04:31.548426 33249 solver.cpp:228] Iteration 13200, loss = 1.13562
I0622 19:04:31.548635 33249 solver.cpp:244]     Train net output #0: loss = 1.13562 (* 1 = 1.13562 loss)
I0622 19:04:31.548650 33249 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0622 19:04:56.821152 33249 solver.cpp:228] Iteration 13400, loss = 1.08141
I0622 19:04:56.821202 33249 solver.cpp:244]     Train net output #0: loss = 1.08141 (* 1 = 1.08141 loss)
I0622 19:04:56.821213 33249 sgd_solver.cpp:106] Iteration 13400, lr = 0.1
I0622 19:05:22.086206 33249 solver.cpp:228] Iteration 13600, loss = 1.08225
I0622 19:05:22.086434 33249 solver.cpp:244]     Train net output #0: loss = 1.08225 (* 1 = 1.08225 loss)
I0622 19:05:22.086469 33249 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0622 19:05:47.352099 33249 solver.cpp:228] Iteration 13800, loss = 1.20499
I0622 19:05:47.352149 33249 solver.cpp:244]     Train net output #0: loss = 1.20499 (* 1 = 1.20499 loss)
I0622 19:05:47.352159 33249 sgd_solver.cpp:106] Iteration 13800, lr = 0.1
I0622 19:06:12.602253 33249 solver.cpp:337] Iteration 14000, Testing net (#0)
I0622 19:06:16.497198 33249 solver.cpp:404]     Test net output #0: accuracy = 0.5815
I0622 19:06:16.497249 33249 solver.cpp:404]     Test net output #1: loss = 1.19778 (* 1 = 1.19778 loss)
I0622 19:06:16.538800 33249 solver.cpp:228] Iteration 14000, loss = 1.1555
I0622 19:06:16.538835 33249 solver.cpp:244]     Train net output #0: loss = 1.1555 (* 1 = 1.1555 loss)
I0622 19:06:16.538848 33249 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0622 19:06:41.754242 33249 solver.cpp:228] Iteration 14200, loss = 1.14302
I0622 19:06:41.754292 33249 solver.cpp:244]     Train net output #0: loss = 1.14302 (* 1 = 1.14302 loss)
I0622 19:06:41.754302 33249 sgd_solver.cpp:106] Iteration 14200, lr = 0.1
I0622 19:07:07.000073 33249 solver.cpp:228] Iteration 14400, loss = 1.07753
I0622 19:07:07.000301 33249 solver.cpp:244]     Train net output #0: loss = 1.07753 (* 1 = 1.07753 loss)
I0622 19:07:07.000332 33249 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0622 19:07:32.233295 33249 solver.cpp:228] Iteration 14600, loss = 1.01336
I0622 19:07:32.233345 33249 solver.cpp:244]     Train net output #0: loss = 1.01336 (* 1 = 1.01336 loss)
I0622 19:07:32.233355 33249 sgd_solver.cpp:106] Iteration 14600, lr = 0.1
I0622 19:07:57.485260 33249 solver.cpp:228] Iteration 14800, loss = 1.1534
I0622 19:07:57.485538 33249 solver.cpp:244]     Train net output #0: loss = 1.1534 (* 1 = 1.1534 loss)
I0622 19:07:57.485559 33249 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0622 19:08:22.692936 33249 solver.cpp:337] Iteration 15000, Testing net (#0)
I0622 19:08:26.563767 33249 solver.cpp:404]     Test net output #0: accuracy = 0.5766
I0622 19:08:26.563817 33249 solver.cpp:404]     Test net output #1: loss = 1.18252 (* 1 = 1.18252 loss)
I0622 19:08:26.605269 33249 solver.cpp:228] Iteration 15000, loss = 1.12171
I0622 19:08:26.605301 33249 solver.cpp:244]     Train net output #0: loss = 1.12171 (* 1 = 1.12171 loss)
I0622 19:08:26.605314 33249 sgd_solver.cpp:106] Iteration 15000, lr = 0.1
I0622 19:08:51.776521 33249 solver.cpp:228] Iteration 15200, loss = 1.0484
I0622 19:08:51.776746 33249 solver.cpp:244]     Train net output #0: loss = 1.0484 (* 1 = 1.0484 loss)
I0622 19:08:51.776778 33249 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0622 19:09:17.094640 33249 solver.cpp:228] Iteration 15400, loss = 1.08768
I0622 19:09:17.094702 33249 solver.cpp:244]     Train net output #0: loss = 1.08768 (* 1 = 1.08768 loss)
I0622 19:09:17.094713 33249 sgd_solver.cpp:106] Iteration 15400, lr = 0.1
I0622 19:09:42.349581 33249 solver.cpp:228] Iteration 15600, loss = 1.00477
I0622 19:09:42.349773 33249 solver.cpp:244]     Train net output #0: loss = 1.00477 (* 1 = 1.00477 loss)
I0622 19:09:42.349786 33249 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0622 19:10:07.598506 33249 solver.cpp:228] Iteration 15800, loss = 1.22334
I0622 19:10:07.598563 33249 solver.cpp:244]     Train net output #0: loss = 1.22334 (* 1 = 1.22334 loss)
I0622 19:10:07.598574 33249 sgd_solver.cpp:106] Iteration 15800, lr = 0.1
I0622 19:10:32.851419 33249 solver.cpp:454] Snapshotting to binary proto file snapshots/res_ide16_iter_16000.caffemodel
I0622 19:10:32.912523 33249 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/res_ide16_iter_16000.solverstate
I0622 19:10:32.933149 33249 solver.cpp:337] Iteration 16000, Testing net (#0)
I0622 19:10:36.806310 33249 solver.cpp:404]     Test net output #0: accuracy = 0.5765
I0622 19:10:36.806360 33249 solver.cpp:404]     Test net output #1: loss = 1.17541 (* 1 = 1.17541 loss)
I0622 19:10:36.847683 33249 solver.cpp:228] Iteration 16000, loss = 1.10005
I0622 19:10:36.847710 33249 solver.cpp:244]     Train net output #0: loss = 1.10005 (* 1 = 1.10005 loss)
I0622 19:10:36.847723 33249 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0622 19:11:02.034157 33249 solver.cpp:228] Iteration 16200, loss = 1.04237
I0622 19:11:02.034209 33249 solver.cpp:244]     Train net output #0: loss = 1.04237 (* 1 = 1.04237 loss)
I0622 19:11:02.034221 33249 sgd_solver.cpp:106] Iteration 16200, lr = 0.1
I0622 19:11:27.278949 33249 solver.cpp:228] Iteration 16400, loss = 1.00661
I0622 19:11:27.279192 33249 solver.cpp:244]     Train net output #0: loss = 1.00661 (* 1 = 1.00661 loss)
I0622 19:11:27.279207 33249 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0622 19:11:52.521571 33249 solver.cpp:228] Iteration 16600, loss = 0.893879
I0622 19:11:52.521628 33249 solver.cpp:244]     Train net output #0: loss = 0.893879 (* 1 = 0.893879 loss)
I0622 19:11:52.521639 33249 sgd_solver.cpp:106] Iteration 16600, lr = 0.1
I0622 19:12:17.674124 33249 solver.cpp:228] Iteration 16800, loss = 0.997523
I0622 19:12:17.674346 33249 solver.cpp:244]     Train net output #0: loss = 0.997523 (* 1 = 0.997523 loss)
I0622 19:12:17.674362 33249 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0622 19:12:42.832535 33249 solver.cpp:337] Iteration 17000, Testing net (#0)
I0622 19:12:46.715123 33249 solver.cpp:404]     Test net output #0: accuracy = 0.5995
I0622 19:12:46.715173 33249 solver.cpp:404]     Test net output #1: loss = 1.11848 (* 1 = 1.11848 loss)
I0622 19:12:46.756546 33249 solver.cpp:228] Iteration 17000, loss = 1.01985
I0622 19:12:46.756577 33249 solver.cpp:244]     Train net output #0: loss = 1.01985 (* 1 = 1.01985 loss)
I0622 19:12:46.756592 33249 sgd_solver.cpp:106] Iteration 17000, lr = 0.1
I0622 19:13:11.927286 33249 solver.cpp:228] Iteration 17200, loss = 1.01358
I0622 19:13:11.927518 33249 solver.cpp:244]     Train net output #0: loss = 1.01358 (* 1 = 1.01358 loss)
I0622 19:13:11.927572 33249 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0622 19:13:37.121443 33249 solver.cpp:228] Iteration 17400, loss = 0.908354
I0622 19:13:37.121496 33249 solver.cpp:244]     Train net output #0: loss = 0.908354 (* 1 = 0.908354 loss)
I0622 19:13:37.121508 33249 sgd_solver.cpp:106] Iteration 17400, lr = 0.1
I0622 19:14:02.311930 33249 solver.cpp:228] Iteration 17600, loss = 0.876066
I0622 19:14:02.312150 33249 solver.cpp:244]     Train net output #0: loss = 0.876066 (* 1 = 0.876066 loss)
I0622 19:14:02.312165 33249 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0622 19:14:27.455981 33249 solver.cpp:228] Iteration 17800, loss = 1.023
I0622 19:14:27.456034 33249 solver.cpp:244]     Train net output #0: loss = 1.023 (* 1 = 1.023 loss)
I0622 19:14:27.456045 33249 sgd_solver.cpp:106] Iteration 17800, lr = 0.1
I0622 19:14:52.703692 33249 solver.cpp:337] Iteration 18000, Testing net (#0)
I0622 19:14:56.594029 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6084
I0622 19:14:56.594080 33249 solver.cpp:404]     Test net output #1: loss = 1.0891 (* 1 = 1.0891 loss)
I0622 19:14:56.635248 33249 solver.cpp:228] Iteration 18000, loss = 1.00967
I0622 19:14:56.635282 33249 solver.cpp:244]     Train net output #0: loss = 1.00967 (* 1 = 1.00967 loss)
I0622 19:14:56.635295 33249 sgd_solver.cpp:106] Iteration 18000, lr = 0.1
I0622 19:15:21.725097 33249 solver.cpp:228] Iteration 18200, loss = 1.11392
I0622 19:15:21.725144 33249 solver.cpp:244]     Train net output #0: loss = 1.11392 (* 1 = 1.11392 loss)
I0622 19:15:21.725154 33249 sgd_solver.cpp:106] Iteration 18200, lr = 0.1
I0622 19:15:46.960813 33249 solver.cpp:228] Iteration 18400, loss = 0.924942
I0622 19:15:46.961051 33249 solver.cpp:244]     Train net output #0: loss = 0.924942 (* 1 = 0.924942 loss)
I0622 19:15:46.961086 33249 sgd_solver.cpp:106] Iteration 18400, lr = 0.1
I0622 19:16:12.137045 33249 solver.cpp:228] Iteration 18600, loss = 0.775911
I0622 19:16:12.137096 33249 solver.cpp:244]     Train net output #0: loss = 0.775911 (* 1 = 0.775911 loss)
I0622 19:16:12.137106 33249 sgd_solver.cpp:106] Iteration 18600, lr = 0.1
I0622 19:16:37.298130 33249 solver.cpp:228] Iteration 18800, loss = 0.880153
I0622 19:16:37.298431 33249 solver.cpp:244]     Train net output #0: loss = 0.880153 (* 1 = 0.880153 loss)
I0622 19:16:37.298465 33249 sgd_solver.cpp:106] Iteration 18800, lr = 0.1
I0622 19:17:02.474304 33249 solver.cpp:337] Iteration 19000, Testing net (#0)
I0622 19:17:06.356288 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6186
I0622 19:17:06.356344 33249 solver.cpp:404]     Test net output #1: loss = 1.0804 (* 1 = 1.0804 loss)
I0622 19:17:06.397795 33249 solver.cpp:228] Iteration 19000, loss = 0.975496
I0622 19:17:06.397825 33249 solver.cpp:244]     Train net output #0: loss = 0.975496 (* 1 = 0.975496 loss)
I0622 19:17:06.397843 33249 sgd_solver.cpp:106] Iteration 19000, lr = 0.1
I0622 19:17:31.468771 33249 solver.cpp:228] Iteration 19200, loss = 1.04147
I0622 19:17:31.469002 33249 solver.cpp:244]     Train net output #0: loss = 1.04147 (* 1 = 1.04147 loss)
I0622 19:17:31.469035 33249 sgd_solver.cpp:106] Iteration 19200, lr = 0.1
I0622 19:17:56.662184 33249 solver.cpp:228] Iteration 19400, loss = 0.857049
I0622 19:17:56.662255 33249 solver.cpp:244]     Train net output #0: loss = 0.857049 (* 1 = 0.857049 loss)
I0622 19:17:56.662266 33249 sgd_solver.cpp:106] Iteration 19400, lr = 0.1
I0622 19:18:21.772681 33249 solver.cpp:228] Iteration 19600, loss = 0.816525
I0622 19:18:21.772879 33249 solver.cpp:244]     Train net output #0: loss = 0.816525 (* 1 = 0.816525 loss)
I0622 19:18:21.772893 33249 sgd_solver.cpp:106] Iteration 19600, lr = 0.1
I0622 19:18:46.986232 33249 solver.cpp:228] Iteration 19800, loss = 1.03107
I0622 19:18:46.986294 33249 solver.cpp:244]     Train net output #0: loss = 1.03107 (* 1 = 1.03107 loss)
I0622 19:18:46.986304 33249 sgd_solver.cpp:106] Iteration 19800, lr = 0.1
I0622 19:19:12.048513 33249 solver.cpp:337] Iteration 20000, Testing net (#0)
I0622 19:19:15.958745 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6475
I0622 19:19:15.958793 33249 solver.cpp:404]     Test net output #1: loss = 0.991158 (* 1 = 0.991158 loss)
I0622 19:19:16.000766 33249 solver.cpp:228] Iteration 20000, loss = 0.876162
I0622 19:19:16.000792 33249 solver.cpp:244]     Train net output #0: loss = 0.876162 (* 1 = 0.876162 loss)
I0622 19:19:16.000805 33249 sgd_solver.cpp:106] Iteration 20000, lr = 0.1
I0622 19:19:41.235769 33249 solver.cpp:228] Iteration 20200, loss = 1.05377
I0622 19:19:41.235829 33249 solver.cpp:244]     Train net output #0: loss = 1.05377 (* 1 = 1.05377 loss)
I0622 19:19:41.235842 33249 sgd_solver.cpp:106] Iteration 20200, lr = 0.1
I0622 19:20:06.501293 33249 solver.cpp:228] Iteration 20400, loss = 0.818484
I0622 19:20:06.501612 33249 solver.cpp:244]     Train net output #0: loss = 0.818484 (* 1 = 0.818484 loss)
I0622 19:20:06.501685 33249 sgd_solver.cpp:106] Iteration 20400, lr = 0.1
I0622 19:20:31.805193 33249 solver.cpp:228] Iteration 20600, loss = 0.714981
I0622 19:20:31.805244 33249 solver.cpp:244]     Train net output #0: loss = 0.714981 (* 1 = 0.714981 loss)
I0622 19:20:31.805255 33249 sgd_solver.cpp:106] Iteration 20600, lr = 0.1
I0622 19:20:57.098510 33249 solver.cpp:228] Iteration 20800, loss = 1.06238
I0622 19:20:57.098798 33249 solver.cpp:244]     Train net output #0: loss = 1.06238 (* 1 = 1.06238 loss)
I0622 19:20:57.098819 33249 sgd_solver.cpp:106] Iteration 20800, lr = 0.1
I0622 19:21:22.367216 33249 solver.cpp:337] Iteration 21000, Testing net (#0)
I0622 19:21:26.273429 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6296
I0622 19:21:26.273481 33249 solver.cpp:404]     Test net output #1: loss = 1.04167 (* 1 = 1.04167 loss)
I0622 19:21:26.314522 33249 solver.cpp:228] Iteration 21000, loss = 1.10064
I0622 19:21:26.314553 33249 solver.cpp:244]     Train net output #0: loss = 1.10064 (* 1 = 1.10064 loss)
I0622 19:21:26.314579 33249 sgd_solver.cpp:106] Iteration 21000, lr = 0.1
I0622 19:21:51.508234 33249 solver.cpp:228] Iteration 21200, loss = 1.01181
I0622 19:21:51.508524 33249 solver.cpp:244]     Train net output #0: loss = 1.01181 (* 1 = 1.01181 loss)
I0622 19:21:51.508541 33249 sgd_solver.cpp:106] Iteration 21200, lr = 0.1
I0622 19:22:16.791296 33249 solver.cpp:228] Iteration 21400, loss = 0.745193
I0622 19:22:16.791350 33249 solver.cpp:244]     Train net output #0: loss = 0.745193 (* 1 = 0.745193 loss)
I0622 19:22:16.791363 33249 sgd_solver.cpp:106] Iteration 21400, lr = 0.1
I0622 19:22:42.033156 33249 solver.cpp:228] Iteration 21600, loss = 0.754804
I0622 19:22:42.033439 33249 solver.cpp:244]     Train net output #0: loss = 0.754804 (* 1 = 0.754804 loss)
I0622 19:22:42.033473 33249 sgd_solver.cpp:106] Iteration 21600, lr = 0.1
I0622 19:23:07.305074 33249 solver.cpp:228] Iteration 21800, loss = 0.814444
I0622 19:23:07.305130 33249 solver.cpp:244]     Train net output #0: loss = 0.814444 (* 1 = 0.814444 loss)
I0622 19:23:07.305141 33249 sgd_solver.cpp:106] Iteration 21800, lr = 0.1
I0622 19:23:32.523073 33249 solver.cpp:337] Iteration 22000, Testing net (#0)
I0622 19:23:36.425385 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6214
I0622 19:23:36.425436 33249 solver.cpp:404]     Test net output #1: loss = 1.07955 (* 1 = 1.07955 loss)
I0622 19:23:36.467241 33249 solver.cpp:228] Iteration 22000, loss = 0.965177
I0622 19:23:36.467267 33249 solver.cpp:244]     Train net output #0: loss = 0.965177 (* 1 = 0.965177 loss)
I0622 19:23:36.467280 33249 sgd_solver.cpp:106] Iteration 22000, lr = 0.1
I0622 19:24:01.725703 33249 solver.cpp:228] Iteration 22200, loss = 0.919208
I0622 19:24:01.725759 33249 solver.cpp:244]     Train net output #0: loss = 0.919208 (* 1 = 0.919208 loss)
I0622 19:24:01.725770 33249 sgd_solver.cpp:106] Iteration 22200, lr = 0.1
I0622 19:24:27.000825 33249 solver.cpp:228] Iteration 22400, loss = 0.742938
I0622 19:24:27.001078 33249 solver.cpp:244]     Train net output #0: loss = 0.742938 (* 1 = 0.742938 loss)
I0622 19:24:27.001113 33249 sgd_solver.cpp:106] Iteration 22400, lr = 0.1
I0622 19:24:52.270136 33249 solver.cpp:228] Iteration 22600, loss = 0.677212
I0622 19:24:52.270192 33249 solver.cpp:244]     Train net output #0: loss = 0.677212 (* 1 = 0.677212 loss)
I0622 19:24:52.270205 33249 sgd_solver.cpp:106] Iteration 22600, lr = 0.1
I0622 19:25:17.623177 33249 solver.cpp:228] Iteration 22800, loss = 0.905063
I0622 19:25:17.623503 33249 solver.cpp:244]     Train net output #0: loss = 0.905063 (* 1 = 0.905063 loss)
I0622 19:25:17.623574 33249 sgd_solver.cpp:106] Iteration 22800, lr = 0.1
I0622 19:25:42.853677 33249 solver.cpp:337] Iteration 23000, Testing net (#0)
I0622 19:25:46.765513 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6491
I0622 19:25:46.765563 33249 solver.cpp:404]     Test net output #1: loss = 0.979885 (* 1 = 0.979885 loss)
I0622 19:25:46.807155 33249 solver.cpp:228] Iteration 23000, loss = 0.87524
I0622 19:25:46.807191 33249 solver.cpp:244]     Train net output #0: loss = 0.87524 (* 1 = 0.87524 loss)
I0622 19:25:46.807205 33249 sgd_solver.cpp:106] Iteration 23000, lr = 0.1
I0622 19:26:11.956542 33249 solver.cpp:228] Iteration 23200, loss = 0.899274
I0622 19:26:11.956830 33249 solver.cpp:244]     Train net output #0: loss = 0.899274 (* 1 = 0.899274 loss)
I0622 19:26:11.956883 33249 sgd_solver.cpp:106] Iteration 23200, lr = 0.1
I0622 19:26:37.258124 33249 solver.cpp:228] Iteration 23400, loss = 0.691854
I0622 19:26:37.258182 33249 solver.cpp:244]     Train net output #0: loss = 0.691854 (* 1 = 0.691854 loss)
I0622 19:26:37.258193 33249 sgd_solver.cpp:106] Iteration 23400, lr = 0.1
I0622 19:27:02.448685 33249 solver.cpp:228] Iteration 23600, loss = 0.716637
I0622 19:27:02.448853 33249 solver.cpp:244]     Train net output #0: loss = 0.716637 (* 1 = 0.716637 loss)
I0622 19:27:02.448866 33249 sgd_solver.cpp:106] Iteration 23600, lr = 0.1
I0622 19:27:27.749097 33249 solver.cpp:228] Iteration 23800, loss = 0.973684
I0622 19:27:27.749146 33249 solver.cpp:244]     Train net output #0: loss = 0.973684 (* 1 = 0.973684 loss)
I0622 19:27:27.749158 33249 sgd_solver.cpp:106] Iteration 23800, lr = 0.1
I0622 19:27:52.885612 33249 solver.cpp:337] Iteration 24000, Testing net (#0)
I0622 19:27:56.750488 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6717
I0622 19:27:56.750542 33249 solver.cpp:404]     Test net output #1: loss = 0.944331 (* 1 = 0.944331 loss)
I0622 19:27:56.792048 33249 solver.cpp:228] Iteration 24000, loss = 0.873006
I0622 19:27:56.792084 33249 solver.cpp:244]     Train net output #0: loss = 0.873006 (* 1 = 0.873006 loss)
I0622 19:27:56.792101 33249 sgd_solver.cpp:106] Iteration 24000, lr = 0.1
I0622 19:28:21.959297 33249 solver.cpp:228] Iteration 24200, loss = 1.00354
I0622 19:28:21.959348 33249 solver.cpp:244]     Train net output #0: loss = 1.00354 (* 1 = 1.00354 loss)
I0622 19:28:21.959359 33249 sgd_solver.cpp:106] Iteration 24200, lr = 0.1
I0622 19:28:47.176231 33249 solver.cpp:228] Iteration 24400, loss = 0.742941
I0622 19:28:47.176542 33249 solver.cpp:244]     Train net output #0: loss = 0.742941 (* 1 = 0.742941 loss)
I0622 19:28:47.176556 33249 sgd_solver.cpp:106] Iteration 24400, lr = 0.1
I0622 19:29:12.392822 33249 solver.cpp:228] Iteration 24600, loss = 0.679339
I0622 19:29:12.392887 33249 solver.cpp:244]     Train net output #0: loss = 0.679339 (* 1 = 0.679339 loss)
I0622 19:29:12.392899 33249 sgd_solver.cpp:106] Iteration 24600, lr = 0.1
I0622 19:29:37.604931 33249 solver.cpp:228] Iteration 24800, loss = 0.790835
I0622 19:29:37.605273 33249 solver.cpp:244]     Train net output #0: loss = 0.790835 (* 1 = 0.790835 loss)
I0622 19:29:37.605352 33249 sgd_solver.cpp:106] Iteration 24800, lr = 0.1
I0622 19:30:02.708003 33249 solver.cpp:337] Iteration 25000, Testing net (#0)
I0622 19:30:06.597254 33249 solver.cpp:404]     Test net output #0: accuracy = 0.7024
I0622 19:30:06.597306 33249 solver.cpp:404]     Test net output #1: loss = 0.853948 (* 1 = 0.853948 loss)
I0622 19:30:06.638226 33249 solver.cpp:228] Iteration 25000, loss = 0.814059
I0622 19:30:06.638258 33249 solver.cpp:244]     Train net output #0: loss = 0.814059 (* 1 = 0.814059 loss)
I0622 19:30:06.638272 33249 sgd_solver.cpp:106] Iteration 25000, lr = 0.1
I0622 19:30:31.734068 33249 solver.cpp:228] Iteration 25200, loss = 0.932524
I0622 19:30:31.734292 33249 solver.cpp:244]     Train net output #0: loss = 0.932524 (* 1 = 0.932524 loss)
I0622 19:30:31.734307 33249 sgd_solver.cpp:106] Iteration 25200, lr = 0.1
I0622 19:30:56.995164 33249 solver.cpp:228] Iteration 25400, loss = 0.636274
I0622 19:30:56.995225 33249 solver.cpp:244]     Train net output #0: loss = 0.636274 (* 1 = 0.636274 loss)
I0622 19:30:56.995237 33249 sgd_solver.cpp:106] Iteration 25400, lr = 0.1
I0622 19:31:22.138506 33249 solver.cpp:228] Iteration 25600, loss = 0.52683
I0622 19:31:22.138759 33249 solver.cpp:244]     Train net output #0: loss = 0.52683 (* 1 = 0.52683 loss)
I0622 19:31:22.138792 33249 sgd_solver.cpp:106] Iteration 25600, lr = 0.1
I0622 19:31:47.437368 33249 solver.cpp:228] Iteration 25800, loss = 0.714153
I0622 19:31:47.437424 33249 solver.cpp:244]     Train net output #0: loss = 0.714153 (* 1 = 0.714153 loss)
I0622 19:31:47.437435 33249 sgd_solver.cpp:106] Iteration 25800, lr = 0.1
I0622 19:32:12.559837 33249 solver.cpp:337] Iteration 26000, Testing net (#0)
I0622 19:32:16.452188 33249 solver.cpp:404]     Test net output #0: accuracy = 0.6716
I0622 19:32:16.452244 33249 solver.cpp:404]     Test net output #1: loss = 0.938837 (* 1 = 0.938837 loss)
I0622 19:32:16.493988 33249 solver.cpp:228] Iteration 26000, loss = 0.853355
I0622 19:32:16.494022 33249 solver.cpp:244]     Train net output #0: loss = 0.853355 (* 1 = 0.853355 loss)
I0622 19:32:16.494037 33249 sgd_solver.cpp:106] Iteration 26000, lr = 0.1
I0622 19:32:41.604339 33249 solver.cpp:228] Iteration 26200, loss = 0.833326
I0622 19:32:41.604390 33249 solver.cpp:244]     Train net output #0: loss = 0.833326 (* 1 = 0.833326 loss)
I0622 19:32:41.604400 33249 sgd_solver.cpp:106] Iteration 26200, lr = 0.1
I0622 19:33:06.823784 33249 solver.cpp:228] Iteration 26400, loss = 0.633573
I0622 19:33:06.824158 33249 solver.cpp:244]     Train net output #0: loss = 0.633573 (* 1 = 0.633573 loss)
I0622 19:33:06.824214 33249 sgd_solver.cpp:106] Iteration 26400, lr = 0.1
I0622 19:33:31.951740 33249 solver.cpp:228] Iteration 26600, loss = 0.574779
I0622 19:33:31.951799 33249 solver.cpp:244]     Train net output #0: loss = 0.574779 (* 1 = 0.574779 loss)
I0622 19:33:31.951810 33249 sgd_solver.cpp:106] Iteration 26600, lr = 0.1
I0622 19:33:57.124583 33249 solver.cpp:228] Iteration 26800, loss = 0.759603
I0622 19:33:57.124995 33249 solver.cpp:244]     Train net output #0: loss = 0.759603 (* 1 = 0.759603 loss)
I0622 19:33:57.125046 33249 sgd_solver.cpp:106] Iteration 26800, lr = 0.1
I0622 19:34:22.244196 33249 solver.cpp:337] Iteration 27000, Testing net (#0)
I0622 19:34:26.123791 33249 solver.cpp:404]     Test net output #0: accuracy = 0.7225
I0622 19:34:26.123847 33249 solver.cpp:404]     Test net output #1: loss = 0.802526 (* 1 = 0.802526 loss)
I0622 19:34:26.165505 33249 solver.cpp:228] Iteration 27000, loss = 0.637089
I0622 19:34:26.165539 33249 solver.cpp:244]     Train net output #0: loss = 0.637089 (* 1 = 0.637089 loss)
I0622 19:34:26.165555 33249 sgd_solver.cpp:106] Iteration 27000, lr = 0.1
I0622 19:34:51.245944 33249 solver.cpp:228] Iteration 27200, loss = 0.71611
I0622 19:34:51.246189 33249 solver.cpp:244]     Train net output #0: loss = 0.71611 (* 1 = 0.71611 loss)
I0622 19:34:51.246224 33249 sgd_solver.cpp:106] Iteration 27200, lr = 0.1
I0622 19:35:16.475193 33249 solver.cpp:228] Iteration 27400, loss = 0.652213
I0622 19:35:16.475272 33249 solver.cpp:244]     Train net output #0: loss = 0.652213 (* 1 = 0.652213 loss)
I0622 19:35:16.475286 33249 sgd_solver.cpp:106] Iteration 27400, lr = 0.1
I0622 19:35:41.684582 33249 solver.cpp:228] Iteration 27600, loss = 0.585262
I0622 19:35:41.684782 33249 solver.cpp:244]     Train net output #0: loss = 0.585262 (* 1 = 0.585262 loss)
I0622 19:35:41.684798 33249 sgd_solver.cpp:106] Iteration 27600, lr = 0.1
