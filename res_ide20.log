I0622 19:43:11.392314 36972 caffe.cpp:185] Using GPUs 0
I0622 19:43:11.853521 36972 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0622 19:43:12.153888 36972 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 200
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 16000
snapshot_prefix: "snapshots/res_ide20"
solver_mode: GPU
device_id: 0
net: "./res_ide20_train_test.prototxt"
stepvalue: 32000
stepvalue: 48000
I0622 19:43:12.154068 36972 solver.cpp:91] Creating training net from net file: ./res_ide20_train_test.prototxt
I0622 19:43:12.156489 36972 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer resnet
I0622 19:43:12.156571 36972 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0622 19:43:12.157069 36972 net.cpp:49] Initializing net from parameters: 
name: "ResNet"
state {
  phase: TRAIN
}
layer {
  name: "resnet"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "/home/takeki/caffe/examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/takeki/caffe/examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_1"
  type: "BatchNorm"
  bottom: "conv0"
  top: "bn_a_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_1"
  type: "ReLU"
  bottom: "bn_a_1_1"
  top: "relu_a_1_1"
}
layer {
  name: "conv_a_1_1"
  type: "Convolution"
  bottom: "relu_a_1_1"
  top: "conv_a_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_2"
  type: "BatchNorm"
  bottom: "conv_a_1_1"
  top: "bn_a_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_2"
  type: "ReLU"
  bottom: "bn_a_1_2"
  top: "relu_a_1_2"
}
layer {
  name: "conv_a_1_2"
  type: "Convolution"
  bottom: "relu_a_1_2"
  top: "conv_a_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_a"
  type: "Convolution"
  bottom: "conv0"
  top: "res_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_1"
  type: "Eltwise"
  bottom: "res_a"
  bottom: "conv_a_1_2"
  top: "elt_a_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_a_2_1"
  type: "BatchNorm"
  bottom: "elt_a_1"
  top: "bn_a_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_1"
  type: "ReLU"
  bottom: "bn_a_2_1"
  top: "relu_a_2_1"
}
layer {
  name: "conv_a_2_1"
  type: "Convolution"
  bottom: "relu_a_2_1"
  top: "conv_a_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_2_2"
  type: "BatchNorm"
  bottom: "conv_a_2_1"
  top: "bn_a_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_2"
  type: "ReLU"
  bottom: "bn_a_2_2"
  top: "relu_a_2_2"
}
layer {
  name: "conv_a_2_2"
  type: "Convolution"
  bottom: "relu_a_2_2"
  top: "conv_a_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_2"
  type: "Eltwise"
  bottom: "elt_a_1"
  bottom: "conv_a_2_2"
  top: "elt_a_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_a_3_1"
  type: "BatchNorm"
  bottom: "elt_a_2"
  top: "bn_a_3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_3_1"
  type: "ReLU"
  bottom: "bn_a_3_1"
  top: "relu_a_3_1"
}
layer {
  name: "conv_a_3_1"
  type: "Convolution"
  bottom: "relu_a_3_1"
  top: "conv_a_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_3_2"
  type: "BatchNorm"
  bottom: "conv_a_3_1"
  top: "bn_a_3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_3_2"
  type: "ReLU"
  bottom: "bn_a_3_2"
  top: "relu_a_3_2"
}
layer {
  name: "conv_a_3_2"
  type: "Convolution"
  bottom: "relu_a_3_2"
  top: "conv_a_3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_3"
  type: "Eltwise"
  bottom: "elt_a_2"
  bottom: "conv_a_3_2"
  top: "elt_a_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_1_1"
  type: "BatchNorm"
  bottom: "elt_a_3"
  top: "bn_d_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_1"
  type: "ReLU"
  bottom: "bn_d_1_1"
  top: "relu_d_1_1"
}
layer {
  name: "conv_d_1_1"
  type: "Convolution"
  bottom: "relu_d_1_1"
  top: "conv_d_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_1_2"
  type: "BatchNorm"
  bottom: "conv_d_1_1"
  top: "bn_d_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_2"
  type: "ReLU"
  bottom: "bn_d_1_2"
  top: "relu_d_1_2"
}
layer {
  name: "conv_d_1_2"
  type: "Convolution"
  bottom: "relu_d_1_2"
  top: "conv_d_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_d"
  type: "Convolution"
  bottom: "elt_a_3"
  top: "res_d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_1"
  type: "Eltwise"
  bottom: "res_d"
  bottom: "conv_d_1_2"
  top: "elt_d_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_2_1"
  type: "BatchNorm"
  bottom: "elt_d_1"
  top: "bn_d_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_1"
  type: "ReLU"
  bottom: "bn_d_2_1"
  top: "relu_d_2_1"
}
layer {
  name: "conv_d_2_1"
  type: "Convolution"
  bottom: "relu_d_2_1"
  top: "conv_d_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_2_2"
  type: "BatchNorm"
  bottom: "conv_d_2_1"
  top: "bn_d_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_2"
  type: "ReLU"
  bottom: "bn_d_2_2"
  top: "relu_d_2_2"
}
layer {
  name: "conv_d_2_2"
  type: "Convolution"
  bottom: "relu_d_2_2"
  top: "conv_d_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_2"
  type: "Eltwise"
  bottom: "elt_d_1"
  bottom: "conv_d_2_2"
  top: "elt_d_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_3_1"
  type: "BatchNorm"
  bottom: "elt_d_2"
  top: "bn_d_3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_3_1"
  type: "ReLU"
  bottom: "bn_d_3_1"
  top: "relu_d_3_1"
}
layer {
  name: "conv_d_3_1"
  type: "Convolution"
  bottom: "relu_d_3_1"
  top: "conv_d_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_3_2"
  type: "BatchNorm"
  bottom: "conv_d_3_1"
  top: "bn_d_3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_3_2"
  type: "ReLU"
  bottom: "bn_d_3_2"
  top: "relu_d_3_2"
}
layer {
  name: "conv_d_3_2"
  type: "Convolution"
  bottom: "relu_d_3_2"
  top: "conv_d_3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_3"
  type: "Eltwise"
  bottom: "elt_d_2"
  bottom: "conv_d_3_2"
  top: "elt_d_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_1_1"
  type: "BatchNorm"
  bottom: "elt_d_3"
  top: "bn_j_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_1"
  type: "ReLU"
  bottom: "bn_j_1_1"
  top: "relu_j_1_1"
}
layer {
  name: "conv_j_1_1"
  type: "Convolution"
  bottom: "relu_j_1_1"
  top: "conv_j_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_1_2"
  type: "BatchNorm"
  bottom: "conv_j_1_1"
  top: "bn_j_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_2"
  type: "ReLU"
  bottom: "bn_j_1_2"
  top: "relu_j_1_2"
}
layer {
  name: "conv_j_1_2"
  type: "Convolution"
  bottom: "relu_j_1_2"
  top: "conv_j_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_j"
  type: "Convolution"
  bottom: "elt_d_3"
  top: "res_j"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_1"
  type: "Eltwise"
  bottom: "res_j"
  bottom: "conv_j_1_2"
  top: "elt_j_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_2_1"
  type: "BatchNorm"
  bottom: "elt_j_1"
  top: "bn_j_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_1"
  type: "ReLU"
  bottom: "bn_j_2_1"
  top: "relu_j_2_1"
}
layer {
  name: "conv_j_2_1"
  type: "Convolution"
  bottom: "relu_j_2_1"
  top: "conv_j_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_2_2"
  type: "BatchNorm"
  bottom: "conv_j_2_1"
  top: "bn_j_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_2"
  type: "ReLU"
  bottom: "bn_j_2_2"
  top: "relu_j_2_2"
}
layer {
  name: "conv_j_2_2"
  type: "Convolution"
  bottom: "relu_j_2_2"
  top: "conv_j_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_2"
  type: "Eltwise"
  bottom: "elt_j_1"
  bottom: "conv_j_2_2"
  top: "elt_j_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_3_1"
  type: "BatchNorm"
  bottom: "elt_j_2"
  top: "bn_j_3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_3_1"
  type: "ReLU"
  bottom: "bn_j_3_1"
  top: "relu_j_3_1"
}
layer {
  name: "conv_j_3_1"
  type: "Convolution"
  bottom: "relu_j_3_1"
  top: "conv_j_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_3_2"
  type: "BatchNorm"
  bottom: "conv_j_3_1"
  top: "bn_j_3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_3_2"
  type: "ReLU"
  bottom: "bn_j_3_2"
  top: "relu_j_3_2"
}
layer {
  name: "conv_j_3_2"
  type: "Convolution"
  bottom: "relu_j_3_2"
  top: "conv_j_3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_3"
  type: "Eltwise"
  bottom: "elt_j_2"
  bottom: "conv_j_3_2"
  top: "elt_j_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_m_1_1"
  type: "BatchNorm"
  bottom: "elt_j_3"
  top: "bn_m_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_m_1_1"
  type: "ReLU"
  bottom: "bn_m_1_1"
  top: "relu_m_1_1"
}
layer {
  name: "gap"
  type: "Pooling"
  bottom: "relu_m_1_1"
  top: "gap"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "gap"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0622 19:43:12.157547 36972 layer_factory.hpp:77] Creating layer resnet
I0622 19:43:12.158148 36972 net.cpp:91] Creating Layer resnet
I0622 19:43:12.158165 36972 net.cpp:399] resnet -> data
I0622 19:43:12.158210 36972 net.cpp:399] resnet -> label
I0622 19:43:12.158231 36972 data_transformer.cpp:25] Loading mean file from: /home/takeki/caffe/examples/cifar10/mean.binaryproto
I0622 19:43:12.159068 37017 db_lmdb.cpp:35] Opened lmdb /home/takeki/caffe/examples/cifar10/cifar10_train_lmdb
I0622 19:43:12.173434 36972 data_layer.cpp:41] output data size: 100,3,32,32
I0622 19:43:12.176362 36972 net.cpp:141] Setting up resnet
I0622 19:43:12.176389 36972 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0622 19:43:12.176399 36972 net.cpp:148] Top shape: 100 (100)
I0622 19:43:12.176405 36972 net.cpp:156] Memory required for data: 1229200
I0622 19:43:12.176416 36972 layer_factory.hpp:77] Creating layer conv0
I0622 19:43:12.176450 36972 net.cpp:91] Creating Layer conv0
I0622 19:43:12.176461 36972 net.cpp:425] conv0 <- data
I0622 19:43:12.176484 36972 net.cpp:399] conv0 -> conv0
I0622 19:43:12.390256 36972 net.cpp:141] Setting up conv0
I0622 19:43:12.390303 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.390311 36972 net.cpp:156] Memory required for data: 7782800
I0622 19:43:12.390339 36972 layer_factory.hpp:77] Creating layer conv0_conv0_0_split
I0622 19:43:12.390368 36972 net.cpp:91] Creating Layer conv0_conv0_0_split
I0622 19:43:12.390377 36972 net.cpp:425] conv0_conv0_0_split <- conv0
I0622 19:43:12.390388 36972 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_0
I0622 19:43:12.390411 36972 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_1
I0622 19:43:12.390465 36972 net.cpp:141] Setting up conv0_conv0_0_split
I0622 19:43:12.390478 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.390488 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.390496 36972 net.cpp:156] Memory required for data: 20890000
I0622 19:43:12.390502 36972 layer_factory.hpp:77] Creating layer bn_a_1_1
I0622 19:43:12.390516 36972 net.cpp:91] Creating Layer bn_a_1_1
I0622 19:43:12.390523 36972 net.cpp:425] bn_a_1_1 <- conv0_conv0_0_split_0
I0622 19:43:12.390532 36972 net.cpp:399] bn_a_1_1 -> bn_a_1_1
I0622 19:43:12.390746 36972 net.cpp:141] Setting up bn_a_1_1
I0622 19:43:12.390761 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.390769 36972 net.cpp:156] Memory required for data: 27443600
I0622 19:43:12.390785 36972 layer_factory.hpp:77] Creating layer relu_a_1_1
I0622 19:43:12.390799 36972 net.cpp:91] Creating Layer relu_a_1_1
I0622 19:43:12.390808 36972 net.cpp:425] relu_a_1_1 <- bn_a_1_1
I0622 19:43:12.390818 36972 net.cpp:399] relu_a_1_1 -> relu_a_1_1
I0622 19:43:12.391149 36972 net.cpp:141] Setting up relu_a_1_1
I0622 19:43:12.391166 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.391175 36972 net.cpp:156] Memory required for data: 33997200
I0622 19:43:12.391183 36972 layer_factory.hpp:77] Creating layer conv_a_1_1
I0622 19:43:12.391203 36972 net.cpp:91] Creating Layer conv_a_1_1
I0622 19:43:12.391211 36972 net.cpp:425] conv_a_1_1 <- relu_a_1_1
I0622 19:43:12.391221 36972 net.cpp:399] conv_a_1_1 -> conv_a_1_1
I0622 19:43:12.392915 36972 net.cpp:141] Setting up conv_a_1_1
I0622 19:43:12.392961 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.392969 36972 net.cpp:156] Memory required for data: 60211600
I0622 19:43:12.392981 36972 layer_factory.hpp:77] Creating layer bn_a_1_2
I0622 19:43:12.392992 36972 net.cpp:91] Creating Layer bn_a_1_2
I0622 19:43:12.393000 36972 net.cpp:425] bn_a_1_2 <- conv_a_1_1
I0622 19:43:12.393009 36972 net.cpp:399] bn_a_1_2 -> bn_a_1_2
I0622 19:43:12.393209 36972 net.cpp:141] Setting up bn_a_1_2
I0622 19:43:12.393224 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.393234 36972 net.cpp:156] Memory required for data: 86426000
I0622 19:43:12.393249 36972 layer_factory.hpp:77] Creating layer relu_a_1_2
I0622 19:43:12.393257 36972 net.cpp:91] Creating Layer relu_a_1_2
I0622 19:43:12.393263 36972 net.cpp:425] relu_a_1_2 <- bn_a_1_2
I0622 19:43:12.393271 36972 net.cpp:399] relu_a_1_2 -> relu_a_1_2
I0622 19:43:12.393587 36972 net.cpp:141] Setting up relu_a_1_2
I0622 19:43:12.393605 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.393611 36972 net.cpp:156] Memory required for data: 112640400
I0622 19:43:12.393618 36972 layer_factory.hpp:77] Creating layer conv_a_1_2
I0622 19:43:12.393633 36972 net.cpp:91] Creating Layer conv_a_1_2
I0622 19:43:12.393640 36972 net.cpp:425] conv_a_1_2 <- relu_a_1_2
I0622 19:43:12.393649 36972 net.cpp:399] conv_a_1_2 -> conv_a_1_2
I0622 19:43:12.396350 36972 net.cpp:141] Setting up conv_a_1_2
I0622 19:43:12.396370 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.396378 36972 net.cpp:156] Memory required for data: 138854800
I0622 19:43:12.396387 36972 layer_factory.hpp:77] Creating layer res_a
I0622 19:43:12.396401 36972 net.cpp:91] Creating Layer res_a
I0622 19:43:12.396409 36972 net.cpp:425] res_a <- conv0_conv0_0_split_1
I0622 19:43:12.396422 36972 net.cpp:399] res_a -> res_a
I0622 19:43:12.397457 36972 net.cpp:141] Setting up res_a
I0622 19:43:12.397481 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.397495 36972 net.cpp:156] Memory required for data: 165069200
I0622 19:43:12.397516 36972 layer_factory.hpp:77] Creating layer elt_a_1
I0622 19:43:12.397559 36972 net.cpp:91] Creating Layer elt_a_1
I0622 19:43:12.397574 36972 net.cpp:425] elt_a_1 <- res_a
I0622 19:43:12.397589 36972 net.cpp:425] elt_a_1 <- conv_a_1_2
I0622 19:43:12.397610 36972 net.cpp:399] elt_a_1 -> elt_a_1
I0622 19:43:12.397653 36972 net.cpp:141] Setting up elt_a_1
I0622 19:43:12.397667 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.397676 36972 net.cpp:156] Memory required for data: 191283600
I0622 19:43:12.397682 36972 layer_factory.hpp:77] Creating layer elt_a_1_elt_a_1_0_split
I0622 19:43:12.397691 36972 net.cpp:91] Creating Layer elt_a_1_elt_a_1_0_split
I0622 19:43:12.397697 36972 net.cpp:425] elt_a_1_elt_a_1_0_split <- elt_a_1
I0622 19:43:12.397706 36972 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_0
I0622 19:43:12.397718 36972 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_1
I0622 19:43:12.397759 36972 net.cpp:141] Setting up elt_a_1_elt_a_1_0_split
I0622 19:43:12.397773 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.397783 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.397788 36972 net.cpp:156] Memory required for data: 243712400
I0622 19:43:12.397794 36972 layer_factory.hpp:77] Creating layer bn_a_2_1
I0622 19:43:12.397804 36972 net.cpp:91] Creating Layer bn_a_2_1
I0622 19:43:12.397811 36972 net.cpp:425] bn_a_2_1 <- elt_a_1_elt_a_1_0_split_0
I0622 19:43:12.397821 36972 net.cpp:399] bn_a_2_1 -> bn_a_2_1
I0622 19:43:12.398082 36972 net.cpp:141] Setting up bn_a_2_1
I0622 19:43:12.398104 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.398118 36972 net.cpp:156] Memory required for data: 269926800
I0622 19:43:12.398149 36972 layer_factory.hpp:77] Creating layer relu_a_2_1
I0622 19:43:12.398169 36972 net.cpp:91] Creating Layer relu_a_2_1
I0622 19:43:12.398182 36972 net.cpp:425] relu_a_2_1 <- bn_a_2_1
I0622 19:43:12.398200 36972 net.cpp:399] relu_a_2_1 -> relu_a_2_1
I0622 19:43:12.398483 36972 net.cpp:141] Setting up relu_a_2_1
I0622 19:43:12.398500 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.398510 36972 net.cpp:156] Memory required for data: 296141200
I0622 19:43:12.398517 36972 layer_factory.hpp:77] Creating layer conv_a_2_1
I0622 19:43:12.398530 36972 net.cpp:91] Creating Layer conv_a_2_1
I0622 19:43:12.398540 36972 net.cpp:425] conv_a_2_1 <- relu_a_2_1
I0622 19:43:12.398551 36972 net.cpp:399] conv_a_2_1 -> conv_a_2_1
I0622 19:43:12.400724 36972 net.cpp:141] Setting up conv_a_2_1
I0622 19:43:12.400744 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.400753 36972 net.cpp:156] Memory required for data: 322355600
I0622 19:43:12.400764 36972 layer_factory.hpp:77] Creating layer bn_a_2_2
I0622 19:43:12.400775 36972 net.cpp:91] Creating Layer bn_a_2_2
I0622 19:43:12.400781 36972 net.cpp:425] bn_a_2_2 <- conv_a_2_1
I0622 19:43:12.400791 36972 net.cpp:399] bn_a_2_2 -> bn_a_2_2
I0622 19:43:12.400992 36972 net.cpp:141] Setting up bn_a_2_2
I0622 19:43:12.401007 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.401016 36972 net.cpp:156] Memory required for data: 348570000
I0622 19:43:12.401028 36972 layer_factory.hpp:77] Creating layer relu_a_2_2
I0622 19:43:12.401041 36972 net.cpp:91] Creating Layer relu_a_2_2
I0622 19:43:12.401049 36972 net.cpp:425] relu_a_2_2 <- bn_a_2_2
I0622 19:43:12.401057 36972 net.cpp:399] relu_a_2_2 -> relu_a_2_2
I0622 19:43:12.401255 36972 net.cpp:141] Setting up relu_a_2_2
I0622 19:43:12.401271 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.401279 36972 net.cpp:156] Memory required for data: 374784400
I0622 19:43:12.401286 36972 layer_factory.hpp:77] Creating layer conv_a_2_2
I0622 19:43:12.401300 36972 net.cpp:91] Creating Layer conv_a_2_2
I0622 19:43:12.401309 36972 net.cpp:425] conv_a_2_2 <- relu_a_2_2
I0622 19:43:12.401320 36972 net.cpp:399] conv_a_2_2 -> conv_a_2_2
I0622 19:43:12.403533 36972 net.cpp:141] Setting up conv_a_2_2
I0622 19:43:12.403563 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.403569 36972 net.cpp:156] Memory required for data: 400998800
I0622 19:43:12.403579 36972 layer_factory.hpp:77] Creating layer elt_a_2
I0622 19:43:12.403589 36972 net.cpp:91] Creating Layer elt_a_2
I0622 19:43:12.403596 36972 net.cpp:425] elt_a_2 <- elt_a_1_elt_a_1_0_split_1
I0622 19:43:12.403604 36972 net.cpp:425] elt_a_2 <- conv_a_2_2
I0622 19:43:12.403620 36972 net.cpp:399] elt_a_2 -> elt_a_2
I0622 19:43:12.403672 36972 net.cpp:141] Setting up elt_a_2
I0622 19:43:12.403692 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.403708 36972 net.cpp:156] Memory required for data: 427213200
I0622 19:43:12.403723 36972 layer_factory.hpp:77] Creating layer elt_a_2_elt_a_2_0_split
I0622 19:43:12.403739 36972 net.cpp:91] Creating Layer elt_a_2_elt_a_2_0_split
I0622 19:43:12.403748 36972 net.cpp:425] elt_a_2_elt_a_2_0_split <- elt_a_2
I0622 19:43:12.403759 36972 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_0
I0622 19:43:12.403769 36972 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_1
I0622 19:43:12.403817 36972 net.cpp:141] Setting up elt_a_2_elt_a_2_0_split
I0622 19:43:12.403831 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.403841 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.403846 36972 net.cpp:156] Memory required for data: 479642000
I0622 19:43:12.403852 36972 layer_factory.hpp:77] Creating layer bn_a_3_1
I0622 19:43:12.403862 36972 net.cpp:91] Creating Layer bn_a_3_1
I0622 19:43:12.403870 36972 net.cpp:425] bn_a_3_1 <- elt_a_2_elt_a_2_0_split_0
I0622 19:43:12.403879 36972 net.cpp:399] bn_a_3_1 -> bn_a_3_1
I0622 19:43:12.404089 36972 net.cpp:141] Setting up bn_a_3_1
I0622 19:43:12.404103 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.404111 36972 net.cpp:156] Memory required for data: 505856400
I0622 19:43:12.404122 36972 layer_factory.hpp:77] Creating layer relu_a_3_1
I0622 19:43:12.404132 36972 net.cpp:91] Creating Layer relu_a_3_1
I0622 19:43:12.404157 36972 net.cpp:425] relu_a_3_1 <- bn_a_3_1
I0622 19:43:12.404176 36972 net.cpp:399] relu_a_3_1 -> relu_a_3_1
I0622 19:43:12.404502 36972 net.cpp:141] Setting up relu_a_3_1
I0622 19:43:12.404520 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.404528 36972 net.cpp:156] Memory required for data: 532070800
I0622 19:43:12.404537 36972 layer_factory.hpp:77] Creating layer conv_a_3_1
I0622 19:43:12.404551 36972 net.cpp:91] Creating Layer conv_a_3_1
I0622 19:43:12.404558 36972 net.cpp:425] conv_a_3_1 <- relu_a_3_1
I0622 19:43:12.404567 36972 net.cpp:399] conv_a_3_1 -> conv_a_3_1
I0622 19:43:12.406965 36972 net.cpp:141] Setting up conv_a_3_1
I0622 19:43:12.406985 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.406991 36972 net.cpp:156] Memory required for data: 558285200
I0622 19:43:12.407001 36972 layer_factory.hpp:77] Creating layer bn_a_3_2
I0622 19:43:12.407012 36972 net.cpp:91] Creating Layer bn_a_3_2
I0622 19:43:12.407018 36972 net.cpp:425] bn_a_3_2 <- conv_a_3_1
I0622 19:43:12.407028 36972 net.cpp:399] bn_a_3_2 -> bn_a_3_2
I0622 19:43:12.407233 36972 net.cpp:141] Setting up bn_a_3_2
I0622 19:43:12.407248 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.407256 36972 net.cpp:156] Memory required for data: 584499600
I0622 19:43:12.407270 36972 layer_factory.hpp:77] Creating layer relu_a_3_2
I0622 19:43:12.407280 36972 net.cpp:91] Creating Layer relu_a_3_2
I0622 19:43:12.407286 36972 net.cpp:425] relu_a_3_2 <- bn_a_3_2
I0622 19:43:12.407294 36972 net.cpp:399] relu_a_3_2 -> relu_a_3_2
I0622 19:43:12.407491 36972 net.cpp:141] Setting up relu_a_3_2
I0622 19:43:12.407507 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.407516 36972 net.cpp:156] Memory required for data: 610714000
I0622 19:43:12.407522 36972 layer_factory.hpp:77] Creating layer conv_a_3_2
I0622 19:43:12.407536 36972 net.cpp:91] Creating Layer conv_a_3_2
I0622 19:43:12.407543 36972 net.cpp:425] conv_a_3_2 <- relu_a_3_2
I0622 19:43:12.407552 36972 net.cpp:399] conv_a_3_2 -> conv_a_3_2
I0622 19:43:12.409710 36972 net.cpp:141] Setting up conv_a_3_2
I0622 19:43:12.409729 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.409735 36972 net.cpp:156] Memory required for data: 636928400
I0622 19:43:12.409750 36972 layer_factory.hpp:77] Creating layer elt_a_3
I0622 19:43:12.409764 36972 net.cpp:91] Creating Layer elt_a_3
I0622 19:43:12.409770 36972 net.cpp:425] elt_a_3 <- elt_a_2_elt_a_2_0_split_1
I0622 19:43:12.409778 36972 net.cpp:425] elt_a_3 <- conv_a_3_2
I0622 19:43:12.409786 36972 net.cpp:399] elt_a_3 -> elt_a_3
I0622 19:43:12.409821 36972 net.cpp:141] Setting up elt_a_3
I0622 19:43:12.409834 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.409842 36972 net.cpp:156] Memory required for data: 663142800
I0622 19:43:12.409848 36972 layer_factory.hpp:77] Creating layer elt_a_3_elt_a_3_0_split
I0622 19:43:12.409857 36972 net.cpp:91] Creating Layer elt_a_3_elt_a_3_0_split
I0622 19:43:12.409863 36972 net.cpp:425] elt_a_3_elt_a_3_0_split <- elt_a_3
I0622 19:43:12.409871 36972 net.cpp:399] elt_a_3_elt_a_3_0_split -> elt_a_3_elt_a_3_0_split_0
I0622 19:43:12.409881 36972 net.cpp:399] elt_a_3_elt_a_3_0_split -> elt_a_3_elt_a_3_0_split_1
I0622 19:43:12.409926 36972 net.cpp:141] Setting up elt_a_3_elt_a_3_0_split
I0622 19:43:12.409940 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.409950 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.409955 36972 net.cpp:156] Memory required for data: 715571600
I0622 19:43:12.409961 36972 layer_factory.hpp:77] Creating layer bn_d_1_1
I0622 19:43:12.409971 36972 net.cpp:91] Creating Layer bn_d_1_1
I0622 19:43:12.409977 36972 net.cpp:425] bn_d_1_1 <- elt_a_3_elt_a_3_0_split_0
I0622 19:43:12.409986 36972 net.cpp:399] bn_d_1_1 -> bn_d_1_1
I0622 19:43:12.410187 36972 net.cpp:141] Setting up bn_d_1_1
I0622 19:43:12.410202 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.410208 36972 net.cpp:156] Memory required for data: 741786000
I0622 19:43:12.410220 36972 layer_factory.hpp:77] Creating layer relu_d_1_1
I0622 19:43:12.410245 36972 net.cpp:91] Creating Layer relu_d_1_1
I0622 19:43:12.410254 36972 net.cpp:425] relu_d_1_1 <- bn_d_1_1
I0622 19:43:12.410261 36972 net.cpp:399] relu_d_1_1 -> relu_d_1_1
I0622 19:43:12.410464 36972 net.cpp:141] Setting up relu_d_1_1
I0622 19:43:12.410480 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.410488 36972 net.cpp:156] Memory required for data: 768000400
I0622 19:43:12.410495 36972 layer_factory.hpp:77] Creating layer conv_d_1_1
I0622 19:43:12.410508 36972 net.cpp:91] Creating Layer conv_d_1_1
I0622 19:43:12.410516 36972 net.cpp:425] conv_d_1_1 <- relu_d_1_1
I0622 19:43:12.410526 36972 net.cpp:399] conv_d_1_1 -> conv_d_1_1
I0622 19:43:12.414441 36972 net.cpp:141] Setting up conv_d_1_1
I0622 19:43:12.414470 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.414484 36972 net.cpp:156] Memory required for data: 781107600
I0622 19:43:12.414506 36972 layer_factory.hpp:77] Creating layer bn_d_1_2
I0622 19:43:12.414523 36972 net.cpp:91] Creating Layer bn_d_1_2
I0622 19:43:12.414530 36972 net.cpp:425] bn_d_1_2 <- conv_d_1_1
I0622 19:43:12.414541 36972 net.cpp:399] bn_d_1_2 -> bn_d_1_2
I0622 19:43:12.414837 36972 net.cpp:141] Setting up bn_d_1_2
I0622 19:43:12.414860 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.414872 36972 net.cpp:156] Memory required for data: 794214800
I0622 19:43:12.414888 36972 layer_factory.hpp:77] Creating layer relu_d_1_2
I0622 19:43:12.414902 36972 net.cpp:91] Creating Layer relu_d_1_2
I0622 19:43:12.414914 36972 net.cpp:425] relu_d_1_2 <- bn_d_1_2
I0622 19:43:12.414932 36972 net.cpp:399] relu_d_1_2 -> relu_d_1_2
I0622 19:43:12.415277 36972 net.cpp:141] Setting up relu_d_1_2
I0622 19:43:12.415297 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.415315 36972 net.cpp:156] Memory required for data: 807322000
I0622 19:43:12.415326 36972 layer_factory.hpp:77] Creating layer conv_d_1_2
I0622 19:43:12.415343 36972 net.cpp:91] Creating Layer conv_d_1_2
I0622 19:43:12.415351 36972 net.cpp:425] conv_d_1_2 <- relu_d_1_2
I0622 19:43:12.415364 36972 net.cpp:399] conv_d_1_2 -> conv_d_1_2
I0622 19:43:12.421193 36972 net.cpp:141] Setting up conv_d_1_2
I0622 19:43:12.421212 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.421219 36972 net.cpp:156] Memory required for data: 820429200
I0622 19:43:12.421231 36972 layer_factory.hpp:77] Creating layer res_d
I0622 19:43:12.421246 36972 net.cpp:91] Creating Layer res_d
I0622 19:43:12.421257 36972 net.cpp:425] res_d <- elt_a_3_elt_a_3_0_split_1
I0622 19:43:12.421267 36972 net.cpp:399] res_d -> res_d
I0622 19:43:12.422514 36972 net.cpp:141] Setting up res_d
I0622 19:43:12.422538 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.422551 36972 net.cpp:156] Memory required for data: 833536400
I0622 19:43:12.422593 36972 layer_factory.hpp:77] Creating layer elt_d_1
I0622 19:43:12.422616 36972 net.cpp:91] Creating Layer elt_d_1
I0622 19:43:12.422633 36972 net.cpp:425] elt_d_1 <- res_d
I0622 19:43:12.422648 36972 net.cpp:425] elt_d_1 <- conv_d_1_2
I0622 19:43:12.422667 36972 net.cpp:399] elt_d_1 -> elt_d_1
I0622 19:43:12.422716 36972 net.cpp:141] Setting up elt_d_1
I0622 19:43:12.422731 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.422740 36972 net.cpp:156] Memory required for data: 846643600
I0622 19:43:12.422746 36972 layer_factory.hpp:77] Creating layer elt_d_1_elt_d_1_0_split
I0622 19:43:12.422760 36972 net.cpp:91] Creating Layer elt_d_1_elt_d_1_0_split
I0622 19:43:12.422768 36972 net.cpp:425] elt_d_1_elt_d_1_0_split <- elt_d_1
I0622 19:43:12.422776 36972 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_0
I0622 19:43:12.422788 36972 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_1
I0622 19:43:12.422840 36972 net.cpp:141] Setting up elt_d_1_elt_d_1_0_split
I0622 19:43:12.422853 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.422863 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.422870 36972 net.cpp:156] Memory required for data: 872858000
I0622 19:43:12.422894 36972 layer_factory.hpp:77] Creating layer bn_d_2_1
I0622 19:43:12.422909 36972 net.cpp:91] Creating Layer bn_d_2_1
I0622 19:43:12.422917 36972 net.cpp:425] bn_d_2_1 <- elt_d_1_elt_d_1_0_split_0
I0622 19:43:12.422927 36972 net.cpp:399] bn_d_2_1 -> bn_d_2_1
I0622 19:43:12.423179 36972 net.cpp:141] Setting up bn_d_2_1
I0622 19:43:12.423195 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.423202 36972 net.cpp:156] Memory required for data: 885965200
I0622 19:43:12.423215 36972 layer_factory.hpp:77] Creating layer relu_d_2_1
I0622 19:43:12.423230 36972 net.cpp:91] Creating Layer relu_d_2_1
I0622 19:43:12.423243 36972 net.cpp:425] relu_d_2_1 <- bn_d_2_1
I0622 19:43:12.423256 36972 net.cpp:399] relu_d_2_1 -> relu_d_2_1
I0622 19:43:12.423672 36972 net.cpp:141] Setting up relu_d_2_1
I0622 19:43:12.423691 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.423696 36972 net.cpp:156] Memory required for data: 899072400
I0622 19:43:12.423702 36972 layer_factory.hpp:77] Creating layer conv_d_2_1
I0622 19:43:12.423720 36972 net.cpp:91] Creating Layer conv_d_2_1
I0622 19:43:12.423727 36972 net.cpp:425] conv_d_2_1 <- relu_d_2_1
I0622 19:43:12.423738 36972 net.cpp:399] conv_d_2_1 -> conv_d_2_1
I0622 19:43:12.430238 36972 net.cpp:141] Setting up conv_d_2_1
I0622 19:43:12.430256 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.430263 36972 net.cpp:156] Memory required for data: 912179600
I0622 19:43:12.430274 36972 layer_factory.hpp:77] Creating layer bn_d_2_2
I0622 19:43:12.430287 36972 net.cpp:91] Creating Layer bn_d_2_2
I0622 19:43:12.430294 36972 net.cpp:425] bn_d_2_2 <- conv_d_2_1
I0622 19:43:12.430304 36972 net.cpp:399] bn_d_2_2 -> bn_d_2_2
I0622 19:43:12.430524 36972 net.cpp:141] Setting up bn_d_2_2
I0622 19:43:12.430538 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.430546 36972 net.cpp:156] Memory required for data: 925286800
I0622 19:43:12.430558 36972 layer_factory.hpp:77] Creating layer relu_d_2_2
I0622 19:43:12.430567 36972 net.cpp:91] Creating Layer relu_d_2_2
I0622 19:43:12.430573 36972 net.cpp:425] relu_d_2_2 <- bn_d_2_2
I0622 19:43:12.430584 36972 net.cpp:399] relu_d_2_2 -> relu_d_2_2
I0622 19:43:12.430830 36972 net.cpp:141] Setting up relu_d_2_2
I0622 19:43:12.430847 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.430855 36972 net.cpp:156] Memory required for data: 938394000
I0622 19:43:12.430860 36972 layer_factory.hpp:77] Creating layer conv_d_2_2
I0622 19:43:12.430877 36972 net.cpp:91] Creating Layer conv_d_2_2
I0622 19:43:12.430884 36972 net.cpp:425] conv_d_2_2 <- relu_d_2_2
I0622 19:43:12.430898 36972 net.cpp:399] conv_d_2_2 -> conv_d_2_2
I0622 19:43:12.437234 36972 net.cpp:141] Setting up conv_d_2_2
I0622 19:43:12.437253 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.437260 36972 net.cpp:156] Memory required for data: 951501200
I0622 19:43:12.437270 36972 layer_factory.hpp:77] Creating layer elt_d_2
I0622 19:43:12.437283 36972 net.cpp:91] Creating Layer elt_d_2
I0622 19:43:12.437289 36972 net.cpp:425] elt_d_2 <- elt_d_1_elt_d_1_0_split_1
I0622 19:43:12.437296 36972 net.cpp:425] elt_d_2 <- conv_d_2_2
I0622 19:43:12.437309 36972 net.cpp:399] elt_d_2 -> elt_d_2
I0622 19:43:12.437342 36972 net.cpp:141] Setting up elt_d_2
I0622 19:43:12.437356 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.437364 36972 net.cpp:156] Memory required for data: 964608400
I0622 19:43:12.437371 36972 layer_factory.hpp:77] Creating layer elt_d_2_elt_d_2_0_split
I0622 19:43:12.437381 36972 net.cpp:91] Creating Layer elt_d_2_elt_d_2_0_split
I0622 19:43:12.437391 36972 net.cpp:425] elt_d_2_elt_d_2_0_split <- elt_d_2
I0622 19:43:12.437398 36972 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_0
I0622 19:43:12.437409 36972 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_1
I0622 19:43:12.437460 36972 net.cpp:141] Setting up elt_d_2_elt_d_2_0_split
I0622 19:43:12.437474 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.437500 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.437507 36972 net.cpp:156] Memory required for data: 990822800
I0622 19:43:12.437515 36972 layer_factory.hpp:77] Creating layer bn_d_3_1
I0622 19:43:12.437528 36972 net.cpp:91] Creating Layer bn_d_3_1
I0622 19:43:12.437537 36972 net.cpp:425] bn_d_3_1 <- elt_d_2_elt_d_2_0_split_0
I0622 19:43:12.437548 36972 net.cpp:399] bn_d_3_1 -> bn_d_3_1
I0622 19:43:12.437773 36972 net.cpp:141] Setting up bn_d_3_1
I0622 19:43:12.437788 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.437793 36972 net.cpp:156] Memory required for data: 1003930000
I0622 19:43:12.437804 36972 layer_factory.hpp:77] Creating layer relu_d_3_1
I0622 19:43:12.437825 36972 net.cpp:91] Creating Layer relu_d_3_1
I0622 19:43:12.437835 36972 net.cpp:425] relu_d_3_1 <- bn_d_3_1
I0622 19:43:12.437844 36972 net.cpp:399] relu_d_3_1 -> relu_d_3_1
I0622 19:43:12.438200 36972 net.cpp:141] Setting up relu_d_3_1
I0622 19:43:12.438222 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.438235 36972 net.cpp:156] Memory required for data: 1017037200
I0622 19:43:12.438274 36972 layer_factory.hpp:77] Creating layer conv_d_3_1
I0622 19:43:12.438338 36972 net.cpp:91] Creating Layer conv_d_3_1
I0622 19:43:12.438351 36972 net.cpp:425] conv_d_3_1 <- relu_d_3_1
I0622 19:43:12.438364 36972 net.cpp:399] conv_d_3_1 -> conv_d_3_1
I0622 19:43:12.444710 36972 net.cpp:141] Setting up conv_d_3_1
I0622 19:43:12.444730 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.444737 36972 net.cpp:156] Memory required for data: 1030144400
I0622 19:43:12.444747 36972 layer_factory.hpp:77] Creating layer bn_d_3_2
I0622 19:43:12.444761 36972 net.cpp:91] Creating Layer bn_d_3_2
I0622 19:43:12.444767 36972 net.cpp:425] bn_d_3_2 <- conv_d_3_1
I0622 19:43:12.444782 36972 net.cpp:399] bn_d_3_2 -> bn_d_3_2
I0622 19:43:12.445013 36972 net.cpp:141] Setting up bn_d_3_2
I0622 19:43:12.445026 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.445034 36972 net.cpp:156] Memory required for data: 1043251600
I0622 19:43:12.445046 36972 layer_factory.hpp:77] Creating layer relu_d_3_2
I0622 19:43:12.445058 36972 net.cpp:91] Creating Layer relu_d_3_2
I0622 19:43:12.445065 36972 net.cpp:425] relu_d_3_2 <- bn_d_3_2
I0622 19:43:12.445075 36972 net.cpp:399] relu_d_3_2 -> relu_d_3_2
I0622 19:43:12.445515 36972 net.cpp:141] Setting up relu_d_3_2
I0622 19:43:12.445533 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.445539 36972 net.cpp:156] Memory required for data: 1056358800
I0622 19:43:12.445545 36972 layer_factory.hpp:77] Creating layer conv_d_3_2
I0622 19:43:12.445564 36972 net.cpp:91] Creating Layer conv_d_3_2
I0622 19:43:12.445570 36972 net.cpp:425] conv_d_3_2 <- relu_d_3_2
I0622 19:43:12.445585 36972 net.cpp:399] conv_d_3_2 -> conv_d_3_2
I0622 19:43:12.452114 36972 net.cpp:141] Setting up conv_d_3_2
I0622 19:43:12.452134 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.452142 36972 net.cpp:156] Memory required for data: 1069466000
I0622 19:43:12.452165 36972 layer_factory.hpp:77] Creating layer elt_d_3
I0622 19:43:12.452177 36972 net.cpp:91] Creating Layer elt_d_3
I0622 19:43:12.452185 36972 net.cpp:425] elt_d_3 <- elt_d_2_elt_d_2_0_split_1
I0622 19:43:12.452193 36972 net.cpp:425] elt_d_3 <- conv_d_3_2
I0622 19:43:12.452205 36972 net.cpp:399] elt_d_3 -> elt_d_3
I0622 19:43:12.452246 36972 net.cpp:141] Setting up elt_d_3
I0622 19:43:12.452260 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.452268 36972 net.cpp:156] Memory required for data: 1082573200
I0622 19:43:12.452275 36972 layer_factory.hpp:77] Creating layer elt_d_3_elt_d_3_0_split
I0622 19:43:12.452296 36972 net.cpp:91] Creating Layer elt_d_3_elt_d_3_0_split
I0622 19:43:12.452301 36972 net.cpp:425] elt_d_3_elt_d_3_0_split <- elt_d_3
I0622 19:43:12.452309 36972 net.cpp:399] elt_d_3_elt_d_3_0_split -> elt_d_3_elt_d_3_0_split_0
I0622 19:43:12.452319 36972 net.cpp:399] elt_d_3_elt_d_3_0_split -> elt_d_3_elt_d_3_0_split_1
I0622 19:43:12.452394 36972 net.cpp:141] Setting up elt_d_3_elt_d_3_0_split
I0622 19:43:12.452409 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.452419 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.452425 36972 net.cpp:156] Memory required for data: 1108787600
I0622 19:43:12.452432 36972 layer_factory.hpp:77] Creating layer bn_j_1_1
I0622 19:43:12.452446 36972 net.cpp:91] Creating Layer bn_j_1_1
I0622 19:43:12.452455 36972 net.cpp:425] bn_j_1_1 <- elt_d_3_elt_d_3_0_split_0
I0622 19:43:12.452464 36972 net.cpp:399] bn_j_1_1 -> bn_j_1_1
I0622 19:43:12.452697 36972 net.cpp:141] Setting up bn_j_1_1
I0622 19:43:12.452711 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.452718 36972 net.cpp:156] Memory required for data: 1121894800
I0622 19:43:12.452728 36972 layer_factory.hpp:77] Creating layer relu_j_1_1
I0622 19:43:12.452739 36972 net.cpp:91] Creating Layer relu_j_1_1
I0622 19:43:12.452746 36972 net.cpp:425] relu_j_1_1 <- bn_j_1_1
I0622 19:43:12.452757 36972 net.cpp:399] relu_j_1_1 -> relu_j_1_1
I0622 19:43:12.453094 36972 net.cpp:141] Setting up relu_j_1_1
I0622 19:43:12.453116 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.453130 36972 net.cpp:156] Memory required for data: 1135002000
I0622 19:43:12.453141 36972 layer_factory.hpp:77] Creating layer conv_j_1_1
I0622 19:43:12.453158 36972 net.cpp:91] Creating Layer conv_j_1_1
I0622 19:43:12.453168 36972 net.cpp:425] conv_j_1_1 <- relu_j_1_1
I0622 19:43:12.453182 36972 net.cpp:399] conv_j_1_1 -> conv_j_1_1
I0622 19:43:12.464426 36972 net.cpp:141] Setting up conv_j_1_1
I0622 19:43:12.464447 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.464453 36972 net.cpp:156] Memory required for data: 1141555600
I0622 19:43:12.464463 36972 layer_factory.hpp:77] Creating layer bn_j_1_2
I0622 19:43:12.464478 36972 net.cpp:91] Creating Layer bn_j_1_2
I0622 19:43:12.464488 36972 net.cpp:425] bn_j_1_2 <- conv_j_1_1
I0622 19:43:12.464503 36972 net.cpp:399] bn_j_1_2 -> bn_j_1_2
I0622 19:43:12.464746 36972 net.cpp:141] Setting up bn_j_1_2
I0622 19:43:12.464761 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.464767 36972 net.cpp:156] Memory required for data: 1148109200
I0622 19:43:12.464778 36972 layer_factory.hpp:77] Creating layer relu_j_1_2
I0622 19:43:12.464789 36972 net.cpp:91] Creating Layer relu_j_1_2
I0622 19:43:12.464797 36972 net.cpp:425] relu_j_1_2 <- bn_j_1_2
I0622 19:43:12.464807 36972 net.cpp:399] relu_j_1_2 -> relu_j_1_2
I0622 19:43:12.465147 36972 net.cpp:141] Setting up relu_j_1_2
I0622 19:43:12.465164 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.465172 36972 net.cpp:156] Memory required for data: 1154662800
I0622 19:43:12.465178 36972 layer_factory.hpp:77] Creating layer conv_j_1_2
I0622 19:43:12.465193 36972 net.cpp:91] Creating Layer conv_j_1_2
I0622 19:43:12.465200 36972 net.cpp:425] conv_j_1_2 <- relu_j_1_2
I0622 19:43:12.465216 36972 net.cpp:399] conv_j_1_2 -> conv_j_1_2
I0622 19:43:12.486423 36972 net.cpp:141] Setting up conv_j_1_2
I0622 19:43:12.486443 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.486450 36972 net.cpp:156] Memory required for data: 1161216400
I0622 19:43:12.486460 36972 layer_factory.hpp:77] Creating layer res_j
I0622 19:43:12.486480 36972 net.cpp:91] Creating Layer res_j
I0622 19:43:12.486488 36972 net.cpp:425] res_j <- elt_d_3_elt_d_3_0_split_1
I0622 19:43:12.486502 36972 net.cpp:399] res_j -> res_j
I0622 19:43:12.488709 36972 net.cpp:141] Setting up res_j
I0622 19:43:12.488729 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.488735 36972 net.cpp:156] Memory required for data: 1167770000
I0622 19:43:12.488745 36972 layer_factory.hpp:77] Creating layer elt_j_1
I0622 19:43:12.488755 36972 net.cpp:91] Creating Layer elt_j_1
I0622 19:43:12.488761 36972 net.cpp:425] elt_j_1 <- res_j
I0622 19:43:12.488770 36972 net.cpp:425] elt_j_1 <- conv_j_1_2
I0622 19:43:12.488785 36972 net.cpp:399] elt_j_1 -> elt_j_1
I0622 19:43:12.488826 36972 net.cpp:141] Setting up elt_j_1
I0622 19:43:12.488839 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.488863 36972 net.cpp:156] Memory required for data: 1174323600
I0622 19:43:12.488881 36972 layer_factory.hpp:77] Creating layer elt_j_1_elt_j_1_0_split
I0622 19:43:12.488891 36972 net.cpp:91] Creating Layer elt_j_1_elt_j_1_0_split
I0622 19:43:12.488898 36972 net.cpp:425] elt_j_1_elt_j_1_0_split <- elt_j_1
I0622 19:43:12.488905 36972 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_0
I0622 19:43:12.488919 36972 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_1
I0622 19:43:12.488970 36972 net.cpp:141] Setting up elt_j_1_elt_j_1_0_split
I0622 19:43:12.488984 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.488994 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.488999 36972 net.cpp:156] Memory required for data: 1187430800
I0622 19:43:12.489007 36972 layer_factory.hpp:77] Creating layer bn_j_2_1
I0622 19:43:12.489020 36972 net.cpp:91] Creating Layer bn_j_2_1
I0622 19:43:12.489028 36972 net.cpp:425] bn_j_2_1 <- elt_j_1_elt_j_1_0_split_0
I0622 19:43:12.489040 36972 net.cpp:399] bn_j_2_1 -> bn_j_2_1
I0622 19:43:12.489274 36972 net.cpp:141] Setting up bn_j_2_1
I0622 19:43:12.489289 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.489295 36972 net.cpp:156] Memory required for data: 1193984400
I0622 19:43:12.489305 36972 layer_factory.hpp:77] Creating layer relu_j_2_1
I0622 19:43:12.489315 36972 net.cpp:91] Creating Layer relu_j_2_1
I0622 19:43:12.489320 36972 net.cpp:425] relu_j_2_1 <- bn_j_2_1
I0622 19:43:12.489328 36972 net.cpp:399] relu_j_2_1 -> relu_j_2_1
I0622 19:43:12.489681 36972 net.cpp:141] Setting up relu_j_2_1
I0622 19:43:12.489698 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.489706 36972 net.cpp:156] Memory required for data: 1200538000
I0622 19:43:12.489714 36972 layer_factory.hpp:77] Creating layer conv_j_2_1
I0622 19:43:12.489738 36972 net.cpp:91] Creating Layer conv_j_2_1
I0622 19:43:12.489747 36972 net.cpp:425] conv_j_2_1 <- relu_j_2_1
I0622 19:43:12.489758 36972 net.cpp:399] conv_j_2_1 -> conv_j_2_1
I0622 19:43:12.511095 36972 net.cpp:141] Setting up conv_j_2_1
I0622 19:43:12.511114 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.511121 36972 net.cpp:156] Memory required for data: 1207091600
I0622 19:43:12.511132 36972 layer_factory.hpp:77] Creating layer bn_j_2_2
I0622 19:43:12.511145 36972 net.cpp:91] Creating Layer bn_j_2_2
I0622 19:43:12.511152 36972 net.cpp:425] bn_j_2_2 <- conv_j_2_1
I0622 19:43:12.511168 36972 net.cpp:399] bn_j_2_2 -> bn_j_2_2
I0622 19:43:12.511415 36972 net.cpp:141] Setting up bn_j_2_2
I0622 19:43:12.511428 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.511435 36972 net.cpp:156] Memory required for data: 1213645200
I0622 19:43:12.511446 36972 layer_factory.hpp:77] Creating layer relu_j_2_2
I0622 19:43:12.511456 36972 net.cpp:91] Creating Layer relu_j_2_2
I0622 19:43:12.511464 36972 net.cpp:425] relu_j_2_2 <- bn_j_2_2
I0622 19:43:12.511476 36972 net.cpp:399] relu_j_2_2 -> relu_j_2_2
I0622 19:43:12.511703 36972 net.cpp:141] Setting up relu_j_2_2
I0622 19:43:12.511721 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.511729 36972 net.cpp:156] Memory required for data: 1220198800
I0622 19:43:12.511735 36972 layer_factory.hpp:77] Creating layer conv_j_2_2
I0622 19:43:12.511752 36972 net.cpp:91] Creating Layer conv_j_2_2
I0622 19:43:12.511761 36972 net.cpp:425] conv_j_2_2 <- relu_j_2_2
I0622 19:43:12.511773 36972 net.cpp:399] conv_j_2_2 -> conv_j_2_2
I0622 19:43:12.532984 36972 net.cpp:141] Setting up conv_j_2_2
I0622 19:43:12.533004 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.533010 36972 net.cpp:156] Memory required for data: 1226752400
I0622 19:43:12.533020 36972 layer_factory.hpp:77] Creating layer elt_j_2
I0622 19:43:12.533033 36972 net.cpp:91] Creating Layer elt_j_2
I0622 19:43:12.533041 36972 net.cpp:425] elt_j_2 <- elt_j_1_elt_j_1_0_split_1
I0622 19:43:12.533048 36972 net.cpp:425] elt_j_2 <- conv_j_2_2
I0622 19:43:12.533061 36972 net.cpp:399] elt_j_2 -> elt_j_2
I0622 19:43:12.533126 36972 net.cpp:141] Setting up elt_j_2
I0622 19:43:12.533141 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.533149 36972 net.cpp:156] Memory required for data: 1233306000
I0622 19:43:12.533156 36972 layer_factory.hpp:77] Creating layer elt_j_2_elt_j_2_0_split
I0622 19:43:12.533167 36972 net.cpp:91] Creating Layer elt_j_2_elt_j_2_0_split
I0622 19:43:12.533176 36972 net.cpp:425] elt_j_2_elt_j_2_0_split <- elt_j_2
I0622 19:43:12.533187 36972 net.cpp:399] elt_j_2_elt_j_2_0_split -> elt_j_2_elt_j_2_0_split_0
I0622 19:43:12.533200 36972 net.cpp:399] elt_j_2_elt_j_2_0_split -> elt_j_2_elt_j_2_0_split_1
I0622 19:43:12.533252 36972 net.cpp:141] Setting up elt_j_2_elt_j_2_0_split
I0622 19:43:12.533267 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.533275 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.533282 36972 net.cpp:156] Memory required for data: 1246413200
I0622 19:43:12.533289 36972 layer_factory.hpp:77] Creating layer bn_j_3_1
I0622 19:43:12.533303 36972 net.cpp:91] Creating Layer bn_j_3_1
I0622 19:43:12.533311 36972 net.cpp:425] bn_j_3_1 <- elt_j_2_elt_j_2_0_split_0
I0622 19:43:12.533324 36972 net.cpp:399] bn_j_3_1 -> bn_j_3_1
I0622 19:43:12.533566 36972 net.cpp:141] Setting up bn_j_3_1
I0622 19:43:12.533581 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.533586 36972 net.cpp:156] Memory required for data: 1252966800
I0622 19:43:12.533597 36972 layer_factory.hpp:77] Creating layer relu_j_3_1
I0622 19:43:12.533607 36972 net.cpp:91] Creating Layer relu_j_3_1
I0622 19:43:12.533613 36972 net.cpp:425] relu_j_3_1 <- bn_j_3_1
I0622 19:43:12.533622 36972 net.cpp:399] relu_j_3_1 -> relu_j_3_1
I0622 19:43:12.533869 36972 net.cpp:141] Setting up relu_j_3_1
I0622 19:43:12.533888 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.533900 36972 net.cpp:156] Memory required for data: 1259520400
I0622 19:43:12.533911 36972 layer_factory.hpp:77] Creating layer conv_j_3_1
I0622 19:43:12.533959 36972 net.cpp:91] Creating Layer conv_j_3_1
I0622 19:43:12.533974 36972 net.cpp:425] conv_j_3_1 <- relu_j_3_1
I0622 19:43:12.533998 36972 net.cpp:399] conv_j_3_1 -> conv_j_3_1
I0622 19:43:12.555375 36972 net.cpp:141] Setting up conv_j_3_1
I0622 19:43:12.555404 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.555418 36972 net.cpp:156] Memory required for data: 1266074000
I0622 19:43:12.555436 36972 layer_factory.hpp:77] Creating layer bn_j_3_2
I0622 19:43:12.555460 36972 net.cpp:91] Creating Layer bn_j_3_2
I0622 19:43:12.555470 36972 net.cpp:425] bn_j_3_2 <- conv_j_3_1
I0622 19:43:12.555480 36972 net.cpp:399] bn_j_3_2 -> bn_j_3_2
I0622 19:43:12.555733 36972 net.cpp:141] Setting up bn_j_3_2
I0622 19:43:12.555747 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.555753 36972 net.cpp:156] Memory required for data: 1272627600
I0622 19:43:12.555765 36972 layer_factory.hpp:77] Creating layer relu_j_3_2
I0622 19:43:12.555774 36972 net.cpp:91] Creating Layer relu_j_3_2
I0622 19:43:12.555781 36972 net.cpp:425] relu_j_3_2 <- bn_j_3_2
I0622 19:43:12.555789 36972 net.cpp:399] relu_j_3_2 -> relu_j_3_2
I0622 19:43:12.556149 36972 net.cpp:141] Setting up relu_j_3_2
I0622 19:43:12.556166 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.556172 36972 net.cpp:156] Memory required for data: 1279181200
I0622 19:43:12.556180 36972 layer_factory.hpp:77] Creating layer conv_j_3_2
I0622 19:43:12.556195 36972 net.cpp:91] Creating Layer conv_j_3_2
I0622 19:43:12.556203 36972 net.cpp:425] conv_j_3_2 <- relu_j_3_2
I0622 19:43:12.556217 36972 net.cpp:399] conv_j_3_2 -> conv_j_3_2
I0622 19:43:12.577235 36972 net.cpp:141] Setting up conv_j_3_2
I0622 19:43:12.577255 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.577262 36972 net.cpp:156] Memory required for data: 1285734800
I0622 19:43:12.577272 36972 layer_factory.hpp:77] Creating layer elt_j_3
I0622 19:43:12.577283 36972 net.cpp:91] Creating Layer elt_j_3
I0622 19:43:12.577289 36972 net.cpp:425] elt_j_3 <- elt_j_2_elt_j_2_0_split_1
I0622 19:43:12.577327 36972 net.cpp:425] elt_j_3 <- conv_j_3_2
I0622 19:43:12.577342 36972 net.cpp:399] elt_j_3 -> elt_j_3
I0622 19:43:12.577384 36972 net.cpp:141] Setting up elt_j_3
I0622 19:43:12.577401 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.577409 36972 net.cpp:156] Memory required for data: 1292288400
I0622 19:43:12.577415 36972 layer_factory.hpp:77] Creating layer bn_m_1_1
I0622 19:43:12.577426 36972 net.cpp:91] Creating Layer bn_m_1_1
I0622 19:43:12.577435 36972 net.cpp:425] bn_m_1_1 <- elt_j_3
I0622 19:43:12.577447 36972 net.cpp:399] bn_m_1_1 -> bn_m_1_1
I0622 19:43:12.577703 36972 net.cpp:141] Setting up bn_m_1_1
I0622 19:43:12.577718 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.577723 36972 net.cpp:156] Memory required for data: 1298842000
I0622 19:43:12.577735 36972 layer_factory.hpp:77] Creating layer relu_m_1_1
I0622 19:43:12.577744 36972 net.cpp:91] Creating Layer relu_m_1_1
I0622 19:43:12.577750 36972 net.cpp:425] relu_m_1_1 <- bn_m_1_1
I0622 19:43:12.577761 36972 net.cpp:399] relu_m_1_1 -> relu_m_1_1
I0622 19:43:12.577982 36972 net.cpp:141] Setting up relu_m_1_1
I0622 19:43:12.577999 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.578006 36972 net.cpp:156] Memory required for data: 1305395600
I0622 19:43:12.578011 36972 layer_factory.hpp:77] Creating layer gap
I0622 19:43:12.578025 36972 net.cpp:91] Creating Layer gap
I0622 19:43:12.578032 36972 net.cpp:425] gap <- relu_m_1_1
I0622 19:43:12.578040 36972 net.cpp:399] gap -> gap
I0622 19:43:12.578533 36972 net.cpp:141] Setting up gap
I0622 19:43:12.578552 36972 net.cpp:148] Top shape: 100 256 1 1 (25600)
I0622 19:43:12.578557 36972 net.cpp:156] Memory required for data: 1305498000
I0622 19:43:12.578564 36972 layer_factory.hpp:77] Creating layer ip1
I0622 19:43:12.578578 36972 net.cpp:91] Creating Layer ip1
I0622 19:43:12.578584 36972 net.cpp:425] ip1 <- gap
I0622 19:43:12.578595 36972 net.cpp:399] ip1 -> ip1
I0622 19:43:12.578853 36972 net.cpp:141] Setting up ip1
I0622 19:43:12.578871 36972 net.cpp:148] Top shape: 100 10 (1000)
I0622 19:43:12.578877 36972 net.cpp:156] Memory required for data: 1305502000
I0622 19:43:12.578887 36972 layer_factory.hpp:77] Creating layer loss
I0622 19:43:12.578903 36972 net.cpp:91] Creating Layer loss
I0622 19:43:12.578912 36972 net.cpp:425] loss <- ip1
I0622 19:43:12.578919 36972 net.cpp:425] loss <- label
I0622 19:43:12.578930 36972 net.cpp:399] loss -> loss
I0622 19:43:12.578949 36972 layer_factory.hpp:77] Creating layer loss
I0622 19:43:12.579282 36972 net.cpp:141] Setting up loss
I0622 19:43:12.579298 36972 net.cpp:148] Top shape: (1)
I0622 19:43:12.579304 36972 net.cpp:151]     with loss weight 1
I0622 19:43:12.579327 36972 net.cpp:156] Memory required for data: 1305502004
I0622 19:43:12.579334 36972 net.cpp:217] loss needs backward computation.
I0622 19:43:12.579345 36972 net.cpp:217] ip1 needs backward computation.
I0622 19:43:12.579351 36972 net.cpp:217] gap needs backward computation.
I0622 19:43:12.579357 36972 net.cpp:217] relu_m_1_1 needs backward computation.
I0622 19:43:12.579362 36972 net.cpp:217] bn_m_1_1 needs backward computation.
I0622 19:43:12.579368 36972 net.cpp:217] elt_j_3 needs backward computation.
I0622 19:43:12.579373 36972 net.cpp:217] conv_j_3_2 needs backward computation.
I0622 19:43:12.579380 36972 net.cpp:217] relu_j_3_2 needs backward computation.
I0622 19:43:12.579385 36972 net.cpp:217] bn_j_3_2 needs backward computation.
I0622 19:43:12.579393 36972 net.cpp:217] conv_j_3_1 needs backward computation.
I0622 19:43:12.579399 36972 net.cpp:217] relu_j_3_1 needs backward computation.
I0622 19:43:12.579406 36972 net.cpp:217] bn_j_3_1 needs backward computation.
I0622 19:43:12.579412 36972 net.cpp:217] elt_j_2_elt_j_2_0_split needs backward computation.
I0622 19:43:12.579418 36972 net.cpp:217] elt_j_2 needs backward computation.
I0622 19:43:12.579427 36972 net.cpp:217] conv_j_2_2 needs backward computation.
I0622 19:43:12.579433 36972 net.cpp:217] relu_j_2_2 needs backward computation.
I0622 19:43:12.579439 36972 net.cpp:217] bn_j_2_2 needs backward computation.
I0622 19:43:12.579463 36972 net.cpp:217] conv_j_2_1 needs backward computation.
I0622 19:43:12.579471 36972 net.cpp:217] relu_j_2_1 needs backward computation.
I0622 19:43:12.579478 36972 net.cpp:217] bn_j_2_1 needs backward computation.
I0622 19:43:12.579484 36972 net.cpp:217] elt_j_1_elt_j_1_0_split needs backward computation.
I0622 19:43:12.579490 36972 net.cpp:217] elt_j_1 needs backward computation.
I0622 19:43:12.579496 36972 net.cpp:217] res_j needs backward computation.
I0622 19:43:12.579502 36972 net.cpp:217] conv_j_1_2 needs backward computation.
I0622 19:43:12.579507 36972 net.cpp:217] relu_j_1_2 needs backward computation.
I0622 19:43:12.579514 36972 net.cpp:217] bn_j_1_2 needs backward computation.
I0622 19:43:12.579519 36972 net.cpp:217] conv_j_1_1 needs backward computation.
I0622 19:43:12.579524 36972 net.cpp:217] relu_j_1_1 needs backward computation.
I0622 19:43:12.579531 36972 net.cpp:217] bn_j_1_1 needs backward computation.
I0622 19:43:12.579538 36972 net.cpp:217] elt_d_3_elt_d_3_0_split needs backward computation.
I0622 19:43:12.579545 36972 net.cpp:217] elt_d_3 needs backward computation.
I0622 19:43:12.579550 36972 net.cpp:217] conv_d_3_2 needs backward computation.
I0622 19:43:12.579560 36972 net.cpp:217] relu_d_3_2 needs backward computation.
I0622 19:43:12.579565 36972 net.cpp:217] bn_d_3_2 needs backward computation.
I0622 19:43:12.579571 36972 net.cpp:217] conv_d_3_1 needs backward computation.
I0622 19:43:12.579576 36972 net.cpp:217] relu_d_3_1 needs backward computation.
I0622 19:43:12.579586 36972 net.cpp:217] bn_d_3_1 needs backward computation.
I0622 19:43:12.579593 36972 net.cpp:217] elt_d_2_elt_d_2_0_split needs backward computation.
I0622 19:43:12.579599 36972 net.cpp:217] elt_d_2 needs backward computation.
I0622 19:43:12.579605 36972 net.cpp:217] conv_d_2_2 needs backward computation.
I0622 19:43:12.579612 36972 net.cpp:217] relu_d_2_2 needs backward computation.
I0622 19:43:12.579617 36972 net.cpp:217] bn_d_2_2 needs backward computation.
I0622 19:43:12.579622 36972 net.cpp:217] conv_d_2_1 needs backward computation.
I0622 19:43:12.579628 36972 net.cpp:217] relu_d_2_1 needs backward computation.
I0622 19:43:12.579633 36972 net.cpp:217] bn_d_2_1 needs backward computation.
I0622 19:43:12.579643 36972 net.cpp:217] elt_d_1_elt_d_1_0_split needs backward computation.
I0622 19:43:12.579649 36972 net.cpp:217] elt_d_1 needs backward computation.
I0622 19:43:12.579655 36972 net.cpp:217] res_d needs backward computation.
I0622 19:43:12.579661 36972 net.cpp:217] conv_d_1_2 needs backward computation.
I0622 19:43:12.579668 36972 net.cpp:217] relu_d_1_2 needs backward computation.
I0622 19:43:12.579673 36972 net.cpp:217] bn_d_1_2 needs backward computation.
I0622 19:43:12.579679 36972 net.cpp:217] conv_d_1_1 needs backward computation.
I0622 19:43:12.579684 36972 net.cpp:217] relu_d_1_1 needs backward computation.
I0622 19:43:12.579689 36972 net.cpp:217] bn_d_1_1 needs backward computation.
I0622 19:43:12.579697 36972 net.cpp:217] elt_a_3_elt_a_3_0_split needs backward computation.
I0622 19:43:12.579704 36972 net.cpp:217] elt_a_3 needs backward computation.
I0622 19:43:12.579710 36972 net.cpp:217] conv_a_3_2 needs backward computation.
I0622 19:43:12.579715 36972 net.cpp:217] relu_a_3_2 needs backward computation.
I0622 19:43:12.579721 36972 net.cpp:217] bn_a_3_2 needs backward computation.
I0622 19:43:12.579726 36972 net.cpp:217] conv_a_3_1 needs backward computation.
I0622 19:43:12.579732 36972 net.cpp:217] relu_a_3_1 needs backward computation.
I0622 19:43:12.579737 36972 net.cpp:217] bn_a_3_1 needs backward computation.
I0622 19:43:12.579743 36972 net.cpp:217] elt_a_2_elt_a_2_0_split needs backward computation.
I0622 19:43:12.579752 36972 net.cpp:217] elt_a_2 needs backward computation.
I0622 19:43:12.579759 36972 net.cpp:217] conv_a_2_2 needs backward computation.
I0622 19:43:12.579766 36972 net.cpp:217] relu_a_2_2 needs backward computation.
I0622 19:43:12.579771 36972 net.cpp:217] bn_a_2_2 needs backward computation.
I0622 19:43:12.579777 36972 net.cpp:217] conv_a_2_1 needs backward computation.
I0622 19:43:12.579793 36972 net.cpp:217] relu_a_2_1 needs backward computation.
I0622 19:43:12.579800 36972 net.cpp:217] bn_a_2_1 needs backward computation.
I0622 19:43:12.579807 36972 net.cpp:217] elt_a_1_elt_a_1_0_split needs backward computation.
I0622 19:43:12.579816 36972 net.cpp:217] elt_a_1 needs backward computation.
I0622 19:43:12.579823 36972 net.cpp:217] res_a needs backward computation.
I0622 19:43:12.579831 36972 net.cpp:217] conv_a_1_2 needs backward computation.
I0622 19:43:12.579839 36972 net.cpp:217] relu_a_1_2 needs backward computation.
I0622 19:43:12.579846 36972 net.cpp:217] bn_a_1_2 needs backward computation.
I0622 19:43:12.579856 36972 net.cpp:217] conv_a_1_1 needs backward computation.
I0622 19:43:12.579865 36972 net.cpp:217] relu_a_1_1 needs backward computation.
I0622 19:43:12.579872 36972 net.cpp:217] bn_a_1_1 needs backward computation.
I0622 19:43:12.579880 36972 net.cpp:217] conv0_conv0_0_split needs backward computation.
I0622 19:43:12.579887 36972 net.cpp:217] conv0 needs backward computation.
I0622 19:43:12.579895 36972 net.cpp:219] resnet does not need backward computation.
I0622 19:43:12.579901 36972 net.cpp:261] This network produces output loss
I0622 19:43:12.579975 36972 net.cpp:274] Network initialization done.
I0622 19:43:12.582219 36972 solver.cpp:181] Creating test net (#0) specified by net file: ./res_ide20_train_test.prototxt
I0622 19:43:12.582336 36972 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer resnet
I0622 19:43:12.582893 36972 net.cpp:49] Initializing net from parameters: 
name: "ResNet"
state {
  phase: TEST
}
layer {
  name: "resnet"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/takeki/caffe/examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/takeki/caffe/examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_1"
  type: "BatchNorm"
  bottom: "conv0"
  top: "bn_a_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_1"
  type: "ReLU"
  bottom: "bn_a_1_1"
  top: "relu_a_1_1"
}
layer {
  name: "conv_a_1_1"
  type: "Convolution"
  bottom: "relu_a_1_1"
  top: "conv_a_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_1_2"
  type: "BatchNorm"
  bottom: "conv_a_1_1"
  top: "bn_a_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_1_2"
  type: "ReLU"
  bottom: "bn_a_1_2"
  top: "relu_a_1_2"
}
layer {
  name: "conv_a_1_2"
  type: "Convolution"
  bottom: "relu_a_1_2"
  top: "conv_a_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_a"
  type: "Convolution"
  bottom: "conv0"
  top: "res_a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_1"
  type: "Eltwise"
  bottom: "res_a"
  bottom: "conv_a_1_2"
  top: "elt_a_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_a_2_1"
  type: "BatchNorm"
  bottom: "elt_a_1"
  top: "bn_a_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_1"
  type: "ReLU"
  bottom: "bn_a_2_1"
  top: "relu_a_2_1"
}
layer {
  name: "conv_a_2_1"
  type: "Convolution"
  bottom: "relu_a_2_1"
  top: "conv_a_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_2_2"
  type: "BatchNorm"
  bottom: "conv_a_2_1"
  top: "bn_a_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_2_2"
  type: "ReLU"
  bottom: "bn_a_2_2"
  top: "relu_a_2_2"
}
layer {
  name: "conv_a_2_2"
  type: "Convolution"
  bottom: "relu_a_2_2"
  top: "conv_a_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_2"
  type: "Eltwise"
  bottom: "elt_a_1"
  bottom: "conv_a_2_2"
  top: "elt_a_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_a_3_1"
  type: "BatchNorm"
  bottom: "elt_a_2"
  top: "bn_a_3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_3_1"
  type: "ReLU"
  bottom: "bn_a_3_1"
  top: "relu_a_3_1"
}
layer {
  name: "conv_a_3_1"
  type: "Convolution"
  bottom: "relu_a_3_1"
  top: "conv_a_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_a_3_2"
  type: "BatchNorm"
  bottom: "conv_a_3_1"
  top: "bn_a_3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_a_3_2"
  type: "ReLU"
  bottom: "bn_a_3_2"
  top: "relu_a_3_2"
}
layer {
  name: "conv_a_3_2"
  type: "Convolution"
  bottom: "relu_a_3_2"
  top: "conv_a_3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_a_3"
  type: "Eltwise"
  bottom: "elt_a_2"
  bottom: "conv_a_3_2"
  top: "elt_a_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_1_1"
  type: "BatchNorm"
  bottom: "elt_a_3"
  top: "bn_d_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_1"
  type: "ReLU"
  bottom: "bn_d_1_1"
  top: "relu_d_1_1"
}
layer {
  name: "conv_d_1_1"
  type: "Convolution"
  bottom: "relu_d_1_1"
  top: "conv_d_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_1_2"
  type: "BatchNorm"
  bottom: "conv_d_1_1"
  top: "bn_d_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_1_2"
  type: "ReLU"
  bottom: "bn_d_1_2"
  top: "relu_d_1_2"
}
layer {
  name: "conv_d_1_2"
  type: "Convolution"
  bottom: "relu_d_1_2"
  top: "conv_d_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_d"
  type: "Convolution"
  bottom: "elt_a_3"
  top: "res_d"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_1"
  type: "Eltwise"
  bottom: "res_d"
  bottom: "conv_d_1_2"
  top: "elt_d_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_2_1"
  type: "BatchNorm"
  bottom: "elt_d_1"
  top: "bn_d_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_1"
  type: "ReLU"
  bottom: "bn_d_2_1"
  top: "relu_d_2_1"
}
layer {
  name: "conv_d_2_1"
  type: "Convolution"
  bottom: "relu_d_2_1"
  top: "conv_d_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_2_2"
  type: "BatchNorm"
  bottom: "conv_d_2_1"
  top: "bn_d_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_2_2"
  type: "ReLU"
  bottom: "bn_d_2_2"
  top: "relu_d_2_2"
}
layer {
  name: "conv_d_2_2"
  type: "Convolution"
  bottom: "relu_d_2_2"
  top: "conv_d_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_2"
  type: "Eltwise"
  bottom: "elt_d_1"
  bottom: "conv_d_2_2"
  top: "elt_d_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_d_3_1"
  type: "BatchNorm"
  bottom: "elt_d_2"
  top: "bn_d_3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_3_1"
  type: "ReLU"
  bottom: "bn_d_3_1"
  top: "relu_d_3_1"
}
layer {
  name: "conv_d_3_1"
  type: "Convolution"
  bottom: "relu_d_3_1"
  top: "conv_d_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_d_3_2"
  type: "BatchNorm"
  bottom: "conv_d_3_1"
  top: "bn_d_3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_d_3_2"
  type: "ReLU"
  bottom: "bn_d_3_2"
  top: "relu_d_3_2"
}
layer {
  name: "conv_d_3_2"
  type: "Convolution"
  bottom: "relu_d_3_2"
  top: "conv_d_3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_d_3"
  type: "Eltwise"
  bottom: "elt_d_2"
  bottom: "conv_d_3_2"
  top: "elt_d_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_1_1"
  type: "BatchNorm"
  bottom: "elt_d_3"
  top: "bn_j_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_1"
  type: "ReLU"
  bottom: "bn_j_1_1"
  top: "relu_j_1_1"
}
layer {
  name: "conv_j_1_1"
  type: "Convolution"
  bottom: "relu_j_1_1"
  top: "conv_j_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_1_2"
  type: "BatchNorm"
  bottom: "conv_j_1_1"
  top: "bn_j_1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_1_2"
  type: "ReLU"
  bottom: "bn_j_1_2"
  top: "relu_j_1_2"
}
layer {
  name: "conv_j_1_2"
  type: "Convolution"
  bottom: "relu_j_1_2"
  top: "conv_j_1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "res_j"
  type: "Convolution"
  bottom: "elt_d_3"
  top: "res_j"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_1"
  type: "Eltwise"
  bottom: "res_j"
  bottom: "conv_j_1_2"
  top: "elt_j_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_2_1"
  type: "BatchNorm"
  bottom: "elt_j_1"
  top: "bn_j_2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_1"
  type: "ReLU"
  bottom: "bn_j_2_1"
  top: "relu_j_2_1"
}
layer {
  name: "conv_j_2_1"
  type: "Convolution"
  bottom: "relu_j_2_1"
  top: "conv_j_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_2_2"
  type: "BatchNorm"
  bottom: "conv_j_2_1"
  top: "bn_j_2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_2_2"
  type: "ReLU"
  bottom: "bn_j_2_2"
  top: "relu_j_2_2"
}
layer {
  name: "conv_j_2_2"
  type: "Convolution"
  bottom: "relu_j_2_2"
  top: "conv_j_2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_2"
  type: "Eltwise"
  bottom: "elt_j_1"
  bottom: "conv_j_2_2"
  top: "elt_j_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_j_3_1"
  type: "BatchNorm"
  bottom: "elt_j_2"
  top: "bn_j_3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_3_1"
  type: "ReLU"
  bottom: "bn_j_3_1"
  top: "relu_j_3_1"
}
layer {
  name: "conv_j_3_1"
  type: "Convolution"
  bottom: "relu_j_3_1"
  top: "conv_j_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_j_3_2"
  type: "BatchNorm"
  bottom: "conv_j_3_1"
  top: "bn_j_3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_j_3_2"
  type: "ReLU"
  bottom: "bn_j_3_2"
  top: "relu_j_3_2"
}
layer {
  name: "conv_j_3_2"
  type: "Convolution"
  bottom: "relu_j_3_2"
  top: "conv_j_3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "elt_j_3"
  type: "Eltwise"
  bottom: "elt_j_2"
  bottom: "conv_j_3_2"
  top: "elt_j_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "bn_m_1_1"
  type: "BatchNorm"
  bottom: "elt_j_3"
  top: "bn_m_1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "relu_m_1_1"
  type: "ReLU"
  bottom: "bn_m_1_1"
  top: "relu_m_1_1"
}
layer {
  name: "gap"
  type: "Pooling"
  bottom: "relu_m_1_1"
  top: "gap"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 1
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "gap"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0622 19:43:12.583299 36972 layer_factory.hpp:77] Creating layer resnet
I0622 19:43:12.583443 36972 net.cpp:91] Creating Layer resnet
I0622 19:43:12.583458 36972 net.cpp:399] resnet -> data
I0622 19:43:12.583472 36972 net.cpp:399] resnet -> label
I0622 19:43:12.583485 36972 data_transformer.cpp:25] Loading mean file from: /home/takeki/caffe/examples/cifar10/mean.binaryproto
I0622 19:43:12.584390 37019 db_lmdb.cpp:35] Opened lmdb /home/takeki/caffe/examples/cifar10/cifar10_test_lmdb
I0622 19:43:12.584537 36972 data_layer.cpp:41] output data size: 100,3,32,32
I0622 19:43:12.588120 36972 net.cpp:141] Setting up resnet
I0622 19:43:12.588141 36972 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0622 19:43:12.588150 36972 net.cpp:148] Top shape: 100 (100)
I0622 19:43:12.588155 36972 net.cpp:156] Memory required for data: 1229200
I0622 19:43:12.588162 36972 layer_factory.hpp:77] Creating layer label_resnet_1_split
I0622 19:43:12.588173 36972 net.cpp:91] Creating Layer label_resnet_1_split
I0622 19:43:12.588182 36972 net.cpp:425] label_resnet_1_split <- label
I0622 19:43:12.588193 36972 net.cpp:399] label_resnet_1_split -> label_resnet_1_split_0
I0622 19:43:12.588206 36972 net.cpp:399] label_resnet_1_split -> label_resnet_1_split_1
I0622 19:43:12.588342 36972 net.cpp:141] Setting up label_resnet_1_split
I0622 19:43:12.588357 36972 net.cpp:148] Top shape: 100 (100)
I0622 19:43:12.588367 36972 net.cpp:148] Top shape: 100 (100)
I0622 19:43:12.588372 36972 net.cpp:156] Memory required for data: 1230000
I0622 19:43:12.588378 36972 layer_factory.hpp:77] Creating layer conv0
I0622 19:43:12.588397 36972 net.cpp:91] Creating Layer conv0
I0622 19:43:12.588404 36972 net.cpp:425] conv0 <- data
I0622 19:43:12.588415 36972 net.cpp:399] conv0 -> conv0
I0622 19:43:12.589886 36972 net.cpp:141] Setting up conv0
I0622 19:43:12.589910 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.589917 36972 net.cpp:156] Memory required for data: 7783600
I0622 19:43:12.589941 36972 layer_factory.hpp:77] Creating layer conv0_conv0_0_split
I0622 19:43:12.589951 36972 net.cpp:91] Creating Layer conv0_conv0_0_split
I0622 19:43:12.589958 36972 net.cpp:425] conv0_conv0_0_split <- conv0
I0622 19:43:12.589969 36972 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_0
I0622 19:43:12.589980 36972 net.cpp:399] conv0_conv0_0_split -> conv0_conv0_0_split_1
I0622 19:43:12.590070 36972 net.cpp:141] Setting up conv0_conv0_0_split
I0622 19:43:12.590085 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.590093 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.590102 36972 net.cpp:156] Memory required for data: 20890800
I0622 19:43:12.590109 36972 layer_factory.hpp:77] Creating layer bn_a_1_1
I0622 19:43:12.590122 36972 net.cpp:91] Creating Layer bn_a_1_1
I0622 19:43:12.590131 36972 net.cpp:425] bn_a_1_1 <- conv0_conv0_0_split_0
I0622 19:43:12.590142 36972 net.cpp:399] bn_a_1_1 -> bn_a_1_1
I0622 19:43:12.590410 36972 net.cpp:141] Setting up bn_a_1_1
I0622 19:43:12.590427 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.590433 36972 net.cpp:156] Memory required for data: 27444400
I0622 19:43:12.590450 36972 layer_factory.hpp:77] Creating layer relu_a_1_1
I0622 19:43:12.590457 36972 net.cpp:91] Creating Layer relu_a_1_1
I0622 19:43:12.590463 36972 net.cpp:425] relu_a_1_1 <- bn_a_1_1
I0622 19:43:12.590476 36972 net.cpp:399] relu_a_1_1 -> relu_a_1_1
I0622 19:43:12.590859 36972 net.cpp:141] Setting up relu_a_1_1
I0622 19:43:12.590878 36972 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0622 19:43:12.590886 36972 net.cpp:156] Memory required for data: 33998000
I0622 19:43:12.590900 36972 layer_factory.hpp:77] Creating layer conv_a_1_1
I0622 19:43:12.590916 36972 net.cpp:91] Creating Layer conv_a_1_1
I0622 19:43:12.590925 36972 net.cpp:425] conv_a_1_1 <- relu_a_1_1
I0622 19:43:12.590940 36972 net.cpp:399] conv_a_1_1 -> conv_a_1_1
I0622 19:43:12.592347 36972 net.cpp:141] Setting up conv_a_1_1
I0622 19:43:12.592370 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.592378 36972 net.cpp:156] Memory required for data: 60212400
I0622 19:43:12.592391 36972 layer_factory.hpp:77] Creating layer bn_a_1_2
I0622 19:43:12.592409 36972 net.cpp:91] Creating Layer bn_a_1_2
I0622 19:43:12.592418 36972 net.cpp:425] bn_a_1_2 <- conv_a_1_1
I0622 19:43:12.592430 36972 net.cpp:399] bn_a_1_2 -> bn_a_1_2
I0622 19:43:12.592867 36972 net.cpp:141] Setting up bn_a_1_2
I0622 19:43:12.592890 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.592905 36972 net.cpp:156] Memory required for data: 86426800
I0622 19:43:12.592926 36972 layer_factory.hpp:77] Creating layer relu_a_1_2
I0622 19:43:12.592936 36972 net.cpp:91] Creating Layer relu_a_1_2
I0622 19:43:12.592944 36972 net.cpp:425] relu_a_1_2 <- bn_a_1_2
I0622 19:43:12.592958 36972 net.cpp:399] relu_a_1_2 -> relu_a_1_2
I0622 19:43:12.593322 36972 net.cpp:141] Setting up relu_a_1_2
I0622 19:43:12.593344 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.593353 36972 net.cpp:156] Memory required for data: 112641200
I0622 19:43:12.593360 36972 layer_factory.hpp:77] Creating layer conv_a_1_2
I0622 19:43:12.593375 36972 net.cpp:91] Creating Layer conv_a_1_2
I0622 19:43:12.593384 36972 net.cpp:425] conv_a_1_2 <- relu_a_1_2
I0622 19:43:12.593397 36972 net.cpp:399] conv_a_1_2 -> conv_a_1_2
I0622 19:43:12.595868 36972 net.cpp:141] Setting up conv_a_1_2
I0622 19:43:12.595890 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.595896 36972 net.cpp:156] Memory required for data: 138855600
I0622 19:43:12.595906 36972 layer_factory.hpp:77] Creating layer res_a
I0622 19:43:12.595922 36972 net.cpp:91] Creating Layer res_a
I0622 19:43:12.595932 36972 net.cpp:425] res_a <- conv0_conv0_0_split_1
I0622 19:43:12.595942 36972 net.cpp:399] res_a -> res_a
I0622 19:43:12.597043 36972 net.cpp:141] Setting up res_a
I0622 19:43:12.597064 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.597072 36972 net.cpp:156] Memory required for data: 165070000
I0622 19:43:12.597084 36972 layer_factory.hpp:77] Creating layer elt_a_1
I0622 19:43:12.597092 36972 net.cpp:91] Creating Layer elt_a_1
I0622 19:43:12.597100 36972 net.cpp:425] elt_a_1 <- res_a
I0622 19:43:12.597106 36972 net.cpp:425] elt_a_1 <- conv_a_1_2
I0622 19:43:12.597115 36972 net.cpp:399] elt_a_1 -> elt_a_1
I0622 19:43:12.597158 36972 net.cpp:141] Setting up elt_a_1
I0622 19:43:12.597172 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.597195 36972 net.cpp:156] Memory required for data: 191284400
I0622 19:43:12.597205 36972 layer_factory.hpp:77] Creating layer elt_a_1_elt_a_1_0_split
I0622 19:43:12.597218 36972 net.cpp:91] Creating Layer elt_a_1_elt_a_1_0_split
I0622 19:43:12.597225 36972 net.cpp:425] elt_a_1_elt_a_1_0_split <- elt_a_1
I0622 19:43:12.597234 36972 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_0
I0622 19:43:12.597244 36972 net.cpp:399] elt_a_1_elt_a_1_0_split -> elt_a_1_elt_a_1_0_split_1
I0622 19:43:12.597308 36972 net.cpp:141] Setting up elt_a_1_elt_a_1_0_split
I0622 19:43:12.597322 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.597332 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.597339 36972 net.cpp:156] Memory required for data: 243713200
I0622 19:43:12.597345 36972 layer_factory.hpp:77] Creating layer bn_a_2_1
I0622 19:43:12.597358 36972 net.cpp:91] Creating Layer bn_a_2_1
I0622 19:43:12.597367 36972 net.cpp:425] bn_a_2_1 <- elt_a_1_elt_a_1_0_split_0
I0622 19:43:12.597376 36972 net.cpp:399] bn_a_2_1 -> bn_a_2_1
I0622 19:43:12.597640 36972 net.cpp:141] Setting up bn_a_2_1
I0622 19:43:12.597656 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.597662 36972 net.cpp:156] Memory required for data: 269927600
I0622 19:43:12.597681 36972 layer_factory.hpp:77] Creating layer relu_a_2_1
I0622 19:43:12.597690 36972 net.cpp:91] Creating Layer relu_a_2_1
I0622 19:43:12.597698 36972 net.cpp:425] relu_a_2_1 <- bn_a_2_1
I0622 19:43:12.597707 36972 net.cpp:399] relu_a_2_1 -> relu_a_2_1
I0622 19:43:12.598069 36972 net.cpp:141] Setting up relu_a_2_1
I0622 19:43:12.598088 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.598104 36972 net.cpp:156] Memory required for data: 296142000
I0622 19:43:12.598110 36972 layer_factory.hpp:77] Creating layer conv_a_2_1
I0622 19:43:12.598127 36972 net.cpp:91] Creating Layer conv_a_2_1
I0622 19:43:12.598136 36972 net.cpp:425] conv_a_2_1 <- relu_a_2_1
I0622 19:43:12.598148 36972 net.cpp:399] conv_a_2_1 -> conv_a_2_1
I0622 19:43:12.601094 36972 net.cpp:141] Setting up conv_a_2_1
I0622 19:43:12.601114 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.601124 36972 net.cpp:156] Memory required for data: 322356400
I0622 19:43:12.601133 36972 layer_factory.hpp:77] Creating layer bn_a_2_2
I0622 19:43:12.601152 36972 net.cpp:91] Creating Layer bn_a_2_2
I0622 19:43:12.601162 36972 net.cpp:425] bn_a_2_2 <- conv_a_2_1
I0622 19:43:12.601173 36972 net.cpp:399] bn_a_2_2 -> bn_a_2_2
I0622 19:43:12.601449 36972 net.cpp:141] Setting up bn_a_2_2
I0622 19:43:12.601464 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.601471 36972 net.cpp:156] Memory required for data: 348570800
I0622 19:43:12.601482 36972 layer_factory.hpp:77] Creating layer relu_a_2_2
I0622 19:43:12.601492 36972 net.cpp:91] Creating Layer relu_a_2_2
I0622 19:43:12.601500 36972 net.cpp:425] relu_a_2_2 <- bn_a_2_2
I0622 19:43:12.601511 36972 net.cpp:399] relu_a_2_2 -> relu_a_2_2
I0622 19:43:12.601754 36972 net.cpp:141] Setting up relu_a_2_2
I0622 19:43:12.601770 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.601778 36972 net.cpp:156] Memory required for data: 374785200
I0622 19:43:12.601786 36972 layer_factory.hpp:77] Creating layer conv_a_2_2
I0622 19:43:12.601801 36972 net.cpp:91] Creating Layer conv_a_2_2
I0622 19:43:12.601810 36972 net.cpp:425] conv_a_2_2 <- relu_a_2_2
I0622 19:43:12.601822 36972 net.cpp:399] conv_a_2_2 -> conv_a_2_2
I0622 19:43:12.604218 36972 net.cpp:141] Setting up conv_a_2_2
I0622 19:43:12.604238 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.604246 36972 net.cpp:156] Memory required for data: 400999600
I0622 19:43:12.604257 36972 layer_factory.hpp:77] Creating layer elt_a_2
I0622 19:43:12.604270 36972 net.cpp:91] Creating Layer elt_a_2
I0622 19:43:12.604279 36972 net.cpp:425] elt_a_2 <- elt_a_1_elt_a_1_0_split_1
I0622 19:43:12.604288 36972 net.cpp:425] elt_a_2 <- conv_a_2_2
I0622 19:43:12.604298 36972 net.cpp:399] elt_a_2 -> elt_a_2
I0622 19:43:12.604368 36972 net.cpp:141] Setting up elt_a_2
I0622 19:43:12.604383 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.604390 36972 net.cpp:156] Memory required for data: 427214000
I0622 19:43:12.604400 36972 layer_factory.hpp:77] Creating layer elt_a_2_elt_a_2_0_split
I0622 19:43:12.604408 36972 net.cpp:91] Creating Layer elt_a_2_elt_a_2_0_split
I0622 19:43:12.604416 36972 net.cpp:425] elt_a_2_elt_a_2_0_split <- elt_a_2
I0622 19:43:12.604427 36972 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_0
I0622 19:43:12.604439 36972 net.cpp:399] elt_a_2_elt_a_2_0_split -> elt_a_2_elt_a_2_0_split_1
I0622 19:43:12.604496 36972 net.cpp:141] Setting up elt_a_2_elt_a_2_0_split
I0622 19:43:12.604509 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.604517 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.604524 36972 net.cpp:156] Memory required for data: 479642800
I0622 19:43:12.604532 36972 layer_factory.hpp:77] Creating layer bn_a_3_1
I0622 19:43:12.604543 36972 net.cpp:91] Creating Layer bn_a_3_1
I0622 19:43:12.604552 36972 net.cpp:425] bn_a_3_1 <- elt_a_2_elt_a_2_0_split_0
I0622 19:43:12.604564 36972 net.cpp:399] bn_a_3_1 -> bn_a_3_1
I0622 19:43:12.604843 36972 net.cpp:141] Setting up bn_a_3_1
I0622 19:43:12.604858 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.604866 36972 net.cpp:156] Memory required for data: 505857200
I0622 19:43:12.604877 36972 layer_factory.hpp:77] Creating layer relu_a_3_1
I0622 19:43:12.604887 36972 net.cpp:91] Creating Layer relu_a_3_1
I0622 19:43:12.604895 36972 net.cpp:425] relu_a_3_1 <- bn_a_3_1
I0622 19:43:12.604905 36972 net.cpp:399] relu_a_3_1 -> relu_a_3_1
I0622 19:43:12.605271 36972 net.cpp:141] Setting up relu_a_3_1
I0622 19:43:12.605288 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.605296 36972 net.cpp:156] Memory required for data: 532071600
I0622 19:43:12.605304 36972 layer_factory.hpp:77] Creating layer conv_a_3_1
I0622 19:43:12.605319 36972 net.cpp:91] Creating Layer conv_a_3_1
I0622 19:43:12.605329 36972 net.cpp:425] conv_a_3_1 <- relu_a_3_1
I0622 19:43:12.605342 36972 net.cpp:399] conv_a_3_1 -> conv_a_3_1
I0622 19:43:12.607846 36972 net.cpp:141] Setting up conv_a_3_1
I0622 19:43:12.607867 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.607877 36972 net.cpp:156] Memory required for data: 558286000
I0622 19:43:12.607888 36972 layer_factory.hpp:77] Creating layer bn_a_3_2
I0622 19:43:12.607900 36972 net.cpp:91] Creating Layer bn_a_3_2
I0622 19:43:12.607908 36972 net.cpp:425] bn_a_3_2 <- conv_a_3_1
I0622 19:43:12.607923 36972 net.cpp:399] bn_a_3_2 -> bn_a_3_2
I0622 19:43:12.608206 36972 net.cpp:141] Setting up bn_a_3_2
I0622 19:43:12.608220 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.608227 36972 net.cpp:156] Memory required for data: 584500400
I0622 19:43:12.608242 36972 layer_factory.hpp:77] Creating layer relu_a_3_2
I0622 19:43:12.608255 36972 net.cpp:91] Creating Layer relu_a_3_2
I0622 19:43:12.608263 36972 net.cpp:425] relu_a_3_2 <- bn_a_3_2
I0622 19:43:12.608273 36972 net.cpp:399] relu_a_3_2 -> relu_a_3_2
I0622 19:43:12.608652 36972 net.cpp:141] Setting up relu_a_3_2
I0622 19:43:12.608670 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.608677 36972 net.cpp:156] Memory required for data: 610714800
I0622 19:43:12.608685 36972 layer_factory.hpp:77] Creating layer conv_a_3_2
I0622 19:43:12.608701 36972 net.cpp:91] Creating Layer conv_a_3_2
I0622 19:43:12.608710 36972 net.cpp:425] conv_a_3_2 <- relu_a_3_2
I0622 19:43:12.608723 36972 net.cpp:399] conv_a_3_2 -> conv_a_3_2
I0622 19:43:12.611148 36972 net.cpp:141] Setting up conv_a_3_2
I0622 19:43:12.611167 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.611176 36972 net.cpp:156] Memory required for data: 636929200
I0622 19:43:12.611196 36972 layer_factory.hpp:77] Creating layer elt_a_3
I0622 19:43:12.611207 36972 net.cpp:91] Creating Layer elt_a_3
I0622 19:43:12.611214 36972 net.cpp:425] elt_a_3 <- elt_a_2_elt_a_2_0_split_1
I0622 19:43:12.611243 36972 net.cpp:425] elt_a_3 <- conv_a_3_2
I0622 19:43:12.611256 36972 net.cpp:399] elt_a_3 -> elt_a_3
I0622 19:43:12.611306 36972 net.cpp:141] Setting up elt_a_3
I0622 19:43:12.611320 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.611327 36972 net.cpp:156] Memory required for data: 663143600
I0622 19:43:12.611336 36972 layer_factory.hpp:77] Creating layer elt_a_3_elt_a_3_0_split
I0622 19:43:12.611346 36972 net.cpp:91] Creating Layer elt_a_3_elt_a_3_0_split
I0622 19:43:12.611352 36972 net.cpp:425] elt_a_3_elt_a_3_0_split <- elt_a_3
I0622 19:43:12.611363 36972 net.cpp:399] elt_a_3_elt_a_3_0_split -> elt_a_3_elt_a_3_0_split_0
I0622 19:43:12.611376 36972 net.cpp:399] elt_a_3_elt_a_3_0_split -> elt_a_3_elt_a_3_0_split_1
I0622 19:43:12.611431 36972 net.cpp:141] Setting up elt_a_3_elt_a_3_0_split
I0622 19:43:12.611446 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.611455 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.611462 36972 net.cpp:156] Memory required for data: 715572400
I0622 19:43:12.611469 36972 layer_factory.hpp:77] Creating layer bn_d_1_1
I0622 19:43:12.611479 36972 net.cpp:91] Creating Layer bn_d_1_1
I0622 19:43:12.611487 36972 net.cpp:425] bn_d_1_1 <- elt_a_3_elt_a_3_0_split_0
I0622 19:43:12.611498 36972 net.cpp:399] bn_d_1_1 -> bn_d_1_1
I0622 19:43:12.611764 36972 net.cpp:141] Setting up bn_d_1_1
I0622 19:43:12.611779 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.611786 36972 net.cpp:156] Memory required for data: 741786800
I0622 19:43:12.611799 36972 layer_factory.hpp:77] Creating layer relu_d_1_1
I0622 19:43:12.611814 36972 net.cpp:91] Creating Layer relu_d_1_1
I0622 19:43:12.611822 36972 net.cpp:425] relu_d_1_1 <- bn_d_1_1
I0622 19:43:12.611830 36972 net.cpp:399] relu_d_1_1 -> relu_d_1_1
I0622 19:43:12.612069 36972 net.cpp:141] Setting up relu_d_1_1
I0622 19:43:12.612085 36972 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I0622 19:43:12.612093 36972 net.cpp:156] Memory required for data: 768001200
I0622 19:43:12.612099 36972 layer_factory.hpp:77] Creating layer conv_d_1_1
I0622 19:43:12.612114 36972 net.cpp:91] Creating Layer conv_d_1_1
I0622 19:43:12.612123 36972 net.cpp:425] conv_d_1_1 <- relu_d_1_1
I0622 19:43:12.612135 36972 net.cpp:399] conv_d_1_1 -> conv_d_1_1
I0622 19:43:12.615736 36972 net.cpp:141] Setting up conv_d_1_1
I0622 19:43:12.615754 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.615768 36972 net.cpp:156] Memory required for data: 781108400
I0622 19:43:12.615778 36972 layer_factory.hpp:77] Creating layer bn_d_1_2
I0622 19:43:12.615795 36972 net.cpp:91] Creating Layer bn_d_1_2
I0622 19:43:12.615803 36972 net.cpp:425] bn_d_1_2 <- conv_d_1_1
I0622 19:43:12.615814 36972 net.cpp:399] bn_d_1_2 -> bn_d_1_2
I0622 19:43:12.616080 36972 net.cpp:141] Setting up bn_d_1_2
I0622 19:43:12.616096 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.616101 36972 net.cpp:156] Memory required for data: 794215600
I0622 19:43:12.616120 36972 layer_factory.hpp:77] Creating layer relu_d_1_2
I0622 19:43:12.616133 36972 net.cpp:91] Creating Layer relu_d_1_2
I0622 19:43:12.616142 36972 net.cpp:425] relu_d_1_2 <- bn_d_1_2
I0622 19:43:12.616150 36972 net.cpp:399] relu_d_1_2 -> relu_d_1_2
I0622 19:43:12.616519 36972 net.cpp:141] Setting up relu_d_1_2
I0622 19:43:12.616536 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.616544 36972 net.cpp:156] Memory required for data: 807322800
I0622 19:43:12.616550 36972 layer_factory.hpp:77] Creating layer conv_d_1_2
I0622 19:43:12.616569 36972 net.cpp:91] Creating Layer conv_d_1_2
I0622 19:43:12.616577 36972 net.cpp:425] conv_d_1_2 <- relu_d_1_2
I0622 19:43:12.616590 36972 net.cpp:399] conv_d_1_2 -> conv_d_1_2
I0622 19:43:12.622834 36972 net.cpp:141] Setting up conv_d_1_2
I0622 19:43:12.622884 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.622892 36972 net.cpp:156] Memory required for data: 820430000
I0622 19:43:12.622905 36972 layer_factory.hpp:77] Creating layer res_d
I0622 19:43:12.622926 36972 net.cpp:91] Creating Layer res_d
I0622 19:43:12.622982 36972 net.cpp:425] res_d <- elt_a_3_elt_a_3_0_split_1
I0622 19:43:12.622999 36972 net.cpp:399] res_d -> res_d
I0622 19:43:12.624406 36972 net.cpp:141] Setting up res_d
I0622 19:43:12.624423 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.624442 36972 net.cpp:156] Memory required for data: 833537200
I0622 19:43:12.624451 36972 layer_factory.hpp:77] Creating layer elt_d_1
I0622 19:43:12.624467 36972 net.cpp:91] Creating Layer elt_d_1
I0622 19:43:12.624476 36972 net.cpp:425] elt_d_1 <- res_d
I0622 19:43:12.624485 36972 net.cpp:425] elt_d_1 <- conv_d_1_2
I0622 19:43:12.624508 36972 net.cpp:399] elt_d_1 -> elt_d_1
I0622 19:43:12.624544 36972 net.cpp:141] Setting up elt_d_1
I0622 19:43:12.624557 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.624564 36972 net.cpp:156] Memory required for data: 846644400
I0622 19:43:12.624570 36972 layer_factory.hpp:77] Creating layer elt_d_1_elt_d_1_0_split
I0622 19:43:12.624582 36972 net.cpp:91] Creating Layer elt_d_1_elt_d_1_0_split
I0622 19:43:12.624589 36972 net.cpp:425] elt_d_1_elt_d_1_0_split <- elt_d_1
I0622 19:43:12.624600 36972 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_0
I0622 19:43:12.624611 36972 net.cpp:399] elt_d_1_elt_d_1_0_split -> elt_d_1_elt_d_1_0_split_1
I0622 19:43:12.624665 36972 net.cpp:141] Setting up elt_d_1_elt_d_1_0_split
I0622 19:43:12.624678 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.624686 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.624692 36972 net.cpp:156] Memory required for data: 872858800
I0622 19:43:12.624699 36972 layer_factory.hpp:77] Creating layer bn_d_2_1
I0622 19:43:12.624713 36972 net.cpp:91] Creating Layer bn_d_2_1
I0622 19:43:12.624722 36972 net.cpp:425] bn_d_2_1 <- elt_d_1_elt_d_1_0_split_0
I0622 19:43:12.624732 36972 net.cpp:399] bn_d_2_1 -> bn_d_2_1
I0622 19:43:12.624999 36972 net.cpp:141] Setting up bn_d_2_1
I0622 19:43:12.625010 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.625017 36972 net.cpp:156] Memory required for data: 885966000
I0622 19:43:12.625028 36972 layer_factory.hpp:77] Creating layer relu_d_2_1
I0622 19:43:12.625038 36972 net.cpp:91] Creating Layer relu_d_2_1
I0622 19:43:12.625046 36972 net.cpp:425] relu_d_2_1 <- bn_d_2_1
I0622 19:43:12.625054 36972 net.cpp:399] relu_d_2_1 -> relu_d_2_1
I0622 19:43:12.625428 36972 net.cpp:141] Setting up relu_d_2_1
I0622 19:43:12.625457 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.625463 36972 net.cpp:156] Memory required for data: 899073200
I0622 19:43:12.625468 36972 layer_factory.hpp:77] Creating layer conv_d_2_1
I0622 19:43:12.625484 36972 net.cpp:91] Creating Layer conv_d_2_1
I0622 19:43:12.625490 36972 net.cpp:425] conv_d_2_1 <- relu_d_2_1
I0622 19:43:12.625512 36972 net.cpp:399] conv_d_2_1 -> conv_d_2_1
I0622 19:43:12.631288 36972 net.cpp:141] Setting up conv_d_2_1
I0622 19:43:12.631316 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.631322 36972 net.cpp:156] Memory required for data: 912180400
I0622 19:43:12.631331 36972 layer_factory.hpp:77] Creating layer bn_d_2_2
I0622 19:43:12.631345 36972 net.cpp:91] Creating Layer bn_d_2_2
I0622 19:43:12.631352 36972 net.cpp:425] bn_d_2_2 <- conv_d_2_1
I0622 19:43:12.631361 36972 net.cpp:399] bn_d_2_2 -> bn_d_2_2
I0622 19:43:12.631629 36972 net.cpp:141] Setting up bn_d_2_2
I0622 19:43:12.631644 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.631651 36972 net.cpp:156] Memory required for data: 925287600
I0622 19:43:12.631664 36972 layer_factory.hpp:77] Creating layer relu_d_2_2
I0622 19:43:12.631672 36972 net.cpp:91] Creating Layer relu_d_2_2
I0622 19:43:12.631680 36972 net.cpp:425] relu_d_2_2 <- bn_d_2_2
I0622 19:43:12.631690 36972 net.cpp:399] relu_d_2_2 -> relu_d_2_2
I0622 19:43:12.631919 36972 net.cpp:141] Setting up relu_d_2_2
I0622 19:43:12.631934 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.631942 36972 net.cpp:156] Memory required for data: 938394800
I0622 19:43:12.631947 36972 layer_factory.hpp:77] Creating layer conv_d_2_2
I0622 19:43:12.631980 36972 net.cpp:91] Creating Layer conv_d_2_2
I0622 19:43:12.631990 36972 net.cpp:425] conv_d_2_2 <- relu_d_2_2
I0622 19:43:12.632001 36972 net.cpp:399] conv_d_2_2 -> conv_d_2_2
I0622 19:43:12.637799 36972 net.cpp:141] Setting up conv_d_2_2
I0622 19:43:12.637830 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.637835 36972 net.cpp:156] Memory required for data: 951502000
I0622 19:43:12.637845 36972 layer_factory.hpp:77] Creating layer elt_d_2
I0622 19:43:12.637854 36972 net.cpp:91] Creating Layer elt_d_2
I0622 19:43:12.637862 36972 net.cpp:425] elt_d_2 <- elt_d_1_elt_d_1_0_split_1
I0622 19:43:12.637882 36972 net.cpp:425] elt_d_2 <- conv_d_2_2
I0622 19:43:12.637892 36972 net.cpp:399] elt_d_2 -> elt_d_2
I0622 19:43:12.637928 36972 net.cpp:141] Setting up elt_d_2
I0622 19:43:12.637940 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.637946 36972 net.cpp:156] Memory required for data: 964609200
I0622 19:43:12.637953 36972 layer_factory.hpp:77] Creating layer elt_d_2_elt_d_2_0_split
I0622 19:43:12.637964 36972 net.cpp:91] Creating Layer elt_d_2_elt_d_2_0_split
I0622 19:43:12.637974 36972 net.cpp:425] elt_d_2_elt_d_2_0_split <- elt_d_2
I0622 19:43:12.637981 36972 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_0
I0622 19:43:12.637992 36972 net.cpp:399] elt_d_2_elt_d_2_0_split -> elt_d_2_elt_d_2_0_split_1
I0622 19:43:12.638046 36972 net.cpp:141] Setting up elt_d_2_elt_d_2_0_split
I0622 19:43:12.638058 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.638067 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.638072 36972 net.cpp:156] Memory required for data: 990823600
I0622 19:43:12.638079 36972 layer_factory.hpp:77] Creating layer bn_d_3_1
I0622 19:43:12.638090 36972 net.cpp:91] Creating Layer bn_d_3_1
I0622 19:43:12.638098 36972 net.cpp:425] bn_d_3_1 <- elt_d_2_elt_d_2_0_split_0
I0622 19:43:12.638109 36972 net.cpp:399] bn_d_3_1 -> bn_d_3_1
I0622 19:43:12.638370 36972 net.cpp:141] Setting up bn_d_3_1
I0622 19:43:12.638383 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.638389 36972 net.cpp:156] Memory required for data: 1003930800
I0622 19:43:12.638417 36972 layer_factory.hpp:77] Creating layer relu_d_3_1
I0622 19:43:12.638425 36972 net.cpp:91] Creating Layer relu_d_3_1
I0622 19:43:12.638432 36972 net.cpp:425] relu_d_3_1 <- bn_d_3_1
I0622 19:43:12.638442 36972 net.cpp:399] relu_d_3_1 -> relu_d_3_1
I0622 19:43:12.638655 36972 net.cpp:141] Setting up relu_d_3_1
I0622 19:43:12.638669 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.638676 36972 net.cpp:156] Memory required for data: 1017038000
I0622 19:43:12.638689 36972 layer_factory.hpp:77] Creating layer conv_d_3_1
I0622 19:43:12.638711 36972 net.cpp:91] Creating Layer conv_d_3_1
I0622 19:43:12.638720 36972 net.cpp:425] conv_d_3_1 <- relu_d_3_1
I0622 19:43:12.638731 36972 net.cpp:399] conv_d_3_1 -> conv_d_3_1
I0622 19:43:12.644596 36972 net.cpp:141] Setting up conv_d_3_1
I0622 19:43:12.644614 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.644623 36972 net.cpp:156] Memory required for data: 1030145200
I0622 19:43:12.644646 36972 layer_factory.hpp:77] Creating layer bn_d_3_2
I0622 19:43:12.644659 36972 net.cpp:91] Creating Layer bn_d_3_2
I0622 19:43:12.644665 36972 net.cpp:425] bn_d_3_2 <- conv_d_3_1
I0622 19:43:12.644672 36972 net.cpp:399] bn_d_3_2 -> bn_d_3_2
I0622 19:43:12.644943 36972 net.cpp:141] Setting up bn_d_3_2
I0622 19:43:12.644958 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.644964 36972 net.cpp:156] Memory required for data: 1043252400
I0622 19:43:12.644975 36972 layer_factory.hpp:77] Creating layer relu_d_3_2
I0622 19:43:12.644984 36972 net.cpp:91] Creating Layer relu_d_3_2
I0622 19:43:12.644990 36972 net.cpp:425] relu_d_3_2 <- bn_d_3_2
I0622 19:43:12.644997 36972 net.cpp:399] relu_d_3_2 -> relu_d_3_2
I0622 19:43:12.645357 36972 net.cpp:141] Setting up relu_d_3_2
I0622 19:43:12.645372 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.645409 36972 net.cpp:156] Memory required for data: 1056359600
I0622 19:43:12.645416 36972 layer_factory.hpp:77] Creating layer conv_d_3_2
I0622 19:43:12.645433 36972 net.cpp:91] Creating Layer conv_d_3_2
I0622 19:43:12.645442 36972 net.cpp:425] conv_d_3_2 <- relu_d_3_2
I0622 19:43:12.645452 36972 net.cpp:399] conv_d_3_2 -> conv_d_3_2
I0622 19:43:12.651232 36972 net.cpp:141] Setting up conv_d_3_2
I0622 19:43:12.651259 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.651267 36972 net.cpp:156] Memory required for data: 1069466800
I0622 19:43:12.651293 36972 layer_factory.hpp:77] Creating layer elt_d_3
I0622 19:43:12.651304 36972 net.cpp:91] Creating Layer elt_d_3
I0622 19:43:12.651324 36972 net.cpp:425] elt_d_3 <- elt_d_2_elt_d_2_0_split_1
I0622 19:43:12.651341 36972 net.cpp:425] elt_d_3 <- conv_d_3_2
I0622 19:43:12.651351 36972 net.cpp:399] elt_d_3 -> elt_d_3
I0622 19:43:12.651386 36972 net.cpp:141] Setting up elt_d_3
I0622 19:43:12.651398 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.651407 36972 net.cpp:156] Memory required for data: 1082574000
I0622 19:43:12.651412 36972 layer_factory.hpp:77] Creating layer elt_d_3_elt_d_3_0_split
I0622 19:43:12.651423 36972 net.cpp:91] Creating Layer elt_d_3_elt_d_3_0_split
I0622 19:43:12.651429 36972 net.cpp:425] elt_d_3_elt_d_3_0_split <- elt_d_3
I0622 19:43:12.651437 36972 net.cpp:399] elt_d_3_elt_d_3_0_split -> elt_d_3_elt_d_3_0_split_0
I0622 19:43:12.651445 36972 net.cpp:399] elt_d_3_elt_d_3_0_split -> elt_d_3_elt_d_3_0_split_1
I0622 19:43:12.651502 36972 net.cpp:141] Setting up elt_d_3_elt_d_3_0_split
I0622 19:43:12.651515 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.651523 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.651530 36972 net.cpp:156] Memory required for data: 1108788400
I0622 19:43:12.651536 36972 layer_factory.hpp:77] Creating layer bn_j_1_1
I0622 19:43:12.651549 36972 net.cpp:91] Creating Layer bn_j_1_1
I0622 19:43:12.651556 36972 net.cpp:425] bn_j_1_1 <- elt_d_3_elt_d_3_0_split_0
I0622 19:43:12.651566 36972 net.cpp:399] bn_j_1_1 -> bn_j_1_1
I0622 19:43:12.651829 36972 net.cpp:141] Setting up bn_j_1_1
I0622 19:43:12.651841 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.651847 36972 net.cpp:156] Memory required for data: 1121895600
I0622 19:43:12.651857 36972 layer_factory.hpp:77] Creating layer relu_j_1_1
I0622 19:43:12.651870 36972 net.cpp:91] Creating Layer relu_j_1_1
I0622 19:43:12.651876 36972 net.cpp:425] relu_j_1_1 <- bn_j_1_1
I0622 19:43:12.651885 36972 net.cpp:399] relu_j_1_1 -> relu_j_1_1
I0622 19:43:12.652119 36972 net.cpp:141] Setting up relu_j_1_1
I0622 19:43:12.652137 36972 net.cpp:148] Top shape: 100 128 16 16 (3276800)
I0622 19:43:12.652143 36972 net.cpp:156] Memory required for data: 1135002800
I0622 19:43:12.652151 36972 layer_factory.hpp:77] Creating layer conv_j_1_1
I0622 19:43:12.652168 36972 net.cpp:91] Creating Layer conv_j_1_1
I0622 19:43:12.652174 36972 net.cpp:425] conv_j_1_1 <- relu_j_1_1
I0622 19:43:12.652185 36972 net.cpp:399] conv_j_1_1 -> conv_j_1_1
I0622 19:43:12.661813 36972 net.cpp:141] Setting up conv_j_1_1
I0622 19:43:12.661841 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.661849 36972 net.cpp:156] Memory required for data: 1141556400
I0622 19:43:12.661856 36972 layer_factory.hpp:77] Creating layer bn_j_1_2
I0622 19:43:12.661869 36972 net.cpp:91] Creating Layer bn_j_1_2
I0622 19:43:12.661875 36972 net.cpp:425] bn_j_1_2 <- conv_j_1_1
I0622 19:43:12.661885 36972 net.cpp:399] bn_j_1_2 -> bn_j_1_2
I0622 19:43:12.662163 36972 net.cpp:141] Setting up bn_j_1_2
I0622 19:43:12.662178 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.662184 36972 net.cpp:156] Memory required for data: 1148110000
I0622 19:43:12.662195 36972 layer_factory.hpp:77] Creating layer relu_j_1_2
I0622 19:43:12.662204 36972 net.cpp:91] Creating Layer relu_j_1_2
I0622 19:43:12.662210 36972 net.cpp:425] relu_j_1_2 <- bn_j_1_2
I0622 19:43:12.662217 36972 net.cpp:399] relu_j_1_2 -> relu_j_1_2
I0622 19:43:12.662467 36972 net.cpp:141] Setting up relu_j_1_2
I0622 19:43:12.662482 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.662488 36972 net.cpp:156] Memory required for data: 1154663600
I0622 19:43:12.662494 36972 layer_factory.hpp:77] Creating layer conv_j_1_2
I0622 19:43:12.662511 36972 net.cpp:91] Creating Layer conv_j_1_2
I0622 19:43:12.662519 36972 net.cpp:425] conv_j_1_2 <- relu_j_1_2
I0622 19:43:12.662533 36972 net.cpp:399] conv_j_1_2 -> conv_j_1_2
I0622 19:43:12.681015 36972 net.cpp:141] Setting up conv_j_1_2
I0622 19:43:12.681044 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.681051 36972 net.cpp:156] Memory required for data: 1161217200
I0622 19:43:12.681059 36972 layer_factory.hpp:77] Creating layer res_j
I0622 19:43:12.681076 36972 net.cpp:91] Creating Layer res_j
I0622 19:43:12.681085 36972 net.cpp:425] res_j <- elt_d_3_elt_d_3_0_split_1
I0622 19:43:12.681110 36972 net.cpp:399] res_j -> res_j
I0622 19:43:12.683161 36972 net.cpp:141] Setting up res_j
I0622 19:43:12.683176 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.683195 36972 net.cpp:156] Memory required for data: 1167770800
I0622 19:43:12.683204 36972 layer_factory.hpp:77] Creating layer elt_j_1
I0622 19:43:12.683213 36972 net.cpp:91] Creating Layer elt_j_1
I0622 19:43:12.683218 36972 net.cpp:425] elt_j_1 <- res_j
I0622 19:43:12.683228 36972 net.cpp:425] elt_j_1 <- conv_j_1_2
I0622 19:43:12.683253 36972 net.cpp:399] elt_j_1 -> elt_j_1
I0622 19:43:12.683295 36972 net.cpp:141] Setting up elt_j_1
I0622 19:43:12.683308 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.683315 36972 net.cpp:156] Memory required for data: 1174324400
I0622 19:43:12.683321 36972 layer_factory.hpp:77] Creating layer elt_j_1_elt_j_1_0_split
I0622 19:43:12.683331 36972 net.cpp:91] Creating Layer elt_j_1_elt_j_1_0_split
I0622 19:43:12.683338 36972 net.cpp:425] elt_j_1_elt_j_1_0_split <- elt_j_1
I0622 19:43:12.683346 36972 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_0
I0622 19:43:12.683359 36972 net.cpp:399] elt_j_1_elt_j_1_0_split -> elt_j_1_elt_j_1_0_split_1
I0622 19:43:12.683418 36972 net.cpp:141] Setting up elt_j_1_elt_j_1_0_split
I0622 19:43:12.683430 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.683439 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.683446 36972 net.cpp:156] Memory required for data: 1187431600
I0622 19:43:12.683452 36972 layer_factory.hpp:77] Creating layer bn_j_2_1
I0622 19:43:12.683466 36972 net.cpp:91] Creating Layer bn_j_2_1
I0622 19:43:12.683475 36972 net.cpp:425] bn_j_2_1 <- elt_j_1_elt_j_1_0_split_0
I0622 19:43:12.683485 36972 net.cpp:399] bn_j_2_1 -> bn_j_2_1
I0622 19:43:12.683748 36972 net.cpp:141] Setting up bn_j_2_1
I0622 19:43:12.683760 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.683765 36972 net.cpp:156] Memory required for data: 1193985200
I0622 19:43:12.683776 36972 layer_factory.hpp:77] Creating layer relu_j_2_1
I0622 19:43:12.683794 36972 net.cpp:91] Creating Layer relu_j_2_1
I0622 19:43:12.683801 36972 net.cpp:425] relu_j_2_1 <- bn_j_2_1
I0622 19:43:12.683812 36972 net.cpp:399] relu_j_2_1 -> relu_j_2_1
I0622 19:43:12.684188 36972 net.cpp:141] Setting up relu_j_2_1
I0622 19:43:12.684203 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.684211 36972 net.cpp:156] Memory required for data: 1200538800
I0622 19:43:12.684217 36972 layer_factory.hpp:77] Creating layer conv_j_2_1
I0622 19:43:12.684234 36972 net.cpp:91] Creating Layer conv_j_2_1
I0622 19:43:12.684243 36972 net.cpp:425] conv_j_2_1 <- relu_j_2_1
I0622 19:43:12.684255 36972 net.cpp:399] conv_j_2_1 -> conv_j_2_1
I0622 19:43:12.702512 36972 net.cpp:141] Setting up conv_j_2_1
I0622 19:43:12.702530 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.702549 36972 net.cpp:156] Memory required for data: 1207092400
I0622 19:43:12.702558 36972 layer_factory.hpp:77] Creating layer bn_j_2_2
I0622 19:43:12.702571 36972 net.cpp:91] Creating Layer bn_j_2_2
I0622 19:43:12.702577 36972 net.cpp:425] bn_j_2_2 <- conv_j_2_1
I0622 19:43:12.702620 36972 net.cpp:399] bn_j_2_2 -> bn_j_2_2
I0622 19:43:12.702949 36972 net.cpp:141] Setting up bn_j_2_2
I0622 19:43:12.702963 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.702968 36972 net.cpp:156] Memory required for data: 1213646000
I0622 19:43:12.702993 36972 layer_factory.hpp:77] Creating layer relu_j_2_2
I0622 19:43:12.703002 36972 net.cpp:91] Creating Layer relu_j_2_2
I0622 19:43:12.703008 36972 net.cpp:425] relu_j_2_2 <- bn_j_2_2
I0622 19:43:12.703018 36972 net.cpp:399] relu_j_2_2 -> relu_j_2_2
I0622 19:43:12.703404 36972 net.cpp:141] Setting up relu_j_2_2
I0622 19:43:12.703420 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.703439 36972 net.cpp:156] Memory required for data: 1220199600
I0622 19:43:12.703445 36972 layer_factory.hpp:77] Creating layer conv_j_2_2
I0622 19:43:12.703461 36972 net.cpp:91] Creating Layer conv_j_2_2
I0622 19:43:12.703470 36972 net.cpp:425] conv_j_2_2 <- relu_j_2_2
I0622 19:43:12.703482 36972 net.cpp:399] conv_j_2_2 -> conv_j_2_2
I0622 19:43:12.721673 36972 net.cpp:141] Setting up conv_j_2_2
I0622 19:43:12.721699 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.721705 36972 net.cpp:156] Memory required for data: 1226753200
I0622 19:43:12.721715 36972 layer_factory.hpp:77] Creating layer elt_j_2
I0622 19:43:12.721727 36972 net.cpp:91] Creating Layer elt_j_2
I0622 19:43:12.721735 36972 net.cpp:425] elt_j_2 <- elt_j_1_elt_j_1_0_split_1
I0622 19:43:12.721745 36972 net.cpp:425] elt_j_2 <- conv_j_2_2
I0622 19:43:12.721753 36972 net.cpp:399] elt_j_2 -> elt_j_2
I0622 19:43:12.721794 36972 net.cpp:141] Setting up elt_j_2
I0622 19:43:12.721808 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.721815 36972 net.cpp:156] Memory required for data: 1233306800
I0622 19:43:12.721822 36972 layer_factory.hpp:77] Creating layer elt_j_2_elt_j_2_0_split
I0622 19:43:12.721832 36972 net.cpp:91] Creating Layer elt_j_2_elt_j_2_0_split
I0622 19:43:12.721838 36972 net.cpp:425] elt_j_2_elt_j_2_0_split <- elt_j_2
I0622 19:43:12.721849 36972 net.cpp:399] elt_j_2_elt_j_2_0_split -> elt_j_2_elt_j_2_0_split_0
I0622 19:43:12.721860 36972 net.cpp:399] elt_j_2_elt_j_2_0_split -> elt_j_2_elt_j_2_0_split_1
I0622 19:43:12.721917 36972 net.cpp:141] Setting up elt_j_2_elt_j_2_0_split
I0622 19:43:12.721930 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.721938 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.721945 36972 net.cpp:156] Memory required for data: 1246414000
I0622 19:43:12.721951 36972 layer_factory.hpp:77] Creating layer bn_j_3_1
I0622 19:43:12.721963 36972 net.cpp:91] Creating Layer bn_j_3_1
I0622 19:43:12.721971 36972 net.cpp:425] bn_j_3_1 <- elt_j_2_elt_j_2_0_split_0
I0622 19:43:12.721983 36972 net.cpp:399] bn_j_3_1 -> bn_j_3_1
I0622 19:43:12.722267 36972 net.cpp:141] Setting up bn_j_3_1
I0622 19:43:12.722280 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.722286 36972 net.cpp:156] Memory required for data: 1252967600
I0622 19:43:12.722297 36972 layer_factory.hpp:77] Creating layer relu_j_3_1
I0622 19:43:12.722307 36972 net.cpp:91] Creating Layer relu_j_3_1
I0622 19:43:12.722314 36972 net.cpp:425] relu_j_3_1 <- bn_j_3_1
I0622 19:43:12.722323 36972 net.cpp:399] relu_j_3_1 -> relu_j_3_1
I0622 19:43:12.722545 36972 net.cpp:141] Setting up relu_j_3_1
I0622 19:43:12.722559 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.722566 36972 net.cpp:156] Memory required for data: 1259521200
I0622 19:43:12.722571 36972 layer_factory.hpp:77] Creating layer conv_j_3_1
I0622 19:43:12.722589 36972 net.cpp:91] Creating Layer conv_j_3_1
I0622 19:43:12.722596 36972 net.cpp:425] conv_j_3_1 <- relu_j_3_1
I0622 19:43:12.722609 36972 net.cpp:399] conv_j_3_1 -> conv_j_3_1
I0622 19:43:12.741031 36972 net.cpp:141] Setting up conv_j_3_1
I0622 19:43:12.741050 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.741056 36972 net.cpp:156] Memory required for data: 1266074800
I0622 19:43:12.741067 36972 layer_factory.hpp:77] Creating layer bn_j_3_2
I0622 19:43:12.741102 36972 net.cpp:91] Creating Layer bn_j_3_2
I0622 19:43:12.741113 36972 net.cpp:425] bn_j_3_2 <- conv_j_3_1
I0622 19:43:12.741124 36972 net.cpp:399] bn_j_3_2 -> bn_j_3_2
I0622 19:43:12.741406 36972 net.cpp:141] Setting up bn_j_3_2
I0622 19:43:12.741420 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.741425 36972 net.cpp:156] Memory required for data: 1272628400
I0622 19:43:12.741438 36972 layer_factory.hpp:77] Creating layer relu_j_3_2
I0622 19:43:12.741449 36972 net.cpp:91] Creating Layer relu_j_3_2
I0622 19:43:12.741457 36972 net.cpp:425] relu_j_3_2 <- bn_j_3_2
I0622 19:43:12.741466 36972 net.cpp:399] relu_j_3_2 -> relu_j_3_2
I0622 19:43:12.741816 36972 net.cpp:141] Setting up relu_j_3_2
I0622 19:43:12.741832 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.741837 36972 net.cpp:156] Memory required for data: 1279182000
I0622 19:43:12.741842 36972 layer_factory.hpp:77] Creating layer conv_j_3_2
I0622 19:43:12.741859 36972 net.cpp:91] Creating Layer conv_j_3_2
I0622 19:43:12.741865 36972 net.cpp:425] conv_j_3_2 <- relu_j_3_2
I0622 19:43:12.741878 36972 net.cpp:399] conv_j_3_2 -> conv_j_3_2
I0622 19:43:12.760257 36972 net.cpp:141] Setting up conv_j_3_2
I0622 19:43:12.760273 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.760293 36972 net.cpp:156] Memory required for data: 1285735600
I0622 19:43:12.760301 36972 layer_factory.hpp:77] Creating layer elt_j_3
I0622 19:43:12.760310 36972 net.cpp:91] Creating Layer elt_j_3
I0622 19:43:12.760316 36972 net.cpp:425] elt_j_3 <- elt_j_2_elt_j_2_0_split_1
I0622 19:43:12.760324 36972 net.cpp:425] elt_j_3 <- conv_j_3_2
I0622 19:43:12.760335 36972 net.cpp:399] elt_j_3 -> elt_j_3
I0622 19:43:12.760388 36972 net.cpp:141] Setting up elt_j_3
I0622 19:43:12.760401 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.760408 36972 net.cpp:156] Memory required for data: 1292289200
I0622 19:43:12.760416 36972 layer_factory.hpp:77] Creating layer bn_m_1_1
I0622 19:43:12.760429 36972 net.cpp:91] Creating Layer bn_m_1_1
I0622 19:43:12.760437 36972 net.cpp:425] bn_m_1_1 <- elt_j_3
I0622 19:43:12.760448 36972 net.cpp:399] bn_m_1_1 -> bn_m_1_1
I0622 19:43:12.760740 36972 net.cpp:141] Setting up bn_m_1_1
I0622 19:43:12.760767 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.760772 36972 net.cpp:156] Memory required for data: 1298842800
I0622 19:43:12.760782 36972 layer_factory.hpp:77] Creating layer relu_m_1_1
I0622 19:43:12.760790 36972 net.cpp:91] Creating Layer relu_m_1_1
I0622 19:43:12.760797 36972 net.cpp:425] relu_m_1_1 <- bn_m_1_1
I0622 19:43:12.760803 36972 net.cpp:399] relu_m_1_1 -> relu_m_1_1
I0622 19:43:12.761299 36972 net.cpp:141] Setting up relu_m_1_1
I0622 19:43:12.761314 36972 net.cpp:148] Top shape: 100 256 8 8 (1638400)
I0622 19:43:12.761333 36972 net.cpp:156] Memory required for data: 1305396400
I0622 19:43:12.761338 36972 layer_factory.hpp:77] Creating layer gap
I0622 19:43:12.761353 36972 net.cpp:91] Creating Layer gap
I0622 19:43:12.761358 36972 net.cpp:425] gap <- relu_m_1_1
I0622 19:43:12.761365 36972 net.cpp:399] gap -> gap
I0622 19:43:12.761615 36972 net.cpp:141] Setting up gap
I0622 19:43:12.761628 36972 net.cpp:148] Top shape: 100 256 1 1 (25600)
I0622 19:43:12.761636 36972 net.cpp:156] Memory required for data: 1305498800
I0622 19:43:12.761656 36972 layer_factory.hpp:77] Creating layer ip1
I0622 19:43:12.761667 36972 net.cpp:91] Creating Layer ip1
I0622 19:43:12.761673 36972 net.cpp:425] ip1 <- gap
I0622 19:43:12.761683 36972 net.cpp:399] ip1 -> ip1
I0622 19:43:12.761941 36972 net.cpp:141] Setting up ip1
I0622 19:43:12.761955 36972 net.cpp:148] Top shape: 100 10 (1000)
I0622 19:43:12.761976 36972 net.cpp:156] Memory required for data: 1305502800
I0622 19:43:12.761986 36972 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0622 19:43:12.761994 36972 net.cpp:91] Creating Layer ip1_ip1_0_split
I0622 19:43:12.761999 36972 net.cpp:425] ip1_ip1_0_split <- ip1
I0622 19:43:12.762008 36972 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0622 19:43:12.762017 36972 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0622 19:43:12.762109 36972 net.cpp:141] Setting up ip1_ip1_0_split
I0622 19:43:12.762125 36972 net.cpp:148] Top shape: 100 10 (1000)
I0622 19:43:12.762132 36972 net.cpp:148] Top shape: 100 10 (1000)
I0622 19:43:12.762140 36972 net.cpp:156] Memory required for data: 1305510800
I0622 19:43:12.762145 36972 layer_factory.hpp:77] Creating layer accuracy
I0622 19:43:12.762157 36972 net.cpp:91] Creating Layer accuracy
I0622 19:43:12.762164 36972 net.cpp:425] accuracy <- ip1_ip1_0_split_0
I0622 19:43:12.762173 36972 net.cpp:425] accuracy <- label_resnet_1_split_0
I0622 19:43:12.762183 36972 net.cpp:399] accuracy -> accuracy
I0622 19:43:12.762197 36972 net.cpp:141] Setting up accuracy
I0622 19:43:12.762207 36972 net.cpp:148] Top shape: (1)
I0622 19:43:12.762212 36972 net.cpp:156] Memory required for data: 1305510804
I0622 19:43:12.762219 36972 layer_factory.hpp:77] Creating layer loss
I0622 19:43:12.762231 36972 net.cpp:91] Creating Layer loss
I0622 19:43:12.762238 36972 net.cpp:425] loss <- ip1_ip1_0_split_1
I0622 19:43:12.762246 36972 net.cpp:425] loss <- label_resnet_1_split_1
I0622 19:43:12.762254 36972 net.cpp:399] loss -> loss
I0622 19:43:12.762266 36972 layer_factory.hpp:77] Creating layer loss
I0622 19:43:12.762742 36972 net.cpp:141] Setting up loss
I0622 19:43:12.762756 36972 net.cpp:148] Top shape: (1)
I0622 19:43:12.762764 36972 net.cpp:151]     with loss weight 1
I0622 19:43:12.762778 36972 net.cpp:156] Memory required for data: 1305510808
I0622 19:43:12.762784 36972 net.cpp:217] loss needs backward computation.
I0622 19:43:12.762790 36972 net.cpp:219] accuracy does not need backward computation.
I0622 19:43:12.762796 36972 net.cpp:217] ip1_ip1_0_split needs backward computation.
I0622 19:43:12.762800 36972 net.cpp:217] ip1 needs backward computation.
I0622 19:43:12.762805 36972 net.cpp:217] gap needs backward computation.
I0622 19:43:12.762812 36972 net.cpp:217] relu_m_1_1 needs backward computation.
I0622 19:43:12.762819 36972 net.cpp:217] bn_m_1_1 needs backward computation.
I0622 19:43:12.762825 36972 net.cpp:217] elt_j_3 needs backward computation.
I0622 19:43:12.762830 36972 net.cpp:217] conv_j_3_2 needs backward computation.
I0622 19:43:12.762837 36972 net.cpp:217] relu_j_3_2 needs backward computation.
I0622 19:43:12.762842 36972 net.cpp:217] bn_j_3_2 needs backward computation.
I0622 19:43:12.762850 36972 net.cpp:217] conv_j_3_1 needs backward computation.
I0622 19:43:12.762856 36972 net.cpp:217] relu_j_3_1 needs backward computation.
I0622 19:43:12.762861 36972 net.cpp:217] bn_j_3_1 needs backward computation.
I0622 19:43:12.762867 36972 net.cpp:217] elt_j_2_elt_j_2_0_split needs backward computation.
I0622 19:43:12.762873 36972 net.cpp:217] elt_j_2 needs backward computation.
I0622 19:43:12.762881 36972 net.cpp:217] conv_j_2_2 needs backward computation.
I0622 19:43:12.762889 36972 net.cpp:217] relu_j_2_2 needs backward computation.
I0622 19:43:12.762897 36972 net.cpp:217] bn_j_2_2 needs backward computation.
I0622 19:43:12.762903 36972 net.cpp:217] conv_j_2_1 needs backward computation.
I0622 19:43:12.762909 36972 net.cpp:217] relu_j_2_1 needs backward computation.
I0622 19:43:12.762915 36972 net.cpp:217] bn_j_2_1 needs backward computation.
I0622 19:43:12.762923 36972 net.cpp:217] elt_j_1_elt_j_1_0_split needs backward computation.
I0622 19:43:12.762928 36972 net.cpp:217] elt_j_1 needs backward computation.
I0622 19:43:12.762934 36972 net.cpp:217] res_j needs backward computation.
I0622 19:43:12.762943 36972 net.cpp:217] conv_j_1_2 needs backward computation.
I0622 19:43:12.762950 36972 net.cpp:217] relu_j_1_2 needs backward computation.
I0622 19:43:12.762956 36972 net.cpp:217] bn_j_1_2 needs backward computation.
I0622 19:43:12.762962 36972 net.cpp:217] conv_j_1_1 needs backward computation.
I0622 19:43:12.762970 36972 net.cpp:217] relu_j_1_1 needs backward computation.
I0622 19:43:12.762975 36972 net.cpp:217] bn_j_1_1 needs backward computation.
I0622 19:43:12.762982 36972 net.cpp:217] elt_d_3_elt_d_3_0_split needs backward computation.
I0622 19:43:12.762989 36972 net.cpp:217] elt_d_3 needs backward computation.
I0622 19:43:12.763016 36972 net.cpp:217] conv_d_3_2 needs backward computation.
I0622 19:43:12.763025 36972 net.cpp:217] relu_d_3_2 needs backward computation.
I0622 19:43:12.763031 36972 net.cpp:217] bn_d_3_2 needs backward computation.
I0622 19:43:12.763037 36972 net.cpp:217] conv_d_3_1 needs backward computation.
I0622 19:43:12.763044 36972 net.cpp:217] relu_d_3_1 needs backward computation.
I0622 19:43:12.763052 36972 net.cpp:217] bn_d_3_1 needs backward computation.
I0622 19:43:12.763057 36972 net.cpp:217] elt_d_2_elt_d_2_0_split needs backward computation.
I0622 19:43:12.763064 36972 net.cpp:217] elt_d_2 needs backward computation.
I0622 19:43:12.763072 36972 net.cpp:217] conv_d_2_2 needs backward computation.
I0622 19:43:12.763077 36972 net.cpp:217] relu_d_2_2 needs backward computation.
I0622 19:43:12.763084 36972 net.cpp:217] bn_d_2_2 needs backward computation.
I0622 19:43:12.763092 36972 net.cpp:217] conv_d_2_1 needs backward computation.
I0622 19:43:12.763097 36972 net.cpp:217] relu_d_2_1 needs backward computation.
I0622 19:43:12.763103 36972 net.cpp:217] bn_d_2_1 needs backward computation.
I0622 19:43:12.763111 36972 net.cpp:217] elt_d_1_elt_d_1_0_split needs backward computation.
I0622 19:43:12.763118 36972 net.cpp:217] elt_d_1 needs backward computation.
I0622 19:43:12.763128 36972 net.cpp:217] res_d needs backward computation.
I0622 19:43:12.763135 36972 net.cpp:217] conv_d_1_2 needs backward computation.
I0622 19:43:12.763142 36972 net.cpp:217] relu_d_1_2 needs backward computation.
I0622 19:43:12.763149 36972 net.cpp:217] bn_d_1_2 needs backward computation.
I0622 19:43:12.763156 36972 net.cpp:217] conv_d_1_1 needs backward computation.
I0622 19:43:12.763164 36972 net.cpp:217] relu_d_1_1 needs backward computation.
I0622 19:43:12.763170 36972 net.cpp:217] bn_d_1_1 needs backward computation.
I0622 19:43:12.763177 36972 net.cpp:217] elt_a_3_elt_a_3_0_split needs backward computation.
I0622 19:43:12.763185 36972 net.cpp:217] elt_a_3 needs backward computation.
I0622 19:43:12.763192 36972 net.cpp:217] conv_a_3_2 needs backward computation.
I0622 19:43:12.763200 36972 net.cpp:217] relu_a_3_2 needs backward computation.
I0622 19:43:12.763206 36972 net.cpp:217] bn_a_3_2 needs backward computation.
I0622 19:43:12.763212 36972 net.cpp:217] conv_a_3_1 needs backward computation.
I0622 19:43:12.763218 36972 net.cpp:217] relu_a_3_1 needs backward computation.
I0622 19:43:12.763226 36972 net.cpp:217] bn_a_3_1 needs backward computation.
I0622 19:43:12.763231 36972 net.cpp:217] elt_a_2_elt_a_2_0_split needs backward computation.
I0622 19:43:12.763238 36972 net.cpp:217] elt_a_2 needs backward computation.
I0622 19:43:12.763247 36972 net.cpp:217] conv_a_2_2 needs backward computation.
I0622 19:43:12.763253 36972 net.cpp:217] relu_a_2_2 needs backward computation.
I0622 19:43:12.763259 36972 net.cpp:217] bn_a_2_2 needs backward computation.
I0622 19:43:12.763265 36972 net.cpp:217] conv_a_2_1 needs backward computation.
I0622 19:43:12.763273 36972 net.cpp:217] relu_a_2_1 needs backward computation.
I0622 19:43:12.763278 36972 net.cpp:217] bn_a_2_1 needs backward computation.
I0622 19:43:12.763285 36972 net.cpp:217] elt_a_1_elt_a_1_0_split needs backward computation.
I0622 19:43:12.763293 36972 net.cpp:217] elt_a_1 needs backward computation.
I0622 19:43:12.763299 36972 net.cpp:217] res_a needs backward computation.
I0622 19:43:12.763305 36972 net.cpp:217] conv_a_1_2 needs backward computation.
I0622 19:43:12.763312 36972 net.cpp:217] relu_a_1_2 needs backward computation.
I0622 19:43:12.763319 36972 net.cpp:217] bn_a_1_2 needs backward computation.
I0622 19:43:12.763324 36972 net.cpp:217] conv_a_1_1 needs backward computation.
I0622 19:43:12.763331 36972 net.cpp:217] relu_a_1_1 needs backward computation.
I0622 19:43:12.763339 36972 net.cpp:217] bn_a_1_1 needs backward computation.
I0622 19:43:12.763345 36972 net.cpp:217] conv0_conv0_0_split needs backward computation.
I0622 19:43:12.763350 36972 net.cpp:217] conv0 needs backward computation.
I0622 19:43:12.763358 36972 net.cpp:219] label_resnet_1_split does not need backward computation.
I0622 19:43:12.763377 36972 net.cpp:219] resnet does not need backward computation.
I0622 19:43:12.763384 36972 net.cpp:261] This network produces output accuracy
I0622 19:43:12.763391 36972 net.cpp:261] This network produces output loss
I0622 19:43:12.763459 36972 net.cpp:274] Network initialization done.
I0622 19:43:12.763886 36972 solver.cpp:60] Solver scaffolding done.
I0622 19:43:12.768791 36972 caffe.cpp:219] Starting Optimization
I0622 19:43:12.768805 36972 solver.cpp:279] Solving ResNet
I0622 19:43:12.768823 36972 solver.cpp:280] Learning Rate Policy: multistep
I0622 19:43:12.772930 36972 solver.cpp:337] Iteration 0, Testing net (#0)
I0622 19:43:18.530642 36972 solver.cpp:404]     Test net output #0: accuracy = 0.1034
I0622 19:43:18.530730 36972 solver.cpp:404]     Test net output #1: loss = 2.60259 (* 1 = 2.60259 loss)
I0622 19:43:18.618233 36972 solver.cpp:228] Iteration 0, loss = 2.63361
I0622 19:43:18.618271 36972 solver.cpp:244]     Train net output #0: loss = 2.63361 (* 1 = 2.63361 loss)
I0622 19:43:18.618304 36972 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0622 19:43:54.068572 36972 solver.cpp:228] Iteration 200, loss = 1.89066
I0622 19:43:54.068717 36972 solver.cpp:244]     Train net output #0: loss = 1.89066 (* 1 = 1.89066 loss)
I0622 19:43:54.068730 36972 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0622 19:44:31.817015 36972 solver.cpp:228] Iteration 400, loss = 1.7264
I0622 19:44:31.817229 36972 solver.cpp:244]     Train net output #0: loss = 1.7264 (* 1 = 1.7264 loss)
I0622 19:44:31.817291 36972 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0622 19:45:09.576190 36972 solver.cpp:228] Iteration 600, loss = 1.66587
I0622 19:45:09.576421 36972 solver.cpp:244]     Train net output #0: loss = 1.66587 (* 1 = 1.66587 loss)
I0622 19:45:09.576447 36972 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0622 19:45:47.321830 36972 solver.cpp:228] Iteration 800, loss = 1.8657
I0622 19:45:47.322140 36972 solver.cpp:244]     Train net output #0: loss = 1.8657 (* 1 = 1.8657 loss)
I0622 19:45:47.322186 36972 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0622 19:46:25.018631 36972 solver.cpp:337] Iteration 1000, Testing net (#0)
I0622 19:46:31.346470 36972 solver.cpp:404]     Test net output #0: accuracy = 0.3761
I0622 19:46:31.346526 36972 solver.cpp:404]     Test net output #1: loss = 1.73014 (* 1 = 1.73014 loss)
I0622 19:46:31.413880 36972 solver.cpp:228] Iteration 1000, loss = 1.91876
I0622 19:46:31.413918 36972 solver.cpp:244]     Train net output #0: loss = 1.91876 (* 1 = 1.91876 loss)
I0622 19:46:31.413933 36972 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0622 19:47:09.142231 36972 solver.cpp:228] Iteration 1200, loss = 1.82573
I0622 19:47:09.142432 36972 solver.cpp:244]     Train net output #0: loss = 1.82573 (* 1 = 1.82573 loss)
I0622 19:47:09.142446 36972 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0622 19:47:46.875818 36972 solver.cpp:228] Iteration 1400, loss = 1.61738
I0622 19:47:46.876051 36972 solver.cpp:244]     Train net output #0: loss = 1.61738 (* 1 = 1.61738 loss)
I0622 19:47:46.876085 36972 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0622 19:48:24.636314 36972 solver.cpp:228] Iteration 1600, loss = 1.52539
I0622 19:48:24.636523 36972 solver.cpp:244]     Train net output #0: loss = 1.52539 (* 1 = 1.52539 loss)
I0622 19:48:24.636543 36972 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0622 19:49:02.366575 36972 solver.cpp:228] Iteration 1800, loss = 1.70425
I0622 19:49:02.366844 36972 solver.cpp:244]     Train net output #0: loss = 1.70425 (* 1 = 1.70425 loss)
I0622 19:49:02.366859 36972 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0622 19:49:40.019999 36972 solver.cpp:337] Iteration 2000, Testing net (#0)
I0622 19:49:46.339367 36972 solver.cpp:404]     Test net output #0: accuracy = 0.3956
I0622 19:49:46.339426 36972 solver.cpp:404]     Test net output #1: loss = 1.65616 (* 1 = 1.65616 loss)
I0622 19:49:46.405967 36972 solver.cpp:228] Iteration 2000, loss = 1.78204
I0622 19:49:46.406013 36972 solver.cpp:244]     Train net output #0: loss = 1.78204 (* 1 = 1.78204 loss)
I0622 19:49:46.406038 36972 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0622 19:50:24.112504 36972 solver.cpp:228] Iteration 2200, loss = 1.77186
I0622 19:50:24.112762 36972 solver.cpp:244]     Train net output #0: loss = 1.77186 (* 1 = 1.77186 loss)
I0622 19:50:24.112824 36972 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0622 19:51:01.841984 36972 solver.cpp:228] Iteration 2400, loss = 1.59138
I0622 19:51:01.842172 36972 solver.cpp:244]     Train net output #0: loss = 1.59138 (* 1 = 1.59138 loss)
I0622 19:51:01.842185 36972 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0622 19:51:39.595860 36972 solver.cpp:228] Iteration 2600, loss = 1.45131
I0622 19:51:39.596138 36972 solver.cpp:244]     Train net output #0: loss = 1.45131 (* 1 = 1.45131 loss)
I0622 19:51:39.596154 36972 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0622 19:52:17.318322 36972 solver.cpp:228] Iteration 2800, loss = 1.588
I0622 19:52:17.318506 36972 solver.cpp:244]     Train net output #0: loss = 1.588 (* 1 = 1.588 loss)
I0622 19:52:17.318519 36972 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0622 19:52:54.999981 36972 solver.cpp:337] Iteration 3000, Testing net (#0)
I0622 19:53:01.339056 36972 solver.cpp:404]     Test net output #0: accuracy = 0.4214
I0622 19:53:01.339108 36972 solver.cpp:404]     Test net output #1: loss = 1.57045 (* 1 = 1.57045 loss)
I0622 19:53:01.406561 36972 solver.cpp:228] Iteration 3000, loss = 1.758
I0622 19:53:01.406597 36972 solver.cpp:244]     Train net output #0: loss = 1.758 (* 1 = 1.758 loss)
I0622 19:53:01.406610 36972 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0622 19:53:39.121156 36972 solver.cpp:228] Iteration 3200, loss = 1.69006
I0622 19:53:39.121366 36972 solver.cpp:244]     Train net output #0: loss = 1.69006 (* 1 = 1.69006 loss)
I0622 19:53:39.121379 36972 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0622 19:54:16.831504 36972 solver.cpp:228] Iteration 3400, loss = 1.48665
I0622 19:54:16.831707 36972 solver.cpp:244]     Train net output #0: loss = 1.48665 (* 1 = 1.48665 loss)
I0622 19:54:16.831720 36972 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0622 19:54:54.558248 36972 solver.cpp:228] Iteration 3600, loss = 1.38972
I0622 19:54:54.558482 36972 solver.cpp:244]     Train net output #0: loss = 1.38972 (* 1 = 1.38972 loss)
I0622 19:54:54.558558 36972 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0622 19:55:32.279983 36972 solver.cpp:228] Iteration 3800, loss = 1.53478
I0622 19:55:32.280092 36972 solver.cpp:244]     Train net output #0: loss = 1.53478 (* 1 = 1.53478 loss)
I0622 19:55:32.280105 36972 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0622 19:56:09.965311 36972 solver.cpp:337] Iteration 4000, Testing net (#0)
I0622 19:56:16.286203 36972 solver.cpp:404]     Test net output #0: accuracy = 0.4375
I0622 19:56:16.286263 36972 solver.cpp:404]     Test net output #1: loss = 1.53854 (* 1 = 1.53854 loss)
I0622 19:56:16.353097 36972 solver.cpp:228] Iteration 4000, loss = 1.7127
I0622 19:56:16.353127 36972 solver.cpp:244]     Train net output #0: loss = 1.7127 (* 1 = 1.7127 loss)
I0622 19:56:16.353138 36972 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0622 19:56:54.027552 36972 solver.cpp:228] Iteration 4200, loss = 1.65641
I0622 19:56:54.027742 36972 solver.cpp:244]     Train net output #0: loss = 1.65641 (* 1 = 1.65641 loss)
I0622 19:56:54.027755 36972 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0622 19:57:31.728076 36972 solver.cpp:228] Iteration 4400, loss = 1.45956
I0622 19:57:31.728286 36972 solver.cpp:244]     Train net output #0: loss = 1.45956 (* 1 = 1.45956 loss)
I0622 19:57:31.728343 36972 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0622 19:58:09.387054 36972 solver.cpp:228] Iteration 4600, loss = 1.48557
I0622 19:58:09.387213 36972 solver.cpp:244]     Train net output #0: loss = 1.48557 (* 1 = 1.48557 loss)
I0622 19:58:09.387233 36972 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0622 19:58:47.084200 36972 solver.cpp:228] Iteration 4800, loss = 1.52855
I0622 19:58:47.084542 36972 solver.cpp:244]     Train net output #0: loss = 1.52855 (* 1 = 1.52855 loss)
I0622 19:58:47.084609 36972 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0622 19:59:24.692458 36972 solver.cpp:337] Iteration 5000, Testing net (#0)
I0622 19:59:31.000579 36972 solver.cpp:404]     Test net output #0: accuracy = 0.439
I0622 19:59:31.000638 36972 solver.cpp:404]     Test net output #1: loss = 1.54034 (* 1 = 1.54034 loss)
I0622 19:59:31.067558 36972 solver.cpp:228] Iteration 5000, loss = 1.73816
I0622 19:59:31.067584 36972 solver.cpp:244]     Train net output #0: loss = 1.73816 (* 1 = 1.73816 loss)
I0622 19:59:31.067595 36972 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0622 20:00:08.764256 36972 solver.cpp:228] Iteration 5200, loss = 1.62136
I0622 20:00:08.764499 36972 solver.cpp:244]     Train net output #0: loss = 1.62136 (* 1 = 1.62136 loss)
I0622 20:00:08.764536 36972 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0622 20:00:46.448917 36972 solver.cpp:228] Iteration 5400, loss = 1.35868
I0622 20:00:46.449221 36972 solver.cpp:244]     Train net output #0: loss = 1.35868 (* 1 = 1.35868 loss)
I0622 20:00:46.449275 36972 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0622 20:01:24.179237 36972 solver.cpp:228] Iteration 5600, loss = 1.45345
I0622 20:01:24.179502 36972 solver.cpp:244]     Train net output #0: loss = 1.45345 (* 1 = 1.45345 loss)
I0622 20:01:24.179565 36972 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0622 20:02:01.822791 36972 solver.cpp:228] Iteration 5800, loss = 1.39714
I0622 20:02:01.822981 36972 solver.cpp:244]     Train net output #0: loss = 1.39714 (* 1 = 1.39714 loss)
I0622 20:02:01.822995 36972 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0622 20:02:39.422075 36972 solver.cpp:337] Iteration 6000, Testing net (#0)
I0622 20:02:45.735736 36972 solver.cpp:404]     Test net output #0: accuracy = 0.4449
I0622 20:02:45.735790 36972 solver.cpp:404]     Test net output #1: loss = 1.51247 (* 1 = 1.51247 loss)
I0622 20:02:45.802171 36972 solver.cpp:228] Iteration 6000, loss = 1.65181
I0622 20:02:45.802206 36972 solver.cpp:244]     Train net output #0: loss = 1.65181 (* 1 = 1.65181 loss)
I0622 20:02:45.802218 36972 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0622 20:03:23.560765 36972 solver.cpp:228] Iteration 6200, loss = 1.57669
I0622 20:03:23.561096 36972 solver.cpp:244]     Train net output #0: loss = 1.57669 (* 1 = 1.57669 loss)
I0622 20:03:23.561157 36972 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0622 20:04:01.308207 36972 solver.cpp:228] Iteration 6400, loss = 1.45719
I0622 20:04:01.308540 36972 solver.cpp:244]     Train net output #0: loss = 1.45719 (* 1 = 1.45719 loss)
I0622 20:04:01.308611 36972 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0622 20:04:39.052717 36972 solver.cpp:228] Iteration 6600, loss = 1.3553
I0622 20:04:39.052963 36972 solver.cpp:244]     Train net output #0: loss = 1.3553 (* 1 = 1.3553 loss)
I0622 20:04:39.052995 36972 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0622 20:05:16.797808 36972 solver.cpp:228] Iteration 6800, loss = 1.40058
I0622 20:05:16.797999 36972 solver.cpp:244]     Train net output #0: loss = 1.40058 (* 1 = 1.40058 loss)
I0622 20:05:16.798014 36972 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0622 20:05:54.439661 36972 solver.cpp:337] Iteration 7000, Testing net (#0)
I0622 20:06:00.758963 36972 solver.cpp:404]     Test net output #0: accuracy = 0.4504
I0622 20:06:00.759006 36972 solver.cpp:404]     Test net output #1: loss = 1.50807 (* 1 = 1.50807 loss)
I0622 20:06:00.824612 36972 solver.cpp:228] Iteration 7000, loss = 1.67967
I0622 20:06:00.824638 36972 solver.cpp:244]     Train net output #0: loss = 1.67967 (* 1 = 1.67967 loss)
I0622 20:06:00.824648 36972 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0622 20:06:38.510730 36972 solver.cpp:228] Iteration 7200, loss = 1.49363
I0622 20:06:38.511086 36972 solver.cpp:244]     Train net output #0: loss = 1.49363 (* 1 = 1.49363 loss)
I0622 20:06:38.511148 36972 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0622 20:07:16.238147 36972 solver.cpp:228] Iteration 7400, loss = 1.37156
I0622 20:07:16.238478 36972 solver.cpp:244]     Train net output #0: loss = 1.37156 (* 1 = 1.37156 loss)
I0622 20:07:16.238540 36972 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0622 20:07:53.977032 36972 solver.cpp:228] Iteration 7600, loss = 1.257
I0622 20:07:53.977282 36972 solver.cpp:244]     Train net output #0: loss = 1.257 (* 1 = 1.257 loss)
I0622 20:07:53.977311 36972 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0622 20:08:31.654961 36972 solver.cpp:228] Iteration 7800, loss = 1.33702
I0622 20:08:31.655159 36972 solver.cpp:244]     Train net output #0: loss = 1.33702 (* 1 = 1.33702 loss)
I0622 20:08:31.655171 36972 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0622 20:09:09.328037 36972 solver.cpp:337] Iteration 8000, Testing net (#0)
I0622 20:09:15.661207 36972 solver.cpp:404]     Test net output #0: accuracy = 0.4694
I0622 20:09:15.661260 36972 solver.cpp:404]     Test net output #1: loss = 1.46466 (* 1 = 1.46466 loss)
I0622 20:09:15.728067 36972 solver.cpp:228] Iteration 8000, loss = 1.61128
I0622 20:09:15.728103 36972 solver.cpp:244]     Train net output #0: loss = 1.61128 (* 1 = 1.61128 loss)
I0622 20:09:15.728116 36972 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0622 20:09:53.435169 36972 solver.cpp:228] Iteration 8200, loss = 1.46128
I0622 20:09:53.435477 36972 solver.cpp:244]     Train net output #0: loss = 1.46128 (* 1 = 1.46128 loss)
I0622 20:09:53.435492 36972 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0622 20:10:31.130427 36972 solver.cpp:228] Iteration 8400, loss = 1.30884
I0622 20:10:31.130658 36972 solver.cpp:244]     Train net output #0: loss = 1.30884 (* 1 = 1.30884 loss)
I0622 20:10:31.130673 36972 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0622 20:11:08.824406 36972 solver.cpp:228] Iteration 8600, loss = 1.29614
I0622 20:11:08.824605 36972 solver.cpp:244]     Train net output #0: loss = 1.29614 (* 1 = 1.29614 loss)
I0622 20:11:08.824617 36972 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0622 20:11:46.483726 36972 solver.cpp:228] Iteration 8800, loss = 1.32598
I0622 20:11:46.483947 36972 solver.cpp:244]     Train net output #0: loss = 1.32598 (* 1 = 1.32598 loss)
I0622 20:11:46.483960 36972 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0622 20:12:24.101685 36972 solver.cpp:337] Iteration 9000, Testing net (#0)
I0622 20:12:30.414003 36972 solver.cpp:404]     Test net output #0: accuracy = 0.4868
I0622 20:12:30.414052 36972 solver.cpp:404]     Test net output #1: loss = 1.41582 (* 1 = 1.41582 loss)
I0622 20:12:30.480795 36972 solver.cpp:228] Iteration 9000, loss = 1.47708
I0622 20:12:30.480840 36972 solver.cpp:244]     Train net output #0: loss = 1.47708 (* 1 = 1.47708 loss)
I0622 20:12:30.480852 36972 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0622 20:13:08.203192 36972 solver.cpp:228] Iteration 9200, loss = 1.4473
I0622 20:13:08.203423 36972 solver.cpp:244]     Train net output #0: loss = 1.4473 (* 1 = 1.4473 loss)
I0622 20:13:08.203444 36972 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0622 20:13:45.907459 36972 solver.cpp:228] Iteration 9400, loss = 1.31556
I0622 20:13:45.907656 36972 solver.cpp:244]     Train net output #0: loss = 1.31556 (* 1 = 1.31556 loss)
I0622 20:13:45.907668 36972 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0622 20:14:23.602897 36972 solver.cpp:228] Iteration 9600, loss = 1.14664
I0622 20:14:23.603109 36972 solver.cpp:244]     Train net output #0: loss = 1.14664 (* 1 = 1.14664 loss)
I0622 20:14:23.603144 36972 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0622 20:15:01.319579 36972 solver.cpp:228] Iteration 9800, loss = 1.27419
I0622 20:15:01.319862 36972 solver.cpp:244]     Train net output #0: loss = 1.27419 (* 1 = 1.27419 loss)
I0622 20:15:01.319901 36972 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0622 20:15:38.949889 36972 solver.cpp:337] Iteration 10000, Testing net (#0)
I0622 20:15:45.270697 36972 solver.cpp:404]     Test net output #0: accuracy = 0.5096
I0622 20:15:45.270750 36972 solver.cpp:404]     Test net output #1: loss = 1.35588 (* 1 = 1.35588 loss)
I0622 20:15:45.337237 36972 solver.cpp:228] Iteration 10000, loss = 1.41007
I0622 20:15:45.337267 36972 solver.cpp:244]     Train net output #0: loss = 1.41007 (* 1 = 1.41007 loss)
I0622 20:15:45.337281 36972 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0622 20:16:23.014307 36972 solver.cpp:228] Iteration 10200, loss = 1.4275
I0622 20:16:23.014603 36972 solver.cpp:244]     Train net output #0: loss = 1.4275 (* 1 = 1.4275 loss)
I0622 20:16:23.014621 36972 sgd_solver.cpp:106] Iteration 10200, lr = 0.1
I0622 20:17:00.730620 36972 solver.cpp:228] Iteration 10400, loss = 1.24093
I0622 20:17:00.730942 36972 solver.cpp:244]     Train net output #0: loss = 1.24093 (* 1 = 1.24093 loss)
I0622 20:17:00.730974 36972 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0622 20:17:38.423651 36972 solver.cpp:228] Iteration 10600, loss = 1.10186
I0622 20:17:38.423954 36972 solver.cpp:244]     Train net output #0: loss = 1.10186 (* 1 = 1.10186 loss)
I0622 20:17:38.424006 36972 sgd_solver.cpp:106] Iteration 10600, lr = 0.1
I0622 20:18:16.097533 36972 solver.cpp:228] Iteration 10800, loss = 1.25839
I0622 20:18:16.097730 36972 solver.cpp:244]     Train net output #0: loss = 1.25839 (* 1 = 1.25839 loss)
I0622 20:18:16.097743 36972 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0622 20:18:53.707813 36972 solver.cpp:337] Iteration 11000, Testing net (#0)
I0622 20:19:00.036823 36972 solver.cpp:404]     Test net output #0: accuracy = 0.549
I0622 20:19:00.036883 36972 solver.cpp:404]     Test net output #1: loss = 1.23864 (* 1 = 1.23864 loss)
I0622 20:19:00.103138 36972 solver.cpp:228] Iteration 11000, loss = 1.22845
I0622 20:19:00.103173 36972 solver.cpp:244]     Train net output #0: loss = 1.22845 (* 1 = 1.22845 loss)
I0622 20:19:00.103199 36972 sgd_solver.cpp:106] Iteration 11000, lr = 0.1
I0622 20:19:37.766614 36972 solver.cpp:228] Iteration 11200, loss = 1.31404
I0622 20:19:37.766989 36972 solver.cpp:244]     Train net output #0: loss = 1.31404 (* 1 = 1.31404 loss)
I0622 20:19:37.767004 36972 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0622 20:20:15.452987 36972 solver.cpp:228] Iteration 11400, loss = 1.17642
I0622 20:20:15.453315 36972 solver.cpp:244]     Train net output #0: loss = 1.17642 (* 1 = 1.17642 loss)
I0622 20:20:15.453379 36972 sgd_solver.cpp:106] Iteration 11400, lr = 0.1
I0622 20:20:53.129163 36972 solver.cpp:228] Iteration 11600, loss = 1.04331
I0622 20:20:53.129364 36972 solver.cpp:244]     Train net output #0: loss = 1.04331 (* 1 = 1.04331 loss)
I0622 20:20:53.129420 36972 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0622 20:21:30.795743 36972 solver.cpp:228] Iteration 11800, loss = 1.08676
I0622 20:21:30.796062 36972 solver.cpp:244]     Train net output #0: loss = 1.08676 (* 1 = 1.08676 loss)
I0622 20:21:30.796141 36972 sgd_solver.cpp:106] Iteration 11800, lr = 0.1
I0622 20:22:08.376003 36972 solver.cpp:337] Iteration 12000, Testing net (#0)
I0622 20:22:14.689293 36972 solver.cpp:404]     Test net output #0: accuracy = 0.5738
I0622 20:22:14.689347 36972 solver.cpp:404]     Test net output #1: loss = 1.1987 (* 1 = 1.1987 loss)
I0622 20:22:14.755924 36972 solver.cpp:228] Iteration 12000, loss = 1.10067
I0622 20:22:14.755954 36972 solver.cpp:244]     Train net output #0: loss = 1.10067 (* 1 = 1.10067 loss)
I0622 20:22:14.755967 36972 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0622 20:22:52.500514 36972 solver.cpp:228] Iteration 12200, loss = 1.3306
I0622 20:22:52.500713 36972 solver.cpp:244]     Train net output #0: loss = 1.3306 (* 1 = 1.3306 loss)
I0622 20:22:52.500732 36972 sgd_solver.cpp:106] Iteration 12200, lr = 0.1
I0622 20:23:30.238636 36972 solver.cpp:228] Iteration 12400, loss = 1.08387
I0622 20:23:30.238888 36972 solver.cpp:244]     Train net output #0: loss = 1.08387 (* 1 = 1.08387 loss)
I0622 20:23:30.238903 36972 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0622 20:24:07.986583 36972 solver.cpp:228] Iteration 12600, loss = 0.960278
I0622 20:24:07.990782 36972 solver.cpp:244]     Train net output #0: loss = 0.960278 (* 1 = 0.960278 loss)
I0622 20:24:07.990805 36972 sgd_solver.cpp:106] Iteration 12600, lr = 0.1
I0622 20:24:45.719238 36972 solver.cpp:228] Iteration 12800, loss = 1.08765
I0622 20:24:45.719527 36972 solver.cpp:244]     Train net output #0: loss = 1.08765 (* 1 = 1.08765 loss)
I0622 20:24:45.719560 36972 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0622 20:25:23.388095 36972 solver.cpp:337] Iteration 13000, Testing net (#0)
I0622 20:25:29.706578 36972 solver.cpp:404]     Test net output #0: accuracy = 0.5811
I0622 20:25:29.706629 36972 solver.cpp:404]     Test net output #1: loss = 1.15603 (* 1 = 1.15603 loss)
I0622 20:25:29.773210 36972 solver.cpp:228] Iteration 13000, loss = 1.11603
I0622 20:25:29.773241 36972 solver.cpp:244]     Train net output #0: loss = 1.11603 (* 1 = 1.11603 loss)
I0622 20:25:29.773254 36972 sgd_solver.cpp:106] Iteration 13000, lr = 0.1
I0622 20:26:07.482621 36972 solver.cpp:228] Iteration 13200, loss = 1.17386
I0622 20:26:07.482856 36972 solver.cpp:244]     Train net output #0: loss = 1.17386 (* 1 = 1.17386 loss)
I0622 20:26:07.482873 36972 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0622 20:26:45.241603 36972 solver.cpp:228] Iteration 13400, loss = 0.983917
I0622 20:26:45.241921 36972 solver.cpp:244]     Train net output #0: loss = 0.983917 (* 1 = 0.983917 loss)
I0622 20:26:45.241989 36972 sgd_solver.cpp:106] Iteration 13400, lr = 0.1
I0622 20:27:22.959079 36972 solver.cpp:228] Iteration 13600, loss = 0.812806
I0622 20:27:22.959288 36972 solver.cpp:244]     Train net output #0: loss = 0.812806 (* 1 = 0.812806 loss)
I0622 20:27:22.959326 36972 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0622 20:28:00.684501 36972 solver.cpp:228] Iteration 13800, loss = 1.17206
I0622 20:28:00.684779 36972 solver.cpp:244]     Train net output #0: loss = 1.17206 (* 1 = 1.17206 loss)
I0622 20:28:00.684836 36972 sgd_solver.cpp:106] Iteration 13800, lr = 0.1
I0622 20:28:38.350419 36972 solver.cpp:337] Iteration 14000, Testing net (#0)
I0622 20:28:44.679939 36972 solver.cpp:404]     Test net output #0: accuracy = 0.5957
I0622 20:28:44.679996 36972 solver.cpp:404]     Test net output #1: loss = 1.15511 (* 1 = 1.15511 loss)
I0622 20:28:44.747145 36972 solver.cpp:228] Iteration 14000, loss = 1.16377
I0622 20:28:44.747179 36972 solver.cpp:244]     Train net output #0: loss = 1.16377 (* 1 = 1.16377 loss)
I0622 20:28:44.747191 36972 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0622 20:29:22.495532 36972 solver.cpp:228] Iteration 14200, loss = 1.0274
I0622 20:29:22.495728 36972 solver.cpp:244]     Train net output #0: loss = 1.0274 (* 1 = 1.0274 loss)
I0622 20:29:22.495743 36972 sgd_solver.cpp:106] Iteration 14200, lr = 0.1
I0622 20:30:00.217591 36972 solver.cpp:228] Iteration 14400, loss = 0.971855
I0622 20:30:00.217777 36972 solver.cpp:244]     Train net output #0: loss = 0.971855 (* 1 = 0.971855 loss)
I0622 20:30:00.217803 36972 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0622 20:30:37.906205 36972 solver.cpp:228] Iteration 14600, loss = 0.833819
I0622 20:30:37.906431 36972 solver.cpp:244]     Train net output #0: loss = 0.833819 (* 1 = 0.833819 loss)
I0622 20:30:37.906448 36972 sgd_solver.cpp:106] Iteration 14600, lr = 0.1
I0622 20:31:15.632081 36972 solver.cpp:228] Iteration 14800, loss = 1.07154
I0622 20:31:15.632362 36972 solver.cpp:244]     Train net output #0: loss = 1.07154 (* 1 = 1.07154 loss)
I0622 20:31:15.632407 36972 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0622 20:31:53.286952 36972 solver.cpp:337] Iteration 15000, Testing net (#0)
I0622 20:31:59.608153 36972 solver.cpp:404]     Test net output #0: accuracy = 0.5906
I0622 20:31:59.608207 36972 solver.cpp:404]     Test net output #1: loss = 1.14012 (* 1 = 1.14012 loss)
I0622 20:31:59.674635 36972 solver.cpp:228] Iteration 15000, loss = 1.02745
I0622 20:31:59.674664 36972 solver.cpp:244]     Train net output #0: loss = 1.02745 (* 1 = 1.02745 loss)
I0622 20:31:59.674679 36972 sgd_solver.cpp:106] Iteration 15000, lr = 0.1
I0622 20:32:37.382236 36972 solver.cpp:228] Iteration 15200, loss = 1.11944
I0622 20:32:37.382444 36972 solver.cpp:244]     Train net output #0: loss = 1.11944 (* 1 = 1.11944 loss)
I0622 20:32:37.382460 36972 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0622 20:33:15.093122 36972 solver.cpp:228] Iteration 15400, loss = 0.868714
I0622 20:33:15.093411 36972 solver.cpp:244]     Train net output #0: loss = 0.868714 (* 1 = 0.868714 loss)
I0622 20:33:15.093444 36972 sgd_solver.cpp:106] Iteration 15400, lr = 0.1
I0622 20:33:52.846987 36972 solver.cpp:228] Iteration 15600, loss = 0.779039
I0622 20:33:52.847177 36972 solver.cpp:244]     Train net output #0: loss = 0.779039 (* 1 = 0.779039 loss)
I0622 20:33:52.847190 36972 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0622 20:34:30.577203 36972 solver.cpp:228] Iteration 15800, loss = 0.976743
I0622 20:34:30.577428 36972 solver.cpp:244]     Train net output #0: loss = 0.976743 (* 1 = 0.976743 loss)
I0622 20:34:30.577442 36972 sgd_solver.cpp:106] Iteration 15800, lr = 0.1
I0622 20:35:08.241194 36972 solver.cpp:454] Snapshotting to binary proto file snapshots/res_ide20_iter_16000.caffemodel
I0622 20:35:08.328428 36972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/res_ide20_iter_16000.solverstate
I0622 20:35:08.359777 36972 solver.cpp:337] Iteration 16000, Testing net (#0)
I0622 20:35:14.694175 36972 solver.cpp:404]     Test net output #0: accuracy = 0.6285
I0622 20:35:14.694224 36972 solver.cpp:404]     Test net output #1: loss = 1.04839 (* 1 = 1.04839 loss)
I0622 20:35:14.760478 36972 solver.cpp:228] Iteration 16000, loss = 0.891986
I0622 20:35:14.760502 36972 solver.cpp:244]     Train net output #0: loss = 0.891986 (* 1 = 0.891986 loss)
I0622 20:35:14.760514 36972 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0622 20:35:52.437448 36972 solver.cpp:228] Iteration 16200, loss = 0.928773
I0622 20:35:52.437613 36972 solver.cpp:244]     Train net output #0: loss = 0.928773 (* 1 = 0.928773 loss)
I0622 20:35:52.437641 36972 sgd_solver.cpp:106] Iteration 16200, lr = 0.1
I0622 20:36:30.122252 36972 solver.cpp:228] Iteration 16400, loss = 0.842979
I0622 20:36:30.122437 36972 solver.cpp:244]     Train net output #0: loss = 0.842979 (* 1 = 0.842979 loss)
I0622 20:36:30.122450 36972 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0622 20:37:07.869953 36972 solver.cpp:228] Iteration 16600, loss = 0.859604
I0622 20:37:07.870250 36972 solver.cpp:244]     Train net output #0: loss = 0.859604 (* 1 = 0.859604 loss)
I0622 20:37:07.870314 36972 sgd_solver.cpp:106] Iteration 16600, lr = 0.1
I0622 20:37:45.525638 36972 solver.cpp:228] Iteration 16800, loss = 0.87023
I0622 20:37:45.525897 36972 solver.cpp:244]     Train net output #0: loss = 0.87023 (* 1 = 0.87023 loss)
I0622 20:37:45.525929 36972 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0622 20:38:23.140097 36972 solver.cpp:337] Iteration 17000, Testing net (#0)
I0622 20:38:29.473754 36972 solver.cpp:404]     Test net output #0: accuracy = 0.6255
I0622 20:38:29.473805 36972 solver.cpp:404]     Test net output #1: loss = 1.06512 (* 1 = 1.06512 loss)
I0622 20:38:29.540594 36972 solver.cpp:228] Iteration 17000, loss = 0.945232
I0622 20:38:29.540621 36972 solver.cpp:244]     Train net output #0: loss = 0.945232 (* 1 = 0.945232 loss)
I0622 20:38:29.540632 36972 sgd_solver.cpp:106] Iteration 17000, lr = 0.1
I0622 20:39:07.231956 36972 solver.cpp:228] Iteration 17200, loss = 0.957127
I0622 20:39:07.232179 36972 solver.cpp:244]     Train net output #0: loss = 0.957127 (* 1 = 0.957127 loss)
I0622 20:39:07.232195 36972 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0622 20:39:44.921048 36972 solver.cpp:228] Iteration 17400, loss = 0.821652
I0622 20:39:44.921332 36972 solver.cpp:244]     Train net output #0: loss = 0.821652 (* 1 = 0.821652 loss)
I0622 20:39:44.921362 36972 sgd_solver.cpp:106] Iteration 17400, lr = 0.1
I0622 20:40:22.595932 36972 solver.cpp:228] Iteration 17600, loss = 0.858555
I0622 20:40:22.596163 36972 solver.cpp:244]     Train net output #0: loss = 0.858555 (* 1 = 0.858555 loss)
I0622 20:40:22.596217 36972 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0622 20:41:00.272753 36972 solver.cpp:228] Iteration 17800, loss = 0.943694
I0622 20:41:00.272917 36972 solver.cpp:244]     Train net output #0: loss = 0.943694 (* 1 = 0.943694 loss)
I0622 20:41:00.272934 36972 sgd_solver.cpp:106] Iteration 17800, lr = 0.1
I0622 20:41:37.855330 36972 solver.cpp:337] Iteration 18000, Testing net (#0)
I0622 20:41:44.181628 36972 solver.cpp:404]     Test net output #0: accuracy = 0.6597
I0622 20:41:44.181681 36972 solver.cpp:404]     Test net output #1: loss = 0.95842 (* 1 = 0.95842 loss)
I0622 20:41:44.248229 36972 solver.cpp:228] Iteration 18000, loss = 0.815867
I0622 20:41:44.248262 36972 solver.cpp:244]     Train net output #0: loss = 0.815867 (* 1 = 0.815867 loss)
I0622 20:41:44.248281 36972 sgd_solver.cpp:106] Iteration 18000, lr = 0.1
I0622 20:42:22.023761 36972 solver.cpp:228] Iteration 18200, loss = 0.95126
I0622 20:42:22.023998 36972 solver.cpp:244]     Train net output #0: loss = 0.95126 (* 1 = 0.95126 loss)
I0622 20:42:22.024030 36972 sgd_solver.cpp:106] Iteration 18200, lr = 0.1
I0622 20:42:59.763500 36972 solver.cpp:228] Iteration 18400, loss = 0.848015
I0622 20:42:59.763721 36972 solver.cpp:244]     Train net output #0: loss = 0.848015 (* 1 = 0.848015 loss)
I0622 20:42:59.763754 36972 sgd_solver.cpp:106] Iteration 18400, lr = 0.1
I0622 20:43:37.495517 36972 solver.cpp:228] Iteration 18600, loss = 0.72229
I0622 20:43:37.495683 36972 solver.cpp:244]     Train net output #0: loss = 0.72229 (* 1 = 0.72229 loss)
I0622 20:43:37.495714 36972 sgd_solver.cpp:106] Iteration 18600, lr = 0.1
I0622 20:44:15.249979 36972 solver.cpp:228] Iteration 18800, loss = 0.959622
I0622 20:44:15.250278 36972 solver.cpp:244]     Train net output #0: loss = 0.959622 (* 1 = 0.959622 loss)
I0622 20:44:15.250325 36972 sgd_solver.cpp:106] Iteration 18800, lr = 0.1
I0622 20:44:52.926530 36972 solver.cpp:337] Iteration 19000, Testing net (#0)
I0622 20:44:59.263005 36972 solver.cpp:404]     Test net output #0: accuracy = 0.6746
I0622 20:44:59.263056 36972 solver.cpp:404]     Test net output #1: loss = 0.926815 (* 1 = 0.926815 loss)
I0622 20:44:59.329730 36972 solver.cpp:228] Iteration 19000, loss = 0.817134
I0622 20:44:59.329762 36972 solver.cpp:244]     Train net output #0: loss = 0.817134 (* 1 = 0.817134 loss)
I0622 20:44:59.329774 36972 sgd_solver.cpp:106] Iteration 19000, lr = 0.1
I0622 20:45:37.078250 36972 solver.cpp:228] Iteration 19200, loss = 0.935856
I0622 20:45:37.078469 36972 solver.cpp:244]     Train net output #0: loss = 0.935856 (* 1 = 0.935856 loss)
I0622 20:45:37.078485 36972 sgd_solver.cpp:106] Iteration 19200, lr = 0.1
I0622 20:46:14.813771 36972 solver.cpp:228] Iteration 19400, loss = 0.715653
I0622 20:46:14.813979 36972 solver.cpp:244]     Train net output #0: loss = 0.715653 (* 1 = 0.715653 loss)
I0622 20:46:14.814013 36972 sgd_solver.cpp:106] Iteration 19400, lr = 0.1
I0622 20:46:52.564363 36972 solver.cpp:228] Iteration 19600, loss = 0.71266
I0622 20:46:52.564589 36972 solver.cpp:244]     Train net output #0: loss = 0.71266 (* 1 = 0.71266 loss)
I0622 20:46:52.564621 36972 sgd_solver.cpp:106] Iteration 19600, lr = 0.1
I0622 20:47:30.300166 36972 solver.cpp:228] Iteration 19800, loss = 0.796055
I0622 20:47:30.300390 36972 solver.cpp:244]     Train net output #0: loss = 0.796055 (* 1 = 0.796055 loss)
I0622 20:47:30.300405 36972 sgd_solver.cpp:106] Iteration 19800, lr = 0.1
I0622 20:48:07.983712 36972 solver.cpp:337] Iteration 20000, Testing net (#0)
I0622 20:48:14.318852 36972 solver.cpp:404]     Test net output #0: accuracy = 0.6896
I0622 20:48:14.318912 36972 solver.cpp:404]     Test net output #1: loss = 0.885252 (* 1 = 0.885252 loss)
I0622 20:48:14.385809 36972 solver.cpp:228] Iteration 20000, loss = 0.827595
I0622 20:48:14.385848 36972 solver.cpp:244]     Train net output #0: loss = 0.827595 (* 1 = 0.827595 loss)
I0622 20:48:14.385859 36972 sgd_solver.cpp:106] Iteration 20000, lr = 0.1
I0622 20:48:52.082347 36972 solver.cpp:228] Iteration 20200, loss = 0.896495
I0622 20:48:52.082655 36972 solver.cpp:244]     Train net output #0: loss = 0.896495 (* 1 = 0.896495 loss)
I0622 20:48:52.082733 36972 sgd_solver.cpp:106] Iteration 20200, lr = 0.1
I0622 20:49:29.798588 36972 solver.cpp:228] Iteration 20400, loss = 0.722914
I0622 20:49:29.798981 36972 solver.cpp:244]     Train net output #0: loss = 0.722914 (* 1 = 0.722914 loss)
I0622 20:49:29.798996 36972 sgd_solver.cpp:106] Iteration 20400, lr = 0.1
I0622 20:50:07.502205 36972 solver.cpp:228] Iteration 20600, loss = 0.628715
I0622 20:50:07.502446 36972 solver.cpp:244]     Train net output #0: loss = 0.628715 (* 1 = 0.628715 loss)
I0622 20:50:07.502462 36972 sgd_solver.cpp:106] Iteration 20600, lr = 0.1
I0622 20:50:45.208385 36972 solver.cpp:228] Iteration 20800, loss = 0.711372
I0622 20:50:45.208595 36972 solver.cpp:244]     Train net output #0: loss = 0.711372 (* 1 = 0.711372 loss)
I0622 20:50:45.208611 36972 sgd_solver.cpp:106] Iteration 20800, lr = 0.1
I0622 20:51:22.844123 36972 solver.cpp:337] Iteration 21000, Testing net (#0)
I0622 20:51:29.150910 36972 solver.cpp:404]     Test net output #0: accuracy = 0.6936
I0622 20:51:29.150969 36972 solver.cpp:404]     Test net output #1: loss = 0.861355 (* 1 = 0.861355 loss)
I0622 20:51:29.217052 36972 solver.cpp:228] Iteration 21000, loss = 0.797401
I0622 20:51:29.217077 36972 solver.cpp:244]     Train net output #0: loss = 0.797401 (* 1 = 0.797401 loss)
I0622 20:51:29.217088 36972 sgd_solver.cpp:106] Iteration 21000, lr = 0.1
I0622 20:52:06.925398 36972 solver.cpp:228] Iteration 21200, loss = 0.846425
I0622 20:52:06.925628 36972 solver.cpp:244]     Train net output #0: loss = 0.846425 (* 1 = 0.846425 loss)
I0622 20:52:06.925640 36972 sgd_solver.cpp:106] Iteration 21200, lr = 0.1
I0622 20:52:44.621227 36972 solver.cpp:228] Iteration 21400, loss = 0.755708
I0622 20:52:44.621467 36972 solver.cpp:244]     Train net output #0: loss = 0.755708 (* 1 = 0.755708 loss)
I0622 20:52:44.621479 36972 sgd_solver.cpp:106] Iteration 21400, lr = 0.1
I0622 20:53:22.336150 36972 solver.cpp:228] Iteration 21600, loss = 0.659203
I0622 20:53:22.336370 36972 solver.cpp:244]     Train net output #0: loss = 0.659203 (* 1 = 0.659203 loss)
I0622 20:53:22.336382 36972 sgd_solver.cpp:106] Iteration 21600, lr = 0.1
I0622 20:54:00.041414 36972 solver.cpp:228] Iteration 21800, loss = 0.857014
I0622 20:54:00.041663 36972 solver.cpp:244]     Train net output #0: loss = 0.857014 (* 1 = 0.857014 loss)
I0622 20:54:00.041713 36972 sgd_solver.cpp:106] Iteration 21800, lr = 0.1
I0622 20:54:37.673142 36972 solver.cpp:337] Iteration 22000, Testing net (#0)
I0622 20:54:43.997474 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7124
I0622 20:54:43.997529 36972 solver.cpp:404]     Test net output #1: loss = 0.821265 (* 1 = 0.821265 loss)
I0622 20:54:44.063868 36972 solver.cpp:228] Iteration 22000, loss = 0.657188
I0622 20:54:44.063894 36972 solver.cpp:244]     Train net output #0: loss = 0.657188 (* 1 = 0.657188 loss)
I0622 20:54:44.063906 36972 sgd_solver.cpp:106] Iteration 22000, lr = 0.1
I0622 20:55:21.735700 36972 solver.cpp:228] Iteration 22200, loss = 0.796425
I0622 20:55:21.735951 36972 solver.cpp:244]     Train net output #0: loss = 0.796425 (* 1 = 0.796425 loss)
I0622 20:55:21.736012 36972 sgd_solver.cpp:106] Iteration 22200, lr = 0.1
I0622 20:55:59.401048 36972 solver.cpp:228] Iteration 22400, loss = 0.562602
I0622 20:55:59.401268 36972 solver.cpp:244]     Train net output #0: loss = 0.562602 (* 1 = 0.562602 loss)
I0622 20:55:59.401299 36972 sgd_solver.cpp:106] Iteration 22400, lr = 0.1
I0622 20:56:37.078474 36972 solver.cpp:228] Iteration 22600, loss = 0.669306
I0622 20:56:37.078694 36972 solver.cpp:244]     Train net output #0: loss = 0.669306 (* 1 = 0.669306 loss)
I0622 20:56:37.078708 36972 sgd_solver.cpp:106] Iteration 22600, lr = 0.1
I0622 20:57:14.714027 36972 solver.cpp:228] Iteration 22800, loss = 0.781466
I0622 20:57:14.714205 36972 solver.cpp:244]     Train net output #0: loss = 0.781466 (* 1 = 0.781466 loss)
I0622 20:57:14.714218 36972 sgd_solver.cpp:106] Iteration 22800, lr = 0.1
I0622 20:57:52.343102 36972 solver.cpp:337] Iteration 23000, Testing net (#0)
I0622 20:57:58.674703 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7012
I0622 20:57:58.674762 36972 solver.cpp:404]     Test net output #1: loss = 0.872596 (* 1 = 0.872596 loss)
I0622 20:57:58.741284 36972 solver.cpp:228] Iteration 23000, loss = 0.628792
I0622 20:57:58.741317 36972 solver.cpp:244]     Train net output #0: loss = 0.628792 (* 1 = 0.628792 loss)
I0622 20:57:58.741329 36972 sgd_solver.cpp:106] Iteration 23000, lr = 0.1
I0622 20:58:36.385439 36972 solver.cpp:228] Iteration 23200, loss = 0.773522
I0622 20:58:36.385856 36972 solver.cpp:244]     Train net output #0: loss = 0.773522 (* 1 = 0.773522 loss)
I0622 20:58:36.385921 36972 sgd_solver.cpp:106] Iteration 23200, lr = 0.1
I0622 20:59:14.047818 36972 solver.cpp:228] Iteration 23400, loss = 0.564553
I0622 20:59:14.048050 36972 solver.cpp:244]     Train net output #0: loss = 0.564553 (* 1 = 0.564553 loss)
I0622 20:59:14.048107 36972 sgd_solver.cpp:106] Iteration 23400, lr = 0.1
I0622 20:59:51.707037 36972 solver.cpp:228] Iteration 23600, loss = 0.542138
I0622 20:59:51.707337 36972 solver.cpp:244]     Train net output #0: loss = 0.542138 (* 1 = 0.542138 loss)
I0622 20:59:51.707397 36972 sgd_solver.cpp:106] Iteration 23600, lr = 0.1
I0622 21:00:29.319141 36972 solver.cpp:228] Iteration 23800, loss = 0.943078
I0622 21:00:29.319370 36972 solver.cpp:244]     Train net output #0: loss = 0.943078 (* 1 = 0.943078 loss)
I0622 21:00:29.319385 36972 sgd_solver.cpp:106] Iteration 23800, lr = 0.1
I0622 21:01:06.905709 36972 solver.cpp:337] Iteration 24000, Testing net (#0)
I0622 21:01:13.215343 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7305
I0622 21:01:13.215399 36972 solver.cpp:404]     Test net output #1: loss = 0.78603 (* 1 = 0.78603 loss)
I0622 21:01:13.282156 36972 solver.cpp:228] Iteration 24000, loss = 0.636241
I0622 21:01:13.282183 36972 solver.cpp:244]     Train net output #0: loss = 0.636241 (* 1 = 0.636241 loss)
I0622 21:01:13.282199 36972 sgd_solver.cpp:106] Iteration 24000, lr = 0.1
I0622 21:01:50.968921 36972 solver.cpp:228] Iteration 24200, loss = 0.628206
I0622 21:01:50.969125 36972 solver.cpp:244]     Train net output #0: loss = 0.628206 (* 1 = 0.628206 loss)
I0622 21:01:50.969141 36972 sgd_solver.cpp:106] Iteration 24200, lr = 0.1
I0622 21:02:28.650589 36972 solver.cpp:228] Iteration 24400, loss = 0.46155
I0622 21:02:28.650776 36972 solver.cpp:244]     Train net output #0: loss = 0.46155 (* 1 = 0.46155 loss)
I0622 21:02:28.650790 36972 sgd_solver.cpp:106] Iteration 24400, lr = 0.1
I0622 21:03:06.350390 36972 solver.cpp:228] Iteration 24600, loss = 0.587127
I0622 21:03:06.350594 36972 solver.cpp:244]     Train net output #0: loss = 0.587127 (* 1 = 0.587127 loss)
I0622 21:03:06.350610 36972 sgd_solver.cpp:106] Iteration 24600, lr = 0.1
I0622 21:03:44.063475 36972 solver.cpp:228] Iteration 24800, loss = 0.602161
I0622 21:03:44.063761 36972 solver.cpp:244]     Train net output #0: loss = 0.602161 (* 1 = 0.602161 loss)
I0622 21:03:44.063794 36972 sgd_solver.cpp:106] Iteration 24800, lr = 0.1
I0622 21:04:21.706096 36972 solver.cpp:337] Iteration 25000, Testing net (#0)
I0622 21:04:28.026298 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7437
I0622 21:04:28.026351 36972 solver.cpp:404]     Test net output #1: loss = 0.748385 (* 1 = 0.748385 loss)
I0622 21:04:28.097445 36972 solver.cpp:228] Iteration 25000, loss = 0.516734
I0622 21:04:28.097476 36972 solver.cpp:244]     Train net output #0: loss = 0.516734 (* 1 = 0.516734 loss)
I0622 21:04:28.097492 36972 sgd_solver.cpp:106] Iteration 25000, lr = 0.1
I0622 21:05:05.759937 36972 solver.cpp:228] Iteration 25200, loss = 0.611156
I0622 21:05:05.760125 36972 solver.cpp:244]     Train net output #0: loss = 0.611156 (* 1 = 0.611156 loss)
I0622 21:05:05.760139 36972 sgd_solver.cpp:106] Iteration 25200, lr = 0.1
I0622 21:05:43.525609 36972 solver.cpp:228] Iteration 25400, loss = 0.464348
I0622 21:05:43.529289 36972 solver.cpp:244]     Train net output #0: loss = 0.464347 (* 1 = 0.464347 loss)
I0622 21:05:43.529326 36972 sgd_solver.cpp:106] Iteration 25400, lr = 0.1
I0622 21:06:21.841014 36972 solver.cpp:228] Iteration 25600, loss = 0.52827
I0622 21:06:21.841217 36972 solver.cpp:244]     Train net output #0: loss = 0.52827 (* 1 = 0.52827 loss)
I0622 21:06:21.841233 36972 sgd_solver.cpp:106] Iteration 25600, lr = 0.1
I0622 21:06:59.601852 36972 solver.cpp:228] Iteration 25800, loss = 0.601392
I0622 21:06:59.602120 36972 solver.cpp:244]     Train net output #0: loss = 0.601392 (* 1 = 0.601392 loss)
I0622 21:06:59.602150 36972 sgd_solver.cpp:106] Iteration 25800, lr = 0.1
I0622 21:07:37.305830 36972 solver.cpp:337] Iteration 26000, Testing net (#0)
I0622 21:07:43.611245 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7541
I0622 21:07:43.611304 36972 solver.cpp:404]     Test net output #1: loss = 0.726182 (* 1 = 0.726182 loss)
I0622 21:07:43.678508 36972 solver.cpp:228] Iteration 26000, loss = 0.535496
I0622 21:07:43.678534 36972 solver.cpp:244]     Train net output #0: loss = 0.535496 (* 1 = 0.535496 loss)
I0622 21:07:43.678547 36972 sgd_solver.cpp:106] Iteration 26000, lr = 0.1
I0622 21:08:21.384604 36972 solver.cpp:228] Iteration 26200, loss = 0.758767
I0622 21:08:21.384824 36972 solver.cpp:244]     Train net output #0: loss = 0.758767 (* 1 = 0.758767 loss)
I0622 21:08:21.384878 36972 sgd_solver.cpp:106] Iteration 26200, lr = 0.1
I0622 21:08:59.101963 36972 solver.cpp:228] Iteration 26400, loss = 0.485917
I0622 21:08:59.102177 36972 solver.cpp:244]     Train net output #0: loss = 0.485917 (* 1 = 0.485917 loss)
I0622 21:08:59.102210 36972 sgd_solver.cpp:106] Iteration 26400, lr = 0.1
I0622 21:09:36.843971 36972 solver.cpp:228] Iteration 26600, loss = 0.53236
I0622 21:09:36.844185 36972 solver.cpp:244]     Train net output #0: loss = 0.53236 (* 1 = 0.53236 loss)
I0622 21:09:36.844243 36972 sgd_solver.cpp:106] Iteration 26600, lr = 0.1
I0622 21:10:14.545296 36972 solver.cpp:228] Iteration 26800, loss = 0.651318
I0622 21:10:14.545509 36972 solver.cpp:244]     Train net output #0: loss = 0.651318 (* 1 = 0.651318 loss)
I0622 21:10:14.545526 36972 sgd_solver.cpp:106] Iteration 26800, lr = 0.1
I0622 21:10:52.219843 36972 solver.cpp:337] Iteration 27000, Testing net (#0)
I0622 21:10:58.535270 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7563
I0622 21:10:58.535336 36972 solver.cpp:404]     Test net output #1: loss = 0.721848 (* 1 = 0.721848 loss)
I0622 21:10:58.601824 36972 solver.cpp:228] Iteration 27000, loss = 0.560645
I0622 21:10:58.601851 36972 solver.cpp:244]     Train net output #0: loss = 0.560645 (* 1 = 0.560645 loss)
I0622 21:10:58.601866 36972 sgd_solver.cpp:106] Iteration 27000, lr = 0.1
I0622 21:11:36.878348 36972 solver.cpp:228] Iteration 27200, loss = 0.746703
I0622 21:11:36.878628 36972 solver.cpp:244]     Train net output #0: loss = 0.746703 (* 1 = 0.746703 loss)
I0622 21:11:36.878672 36972 sgd_solver.cpp:106] Iteration 27200, lr = 0.1
I0622 21:12:14.584341 36972 solver.cpp:228] Iteration 27400, loss = 0.449525
I0622 21:12:14.584615 36972 solver.cpp:244]     Train net output #0: loss = 0.449525 (* 1 = 0.449525 loss)
I0622 21:12:14.584683 36972 sgd_solver.cpp:106] Iteration 27400, lr = 0.1
I0622 21:12:52.264130 36972 solver.cpp:228] Iteration 27600, loss = 0.642202
I0622 21:12:52.264335 36972 solver.cpp:244]     Train net output #0: loss = 0.642202 (* 1 = 0.642202 loss)
I0622 21:12:52.264351 36972 sgd_solver.cpp:106] Iteration 27600, lr = 0.1
I0622 21:13:29.964438 36972 solver.cpp:228] Iteration 27800, loss = 0.543064
I0622 21:13:29.964625 36972 solver.cpp:244]     Train net output #0: loss = 0.543064 (* 1 = 0.543064 loss)
I0622 21:13:29.964642 36972 sgd_solver.cpp:106] Iteration 27800, lr = 0.1
I0622 21:14:07.603670 36972 solver.cpp:337] Iteration 28000, Testing net (#0)
I0622 21:14:13.923387 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7735
I0622 21:14:13.923434 36972 solver.cpp:404]     Test net output #1: loss = 0.691457 (* 1 = 0.691457 loss)
I0622 21:14:13.990412 36972 solver.cpp:228] Iteration 28000, loss = 0.42914
I0622 21:14:13.990439 36972 solver.cpp:244]     Train net output #0: loss = 0.42914 (* 1 = 0.42914 loss)
I0622 21:14:13.990453 36972 sgd_solver.cpp:106] Iteration 28000, lr = 0.1
I0622 21:14:51.664038 36972 solver.cpp:228] Iteration 28200, loss = 0.640479
I0622 21:14:51.664243 36972 solver.cpp:244]     Train net output #0: loss = 0.640479 (* 1 = 0.640479 loss)
I0622 21:14:51.664276 36972 sgd_solver.cpp:106] Iteration 28200, lr = 0.1
I0622 21:15:29.324712 36972 solver.cpp:228] Iteration 28400, loss = 0.437558
I0622 21:15:29.325016 36972 solver.cpp:244]     Train net output #0: loss = 0.437558 (* 1 = 0.437558 loss)
I0622 21:15:29.325050 36972 sgd_solver.cpp:106] Iteration 28400, lr = 0.1
I0622 21:16:07.013921 36972 solver.cpp:228] Iteration 28600, loss = 0.492824
I0622 21:16:07.014119 36972 solver.cpp:244]     Train net output #0: loss = 0.492824 (* 1 = 0.492824 loss)
I0622 21:16:07.014133 36972 sgd_solver.cpp:106] Iteration 28600, lr = 0.1
I0622 21:16:44.677789 36972 solver.cpp:228] Iteration 28800, loss = 0.600519
I0622 21:16:44.678064 36972 solver.cpp:244]     Train net output #0: loss = 0.600519 (* 1 = 0.600519 loss)
I0622 21:16:44.678122 36972 sgd_solver.cpp:106] Iteration 28800, lr = 0.1
I0622 21:17:22.276468 36972 solver.cpp:337] Iteration 29000, Testing net (#0)
I0622 21:17:28.593228 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7584
I0622 21:17:28.593279 36972 solver.cpp:404]     Test net output #1: loss = 0.728647 (* 1 = 0.728647 loss)
I0622 21:17:28.660069 36972 solver.cpp:228] Iteration 29000, loss = 0.437458
I0622 21:17:28.660095 36972 solver.cpp:244]     Train net output #0: loss = 0.437458 (* 1 = 0.437458 loss)
I0622 21:17:28.660112 36972 sgd_solver.cpp:106] Iteration 29000, lr = 0.1
I0622 21:18:06.319278 36972 solver.cpp:228] Iteration 29200, loss = 0.447484
I0622 21:18:06.319511 36972 solver.cpp:244]     Train net output #0: loss = 0.447484 (* 1 = 0.447484 loss)
I0622 21:18:06.319561 36972 sgd_solver.cpp:106] Iteration 29200, lr = 0.1
I0622 21:18:43.991631 36972 solver.cpp:228] Iteration 29400, loss = 0.381062
I0622 21:18:43.991907 36972 solver.cpp:244]     Train net output #0: loss = 0.381062 (* 1 = 0.381062 loss)
I0622 21:18:43.991958 36972 sgd_solver.cpp:106] Iteration 29400, lr = 0.1
I0622 21:19:21.647336 36972 solver.cpp:228] Iteration 29600, loss = 0.409989
I0622 21:19:21.647564 36972 solver.cpp:244]     Train net output #0: loss = 0.409988 (* 1 = 0.409988 loss)
I0622 21:19:21.647608 36972 sgd_solver.cpp:106] Iteration 29600, lr = 0.1
I0622 21:19:59.286237 36972 solver.cpp:228] Iteration 29800, loss = 0.624707
I0622 21:19:59.286490 36972 solver.cpp:244]     Train net output #0: loss = 0.624707 (* 1 = 0.624707 loss)
I0622 21:19:59.286515 36972 sgd_solver.cpp:106] Iteration 29800, lr = 0.1
I0622 21:20:36.901056 36972 solver.cpp:337] Iteration 30000, Testing net (#0)
I0622 21:20:43.227386 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7785
I0622 21:20:43.227437 36972 solver.cpp:404]     Test net output #1: loss = 0.679181 (* 1 = 0.679181 loss)
I0622 21:20:43.294339 36972 solver.cpp:228] Iteration 30000, loss = 0.399852
I0622 21:20:43.294383 36972 solver.cpp:244]     Train net output #0: loss = 0.399851 (* 1 = 0.399851 loss)
I0622 21:20:43.294396 36972 sgd_solver.cpp:106] Iteration 30000, lr = 0.1
I0622 21:21:21.009340 36972 solver.cpp:228] Iteration 30200, loss = 0.645288
I0622 21:21:21.009552 36972 solver.cpp:244]     Train net output #0: loss = 0.645288 (* 1 = 0.645288 loss)
I0622 21:21:21.009568 36972 sgd_solver.cpp:106] Iteration 30200, lr = 0.1
I0622 21:21:58.720423 36972 solver.cpp:228] Iteration 30400, loss = 0.36725
I0622 21:21:58.720664 36972 solver.cpp:244]     Train net output #0: loss = 0.36725 (* 1 = 0.36725 loss)
I0622 21:21:58.720696 36972 sgd_solver.cpp:106] Iteration 30400, lr = 0.1
I0622 21:22:36.445303 36972 solver.cpp:228] Iteration 30600, loss = 0.481722
I0622 21:22:36.445546 36972 solver.cpp:244]     Train net output #0: loss = 0.481722 (* 1 = 0.481722 loss)
I0622 21:22:36.445579 36972 sgd_solver.cpp:106] Iteration 30600, lr = 0.1
I0622 21:23:14.151890 36972 solver.cpp:228] Iteration 30800, loss = 0.47802
I0622 21:23:14.152168 36972 solver.cpp:244]     Train net output #0: loss = 0.47802 (* 1 = 0.47802 loss)
I0622 21:23:14.152199 36972 sgd_solver.cpp:106] Iteration 30800, lr = 0.1
I0622 21:23:51.789844 36972 solver.cpp:337] Iteration 31000, Testing net (#0)
I0622 21:23:58.110924 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7538
I0622 21:23:58.110975 36972 solver.cpp:404]     Test net output #1: loss = 0.760208 (* 1 = 0.760208 loss)
I0622 21:23:58.177278 36972 solver.cpp:228] Iteration 31000, loss = 0.393247
I0622 21:23:58.177304 36972 solver.cpp:244]     Train net output #0: loss = 0.393247 (* 1 = 0.393247 loss)
I0622 21:23:58.177316 36972 sgd_solver.cpp:106] Iteration 31000, lr = 0.1
I0622 21:24:35.875102 36972 solver.cpp:228] Iteration 31200, loss = 0.561321
I0622 21:24:35.875388 36972 solver.cpp:244]     Train net output #0: loss = 0.561321 (* 1 = 0.561321 loss)
I0622 21:24:35.875429 36972 sgd_solver.cpp:106] Iteration 31200, lr = 0.1
I0622 21:25:13.598875 36972 solver.cpp:228] Iteration 31400, loss = 0.296213
I0622 21:25:13.599093 36972 solver.cpp:244]     Train net output #0: loss = 0.296212 (* 1 = 0.296212 loss)
I0622 21:25:13.599109 36972 sgd_solver.cpp:106] Iteration 31400, lr = 0.1
I0622 21:25:51.300964 36972 solver.cpp:228] Iteration 31600, loss = 0.52629
I0622 21:25:51.301129 36972 solver.cpp:244]     Train net output #0: loss = 0.526289 (* 1 = 0.526289 loss)
I0622 21:25:51.301142 36972 sgd_solver.cpp:106] Iteration 31600, lr = 0.1
I0622 21:26:29.060950 36972 solver.cpp:228] Iteration 31800, loss = 0.438021
I0622 21:26:29.061187 36972 solver.cpp:244]     Train net output #0: loss = 0.438021 (* 1 = 0.438021 loss)
I0622 21:26:29.061218 36972 sgd_solver.cpp:106] Iteration 31800, lr = 0.1
I0622 21:27:06.722939 36972 solver.cpp:454] Snapshotting to binary proto file snapshots/res_ide20_iter_32000.caffemodel
I0622 21:27:06.818166 36972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/res_ide20_iter_32000.solverstate
I0622 21:27:06.851979 36972 solver.cpp:337] Iteration 32000, Testing net (#0)
I0622 21:27:13.184499 36972 solver.cpp:404]     Test net output #0: accuracy = 0.7828
I0622 21:27:13.184546 36972 solver.cpp:404]     Test net output #1: loss = 0.658675 (* 1 = 0.658675 loss)
I0622 21:27:13.250653 36972 solver.cpp:228] Iteration 32000, loss = 0.293858
I0622 21:27:13.250680 36972 solver.cpp:244]     Train net output #0: loss = 0.293857 (* 1 = 0.293857 loss)
I0622 21:27:13.250707 36972 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0622 21:27:13.250716 36972 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I0622 21:27:50.907734 36972 solver.cpp:228] Iteration 32200, loss = 0.287914
I0622 21:27:50.907924 36972 solver.cpp:244]     Train net output #0: loss = 0.287914 (* 1 = 0.287914 loss)
I0622 21:27:50.907938 36972 sgd_solver.cpp:106] Iteration 32200, lr = 0.01
I0622 21:28:28.576573 36972 solver.cpp:228] Iteration 32400, loss = 0.126004
I0622 21:28:28.576810 36972 solver.cpp:244]     Train net output #0: loss = 0.126004 (* 1 = 0.126004 loss)
I0622 21:28:28.576843 36972 sgd_solver.cpp:106] Iteration 32400, lr = 0.01
I0622 21:29:06.251565 36972 solver.cpp:228] Iteration 32600, loss = 0.229832
I0622 21:29:06.251767 36972 solver.cpp:244]     Train net output #0: loss = 0.229832 (* 1 = 0.229832 loss)
I0622 21:29:06.251783 36972 sgd_solver.cpp:106] Iteration 32600, lr = 0.01
I0622 21:29:43.918050 36972 solver.cpp:228] Iteration 32800, loss = 0.221889
I0622 21:29:43.918256 36972 solver.cpp:244]     Train net output #0: loss = 0.221889 (* 1 = 0.221889 loss)
I0622 21:29:43.918288 36972 sgd_solver.cpp:106] Iteration 32800, lr = 0.01
I0622 21:30:21.522470 36972 solver.cpp:337] Iteration 33000, Testing net (#0)
I0622 21:30:27.850648 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8524
I0622 21:30:27.850714 36972 solver.cpp:404]     Test net output #1: loss = 0.435568 (* 1 = 0.435568 loss)
I0622 21:30:27.917353 36972 solver.cpp:228] Iteration 33000, loss = 0.159485
I0622 21:30:27.917385 36972 solver.cpp:244]     Train net output #0: loss = 0.159485 (* 1 = 0.159485 loss)
I0622 21:30:27.917398 36972 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I0622 21:31:05.614995 36972 solver.cpp:228] Iteration 33200, loss = 0.218743
I0622 21:31:05.615157 36972 solver.cpp:244]     Train net output #0: loss = 0.218743 (* 1 = 0.218743 loss)
I0622 21:31:05.615171 36972 sgd_solver.cpp:106] Iteration 33200, lr = 0.01
I0622 21:31:43.336711 36972 solver.cpp:228] Iteration 33400, loss = 0.0924499
I0622 21:31:43.336954 36972 solver.cpp:244]     Train net output #0: loss = 0.0924496 (* 1 = 0.0924496 loss)
I0622 21:31:43.336971 36972 sgd_solver.cpp:106] Iteration 33400, lr = 0.01
I0622 21:32:21.047937 36972 solver.cpp:228] Iteration 33600, loss = 0.197933
I0622 21:32:21.048203 36972 solver.cpp:244]     Train net output #0: loss = 0.197933 (* 1 = 0.197933 loss)
I0622 21:32:21.048269 36972 sgd_solver.cpp:106] Iteration 33600, lr = 0.01
I0622 21:32:58.750875 36972 solver.cpp:228] Iteration 33800, loss = 0.185453
I0622 21:32:58.751220 36972 solver.cpp:244]     Train net output #0: loss = 0.185453 (* 1 = 0.185453 loss)
I0622 21:32:58.751297 36972 sgd_solver.cpp:106] Iteration 33800, lr = 0.01
I0622 21:33:36.381786 36972 solver.cpp:337] Iteration 34000, Testing net (#0)
I0622 21:33:42.713757 36972 solver.cpp:404]     Test net output #0: accuracy = 0.855
I0622 21:33:42.713805 36972 solver.cpp:404]     Test net output #1: loss = 0.441272 (* 1 = 0.441272 loss)
I0622 21:33:42.780128 36972 solver.cpp:228] Iteration 34000, loss = 0.130632
I0622 21:33:42.780154 36972 solver.cpp:244]     Train net output #0: loss = 0.130632 (* 1 = 0.130632 loss)
I0622 21:33:42.780166 36972 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I0622 21:34:20.431465 36972 solver.cpp:228] Iteration 34200, loss = 0.160698
I0622 21:34:20.431717 36972 solver.cpp:244]     Train net output #0: loss = 0.160698 (* 1 = 0.160698 loss)
I0622 21:34:20.431749 36972 sgd_solver.cpp:106] Iteration 34200, lr = 0.01
I0622 21:34:58.084558 36972 solver.cpp:228] Iteration 34400, loss = 0.0745086
I0622 21:34:58.084749 36972 solver.cpp:244]     Train net output #0: loss = 0.0745084 (* 1 = 0.0745084 loss)
I0622 21:34:58.084765 36972 sgd_solver.cpp:106] Iteration 34400, lr = 0.01
I0622 21:35:35.753465 36972 solver.cpp:228] Iteration 34600, loss = 0.174932
I0622 21:35:35.753690 36972 solver.cpp:244]     Train net output #0: loss = 0.174932 (* 1 = 0.174932 loss)
I0622 21:35:35.753721 36972 sgd_solver.cpp:106] Iteration 34600, lr = 0.01
I0622 21:36:13.423691 36972 solver.cpp:228] Iteration 34800, loss = 0.149508
I0622 21:36:13.423967 36972 solver.cpp:244]     Train net output #0: loss = 0.149508 (* 1 = 0.149508 loss)
I0622 21:36:13.424018 36972 sgd_solver.cpp:106] Iteration 34800, lr = 0.01
I0622 21:36:51.036309 36972 solver.cpp:337] Iteration 35000, Testing net (#0)
I0622 21:36:57.359946 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8544
I0622 21:36:57.359994 36972 solver.cpp:404]     Test net output #1: loss = 0.457875 (* 1 = 0.457875 loss)
I0622 21:36:57.426756 36972 solver.cpp:228] Iteration 35000, loss = 0.104151
I0622 21:36:57.426784 36972 solver.cpp:244]     Train net output #0: loss = 0.104151 (* 1 = 0.104151 loss)
I0622 21:36:57.426796 36972 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I0622 21:37:35.077605 36972 solver.cpp:228] Iteration 35200, loss = 0.112369
I0622 21:37:35.077940 36972 solver.cpp:244]     Train net output #0: loss = 0.112368 (* 1 = 0.112368 loss)
I0622 21:37:35.078001 36972 sgd_solver.cpp:106] Iteration 35200, lr = 0.01
I0622 21:38:12.741204 36972 solver.cpp:228] Iteration 35400, loss = 0.0550295
I0622 21:38:12.741433 36972 solver.cpp:244]     Train net output #0: loss = 0.0550293 (* 1 = 0.0550293 loss)
I0622 21:38:12.741472 36972 sgd_solver.cpp:106] Iteration 35400, lr = 0.01
I0622 21:38:50.420394 36972 solver.cpp:228] Iteration 35600, loss = 0.149407
I0622 21:38:50.420703 36972 solver.cpp:244]     Train net output #0: loss = 0.149407 (* 1 = 0.149407 loss)
I0622 21:38:50.420758 36972 sgd_solver.cpp:106] Iteration 35600, lr = 0.01
I0622 21:39:28.063889 36972 solver.cpp:228] Iteration 35800, loss = 0.130126
I0622 21:39:28.064077 36972 solver.cpp:244]     Train net output #0: loss = 0.130126 (* 1 = 0.130126 loss)
I0622 21:39:28.064091 36972 sgd_solver.cpp:106] Iteration 35800, lr = 0.01
I0622 21:40:05.658159 36972 solver.cpp:337] Iteration 36000, Testing net (#0)
I0622 21:40:11.969485 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8536
I0622 21:40:11.969532 36972 solver.cpp:404]     Test net output #1: loss = 0.480248 (* 1 = 0.480248 loss)
I0622 21:40:12.036481 36972 solver.cpp:228] Iteration 36000, loss = 0.0849532
I0622 21:40:12.036509 36972 solver.cpp:244]     Train net output #0: loss = 0.084953 (* 1 = 0.084953 loss)
I0622 21:40:12.036522 36972 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I0622 21:40:49.731819 36972 solver.cpp:228] Iteration 36200, loss = 0.0911228
I0622 21:40:49.732081 36972 solver.cpp:244]     Train net output #0: loss = 0.0911226 (* 1 = 0.0911226 loss)
I0622 21:40:49.732137 36972 sgd_solver.cpp:106] Iteration 36200, lr = 0.01
I0622 21:41:27.410336 36972 solver.cpp:228] Iteration 36400, loss = 0.0373444
I0622 21:41:27.410645 36972 solver.cpp:244]     Train net output #0: loss = 0.0373442 (* 1 = 0.0373442 loss)
I0622 21:41:27.410751 36972 sgd_solver.cpp:106] Iteration 36400, lr = 0.01
I0622 21:42:05.105412 36972 solver.cpp:228] Iteration 36600, loss = 0.117827
I0622 21:42:05.105655 36972 solver.cpp:244]     Train net output #0: loss = 0.117827 (* 1 = 0.117827 loss)
I0622 21:42:05.105711 36972 sgd_solver.cpp:106] Iteration 36600, lr = 0.01
I0622 21:42:42.787549 36972 solver.cpp:228] Iteration 36800, loss = 0.104646
I0622 21:42:42.787765 36972 solver.cpp:244]     Train net output #0: loss = 0.104646 (* 1 = 0.104646 loss)
I0622 21:42:42.787824 36972 sgd_solver.cpp:106] Iteration 36800, lr = 0.01
I0622 21:43:20.416425 36972 solver.cpp:337] Iteration 37000, Testing net (#0)
I0622 21:43:26.725792 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8514
I0622 21:43:26.725842 36972 solver.cpp:404]     Test net output #1: loss = 0.508957 (* 1 = 0.508957 loss)
I0622 21:43:26.792788 36972 solver.cpp:228] Iteration 37000, loss = 0.0686662
I0622 21:43:26.792816 36972 solver.cpp:244]     Train net output #0: loss = 0.068666 (* 1 = 0.068666 loss)
I0622 21:43:26.792829 36972 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I0622 21:44:04.483500 36972 solver.cpp:228] Iteration 37200, loss = 0.0726428
I0622 21:44:04.483686 36972 solver.cpp:244]     Train net output #0: loss = 0.0726426 (* 1 = 0.0726426 loss)
I0622 21:44:04.483702 36972 sgd_solver.cpp:106] Iteration 37200, lr = 0.01
I0622 21:44:42.169347 36972 solver.cpp:228] Iteration 37400, loss = 0.0242682
I0622 21:44:42.169581 36972 solver.cpp:244]     Train net output #0: loss = 0.024268 (* 1 = 0.024268 loss)
I0622 21:44:42.169633 36972 sgd_solver.cpp:106] Iteration 37400, lr = 0.01
I0622 21:45:19.865032 36972 solver.cpp:228] Iteration 37600, loss = 0.0828208
I0622 21:45:19.865226 36972 solver.cpp:244]     Train net output #0: loss = 0.0828206 (* 1 = 0.0828206 loss)
I0622 21:45:19.865242 36972 sgd_solver.cpp:106] Iteration 37600, lr = 0.01
I0622 21:45:57.566148 36972 solver.cpp:228] Iteration 37800, loss = 0.0921774
I0622 21:45:57.566368 36972 solver.cpp:244]     Train net output #0: loss = 0.0921772 (* 1 = 0.0921772 loss)
I0622 21:45:57.566401 36972 sgd_solver.cpp:106] Iteration 37800, lr = 0.01
I0622 21:46:35.199344 36972 solver.cpp:337] Iteration 38000, Testing net (#0)
I0622 21:46:41.505161 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8491
I0622 21:46:41.505206 36972 solver.cpp:404]     Test net output #1: loss = 0.546047 (* 1 = 0.546047 loss)
I0622 21:46:41.571522 36972 solver.cpp:228] Iteration 38000, loss = 0.0491101
I0622 21:46:41.571549 36972 solver.cpp:244]     Train net output #0: loss = 0.0491099 (* 1 = 0.0491099 loss)
I0622 21:46:41.571563 36972 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I0622 21:47:19.235862 36972 solver.cpp:228] Iteration 38200, loss = 0.0601251
I0622 21:47:19.236145 36972 solver.cpp:244]     Train net output #0: loss = 0.0601249 (* 1 = 0.0601249 loss)
I0622 21:47:19.236230 36972 sgd_solver.cpp:106] Iteration 38200, lr = 0.01
I0622 21:47:56.911207 36972 solver.cpp:228] Iteration 38400, loss = 0.0173992
I0622 21:47:56.911401 36972 solver.cpp:244]     Train net output #0: loss = 0.017399 (* 1 = 0.017399 loss)
I0622 21:47:56.911415 36972 sgd_solver.cpp:106] Iteration 38400, lr = 0.01
I0622 21:48:34.564200 36972 solver.cpp:228] Iteration 38600, loss = 0.0554518
I0622 21:48:34.564429 36972 solver.cpp:244]     Train net output #0: loss = 0.0554516 (* 1 = 0.0554516 loss)
I0622 21:48:34.564481 36972 sgd_solver.cpp:106] Iteration 38600, lr = 0.01
I0622 21:49:12.222080 36972 solver.cpp:228] Iteration 38800, loss = 0.074345
I0622 21:49:12.222298 36972 solver.cpp:244]     Train net output #0: loss = 0.0743448 (* 1 = 0.0743448 loss)
I0622 21:49:12.222314 36972 sgd_solver.cpp:106] Iteration 38800, lr = 0.01
I0622 21:49:49.846714 36972 solver.cpp:337] Iteration 39000, Testing net (#0)
I0622 21:49:56.166569 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8461
I0622 21:49:56.166617 36972 solver.cpp:404]     Test net output #1: loss = 0.584503 (* 1 = 0.584503 loss)
I0622 21:49:56.233290 36972 solver.cpp:228] Iteration 39000, loss = 0.028943
I0622 21:49:56.233324 36972 solver.cpp:244]     Train net output #0: loss = 0.0289428 (* 1 = 0.0289428 loss)
I0622 21:49:56.233336 36972 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I0622 21:50:33.923635 36972 solver.cpp:228] Iteration 39200, loss = 0.0476405
I0622 21:50:33.923845 36972 solver.cpp:244]     Train net output #0: loss = 0.0476402 (* 1 = 0.0476402 loss)
I0622 21:50:33.923859 36972 sgd_solver.cpp:106] Iteration 39200, lr = 0.01
I0622 21:51:11.605697 36972 solver.cpp:228] Iteration 39400, loss = 0.0124951
I0622 21:51:11.606026 36972 solver.cpp:244]     Train net output #0: loss = 0.0124949 (* 1 = 0.0124949 loss)
I0622 21:51:11.606094 36972 sgd_solver.cpp:106] Iteration 39400, lr = 0.01
I0622 21:51:49.305450 36972 solver.cpp:228] Iteration 39600, loss = 0.0319357
I0622 21:51:49.305680 36972 solver.cpp:244]     Train net output #0: loss = 0.0319354 (* 1 = 0.0319354 loss)
I0622 21:51:49.305703 36972 sgd_solver.cpp:106] Iteration 39600, lr = 0.01
I0622 21:52:27.004456 36972 solver.cpp:228] Iteration 39800, loss = 0.0517047
I0622 21:52:27.004659 36972 solver.cpp:244]     Train net output #0: loss = 0.0517045 (* 1 = 0.0517045 loss)
I0622 21:52:27.004673 36972 sgd_solver.cpp:106] Iteration 39800, lr = 0.01
I0622 21:53:04.675108 36972 solver.cpp:337] Iteration 40000, Testing net (#0)
I0622 21:53:10.985996 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8468
I0622 21:53:10.986043 36972 solver.cpp:404]     Test net output #1: loss = 0.612609 (* 1 = 0.612609 loss)
I0622 21:53:11.052691 36972 solver.cpp:228] Iteration 40000, loss = 0.0201916
I0622 21:53:11.052719 36972 solver.cpp:244]     Train net output #0: loss = 0.0201914 (* 1 = 0.0201914 loss)
I0622 21:53:11.052732 36972 sgd_solver.cpp:106] Iteration 40000, lr = 0.01
I0622 21:53:48.697662 36972 solver.cpp:228] Iteration 40200, loss = 0.024704
I0622 21:53:48.697872 36972 solver.cpp:244]     Train net output #0: loss = 0.0247037 (* 1 = 0.0247037 loss)
I0622 21:53:48.697906 36972 sgd_solver.cpp:106] Iteration 40200, lr = 0.01
I0622 21:54:26.368458 36972 solver.cpp:228] Iteration 40400, loss = 0.0104246
I0622 21:54:26.368674 36972 solver.cpp:244]     Train net output #0: loss = 0.0104244 (* 1 = 0.0104244 loss)
I0622 21:54:26.368688 36972 sgd_solver.cpp:106] Iteration 40400, lr = 0.01
I0622 21:55:04.053864 36972 solver.cpp:228] Iteration 40600, loss = 0.0164532
I0622 21:55:04.054083 36972 solver.cpp:244]     Train net output #0: loss = 0.016453 (* 1 = 0.016453 loss)
I0622 21:55:04.054138 36972 sgd_solver.cpp:106] Iteration 40600, lr = 0.01
I0622 21:55:41.729363 36972 solver.cpp:228] Iteration 40800, loss = 0.0324122
I0622 21:55:41.729588 36972 solver.cpp:244]     Train net output #0: loss = 0.032412 (* 1 = 0.032412 loss)
I0622 21:55:41.729642 36972 sgd_solver.cpp:106] Iteration 40800, lr = 0.01
I0622 21:56:19.301623 36972 solver.cpp:337] Iteration 41000, Testing net (#0)
I0622 21:56:25.619963 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8471
I0622 21:56:25.620018 36972 solver.cpp:404]     Test net output #1: loss = 0.638521 (* 1 = 0.638521 loss)
I0622 21:56:25.686607 36972 solver.cpp:228] Iteration 41000, loss = 0.0125493
I0622 21:56:25.686641 36972 solver.cpp:244]     Train net output #0: loss = 0.0125491 (* 1 = 0.0125491 loss)
I0622 21:56:25.686655 36972 sgd_solver.cpp:106] Iteration 41000, lr = 0.01
I0622 21:57:03.336076 36972 solver.cpp:228] Iteration 41200, loss = 0.0165427
I0622 21:57:03.336367 36972 solver.cpp:244]     Train net output #0: loss = 0.0165424 (* 1 = 0.0165424 loss)
I0622 21:57:03.336381 36972 sgd_solver.cpp:106] Iteration 41200, lr = 0.01
I0622 21:57:40.958793 36972 solver.cpp:228] Iteration 41400, loss = 0.00774954
I0622 21:57:40.959018 36972 solver.cpp:244]     Train net output #0: loss = 0.00774931 (* 1 = 0.00774931 loss)
I0622 21:57:40.959050 36972 sgd_solver.cpp:106] Iteration 41400, lr = 0.01
I0622 21:58:18.615828 36972 solver.cpp:228] Iteration 41600, loss = 0.0174852
I0622 21:58:18.616027 36972 solver.cpp:244]     Train net output #0: loss = 0.0174849 (* 1 = 0.0174849 loss)
I0622 21:58:18.616041 36972 sgd_solver.cpp:106] Iteration 41600, lr = 0.01
I0622 21:58:56.287210 36972 solver.cpp:228] Iteration 41800, loss = 0.0246481
I0622 21:58:56.287407 36972 solver.cpp:244]     Train net output #0: loss = 0.0246479 (* 1 = 0.0246479 loss)
I0622 21:58:56.287423 36972 sgd_solver.cpp:106] Iteration 41800, lr = 0.01
I0622 21:59:33.902853 36972 solver.cpp:337] Iteration 42000, Testing net (#0)
I0622 21:59:40.238595 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8488
I0622 21:59:40.238649 36972 solver.cpp:404]     Test net output #1: loss = 0.654796 (* 1 = 0.654796 loss)
I0622 21:59:40.305608 36972 solver.cpp:228] Iteration 42000, loss = 0.00958854
I0622 21:59:40.305636 36972 solver.cpp:244]     Train net output #0: loss = 0.00958831 (* 1 = 0.00958831 loss)
I0622 21:59:40.305652 36972 sgd_solver.cpp:106] Iteration 42000, lr = 0.01
I0622 22:00:17.993124 36972 solver.cpp:228] Iteration 42200, loss = 0.00999889
I0622 22:00:17.993710 36972 solver.cpp:244]     Train net output #0: loss = 0.00999865 (* 1 = 0.00999865 loss)
I0622 22:00:17.993731 36972 sgd_solver.cpp:106] Iteration 42200, lr = 0.01
I0622 22:00:55.705073 36972 solver.cpp:228] Iteration 42400, loss = 0.0054671
I0622 22:00:55.705258 36972 solver.cpp:244]     Train net output #0: loss = 0.00546686 (* 1 = 0.00546686 loss)
I0622 22:00:55.705273 36972 sgd_solver.cpp:106] Iteration 42400, lr = 0.01
I0622 22:01:33.425493 36972 solver.cpp:228] Iteration 42600, loss = 0.0103891
I0622 22:01:33.425716 36972 solver.cpp:244]     Train net output #0: loss = 0.0103888 (* 1 = 0.0103888 loss)
I0622 22:01:33.425748 36972 sgd_solver.cpp:106] Iteration 42600, lr = 0.01
I0622 22:02:11.137720 36972 solver.cpp:228] Iteration 42800, loss = 0.0152144
I0622 22:02:11.137903 36972 solver.cpp:244]     Train net output #0: loss = 0.0152142 (* 1 = 0.0152142 loss)
I0622 22:02:11.137917 36972 sgd_solver.cpp:106] Iteration 42800, lr = 0.01
I0622 22:02:48.794970 36972 solver.cpp:337] Iteration 43000, Testing net (#0)
I0622 22:02:55.105314 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8499
I0622 22:02:55.105360 36972 solver.cpp:404]     Test net output #1: loss = 0.67504 (* 1 = 0.67504 loss)
I0622 22:02:55.171367 36972 solver.cpp:228] Iteration 43000, loss = 0.00719453
I0622 22:02:55.171393 36972 solver.cpp:244]     Train net output #0: loss = 0.00719429 (* 1 = 0.00719429 loss)
I0622 22:02:55.171406 36972 sgd_solver.cpp:106] Iteration 43000, lr = 0.01
I0622 22:03:32.857421 36972 solver.cpp:228] Iteration 43200, loss = 0.00727333
I0622 22:03:32.857700 36972 solver.cpp:244]     Train net output #0: loss = 0.0072731 (* 1 = 0.0072731 loss)
I0622 22:03:32.857753 36972 sgd_solver.cpp:106] Iteration 43200, lr = 0.01
I0622 22:04:10.575137 36972 solver.cpp:228] Iteration 43400, loss = 0.00393705
I0622 22:04:10.575340 36972 solver.cpp:244]     Train net output #0: loss = 0.00393681 (* 1 = 0.00393681 loss)
I0622 22:04:10.575356 36972 sgd_solver.cpp:106] Iteration 43400, lr = 0.01
I0622 22:04:48.287596 36972 solver.cpp:228] Iteration 43600, loss = 0.00840659
I0622 22:04:48.287801 36972 solver.cpp:244]     Train net output #0: loss = 0.00840636 (* 1 = 0.00840636 loss)
I0622 22:04:48.287817 36972 sgd_solver.cpp:106] Iteration 43600, lr = 0.01
I0622 22:05:25.963707 36972 solver.cpp:228] Iteration 43800, loss = 0.00774922
I0622 22:05:25.963961 36972 solver.cpp:244]     Train net output #0: loss = 0.00774899 (* 1 = 0.00774899 loss)
I0622 22:05:25.963994 36972 sgd_solver.cpp:106] Iteration 43800, lr = 0.01
I0622 22:06:03.604643 36972 solver.cpp:337] Iteration 44000, Testing net (#0)
I0622 22:06:09.928257 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8496
I0622 22:06:09.928310 36972 solver.cpp:404]     Test net output #1: loss = 0.694115 (* 1 = 0.694115 loss)
I0622 22:06:09.995138 36972 solver.cpp:228] Iteration 44000, loss = 0.00607413
I0622 22:06:09.995165 36972 solver.cpp:244]     Train net output #0: loss = 0.00607389 (* 1 = 0.00607389 loss)
I0622 22:06:09.995182 36972 sgd_solver.cpp:106] Iteration 44000, lr = 0.01
I0622 22:06:47.648663 36972 solver.cpp:228] Iteration 44200, loss = 0.00610571
I0622 22:06:47.648860 36972 solver.cpp:244]     Train net output #0: loss = 0.00610548 (* 1 = 0.00610548 loss)
I0622 22:06:47.648876 36972 sgd_solver.cpp:106] Iteration 44200, lr = 0.01
I0622 22:07:25.317178 36972 solver.cpp:228] Iteration 44400, loss = 0.00316748
I0622 22:07:25.317472 36972 solver.cpp:244]     Train net output #0: loss = 0.00316724 (* 1 = 0.00316724 loss)
I0622 22:07:25.317551 36972 sgd_solver.cpp:106] Iteration 44400, lr = 0.01
I0622 22:08:02.988348 36972 solver.cpp:228] Iteration 44600, loss = 0.00512077
I0622 22:08:02.988582 36972 solver.cpp:244]     Train net output #0: loss = 0.00512053 (* 1 = 0.00512053 loss)
I0622 22:08:02.988598 36972 sgd_solver.cpp:106] Iteration 44600, lr = 0.01
I0622 22:08:40.646263 36972 solver.cpp:228] Iteration 44800, loss = 0.00537536
I0622 22:08:40.646484 36972 solver.cpp:244]     Train net output #0: loss = 0.00537512 (* 1 = 0.00537512 loss)
I0622 22:08:40.646517 36972 sgd_solver.cpp:106] Iteration 44800, lr = 0.01
I0622 22:09:18.244011 36972 solver.cpp:337] Iteration 45000, Testing net (#0)
I0622 22:09:24.569855 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8497
I0622 22:09:24.569903 36972 solver.cpp:404]     Test net output #1: loss = 0.705843 (* 1 = 0.705843 loss)
I0622 22:09:24.637336 36972 solver.cpp:228] Iteration 45000, loss = 0.00479233
I0622 22:09:24.637367 36972 solver.cpp:244]     Train net output #0: loss = 0.00479209 (* 1 = 0.00479209 loss)
I0622 22:09:24.637380 36972 sgd_solver.cpp:106] Iteration 45000, lr = 0.01
I0622 22:10:02.326206 36972 solver.cpp:228] Iteration 45200, loss = 0.00482594
I0622 22:10:02.326444 36972 solver.cpp:244]     Train net output #0: loss = 0.00482571 (* 1 = 0.00482571 loss)
I0622 22:10:02.326477 36972 sgd_solver.cpp:106] Iteration 45200, lr = 0.01
I0622 22:10:40.002398 36972 solver.cpp:228] Iteration 45400, loss = 0.00230053
I0622 22:10:40.002632 36972 solver.cpp:244]     Train net output #0: loss = 0.0023003 (* 1 = 0.0023003 loss)
I0622 22:10:40.002665 36972 sgd_solver.cpp:106] Iteration 45400, lr = 0.01
I0622 22:11:17.702288 36972 solver.cpp:228] Iteration 45600, loss = 0.00359095
I0622 22:11:17.702528 36972 solver.cpp:244]     Train net output #0: loss = 0.00359072 (* 1 = 0.00359072 loss)
I0622 22:11:17.702561 36972 sgd_solver.cpp:106] Iteration 45600, lr = 0.01
I0622 22:11:55.378847 36972 solver.cpp:228] Iteration 45800, loss = 0.00409577
I0622 22:11:55.379021 36972 solver.cpp:244]     Train net output #0: loss = 0.00409554 (* 1 = 0.00409554 loss)
I0622 22:11:55.379035 36972 sgd_solver.cpp:106] Iteration 45800, lr = 0.01
I0622 22:12:33.017948 36972 solver.cpp:337] Iteration 46000, Testing net (#0)
I0622 22:12:39.342352 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8497
I0622 22:12:39.342401 36972 solver.cpp:404]     Test net output #1: loss = 0.714369 (* 1 = 0.714369 loss)
I0622 22:12:39.409757 36972 solver.cpp:228] Iteration 46000, loss = 0.00370247
I0622 22:12:39.409783 36972 solver.cpp:244]     Train net output #0: loss = 0.00370224 (* 1 = 0.00370224 loss)
I0622 22:12:39.409795 36972 sgd_solver.cpp:106] Iteration 46000, lr = 0.01
I0622 22:13:17.052122 36972 solver.cpp:228] Iteration 46200, loss = 0.00346308
I0622 22:13:17.052438 36972 solver.cpp:244]     Train net output #0: loss = 0.00346284 (* 1 = 0.00346284 loss)
I0622 22:13:17.052498 36972 sgd_solver.cpp:106] Iteration 46200, lr = 0.01
I0622 22:13:54.685595 36972 solver.cpp:228] Iteration 46400, loss = 0.00204602
I0622 22:13:54.685859 36972 solver.cpp:244]     Train net output #0: loss = 0.00204579 (* 1 = 0.00204579 loss)
I0622 22:13:54.685891 36972 sgd_solver.cpp:106] Iteration 46400, lr = 0.01
I0622 22:14:32.342218 36972 solver.cpp:228] Iteration 46600, loss = 0.00286581
I0622 22:14:32.342514 36972 solver.cpp:244]     Train net output #0: loss = 0.00286558 (* 1 = 0.00286558 loss)
I0622 22:14:32.342530 36972 sgd_solver.cpp:106] Iteration 46600, lr = 0.01
I0622 22:15:10.016391 36972 solver.cpp:228] Iteration 46800, loss = 0.00337542
I0622 22:15:10.016597 36972 solver.cpp:244]     Train net output #0: loss = 0.00337519 (* 1 = 0.00337519 loss)
I0622 22:15:10.016613 36972 sgd_solver.cpp:106] Iteration 46800, lr = 0.01
I0622 22:15:47.632495 36972 solver.cpp:337] Iteration 47000, Testing net (#0)
I0622 22:15:53.948142 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8507
I0622 22:15:53.948189 36972 solver.cpp:404]     Test net output #1: loss = 0.721495 (* 1 = 0.721495 loss)
I0622 22:15:54.014821 36972 solver.cpp:228] Iteration 47000, loss = 0.00296861
I0622 22:15:54.014848 36972 solver.cpp:244]     Train net output #0: loss = 0.00296838 (* 1 = 0.00296838 loss)
I0622 22:15:54.014864 36972 sgd_solver.cpp:106] Iteration 47000, lr = 0.01
I0622 22:16:31.659485 36972 solver.cpp:228] Iteration 47200, loss = 0.00270701
I0622 22:16:31.659700 36972 solver.cpp:244]     Train net output #0: loss = 0.00270678 (* 1 = 0.00270678 loss)
I0622 22:16:31.659745 36972 sgd_solver.cpp:106] Iteration 47200, lr = 0.01
I0622 22:17:09.292600 36972 solver.cpp:228] Iteration 47400, loss = 0.00187419
I0622 22:17:09.292873 36972 solver.cpp:244]     Train net output #0: loss = 0.00187395 (* 1 = 0.00187395 loss)
I0622 22:17:09.292933 36972 sgd_solver.cpp:106] Iteration 47400, lr = 0.01
I0622 22:17:46.944805 36972 solver.cpp:228] Iteration 47600, loss = 0.00236225
I0622 22:17:46.945029 36972 solver.cpp:244]     Train net output #0: loss = 0.00236202 (* 1 = 0.00236202 loss)
I0622 22:17:46.945060 36972 sgd_solver.cpp:106] Iteration 47600, lr = 0.01
I0622 22:18:24.580535 36972 solver.cpp:228] Iteration 47800, loss = 0.00281641
I0622 22:18:24.580749 36972 solver.cpp:244]     Train net output #0: loss = 0.00281618 (* 1 = 0.00281618 loss)
I0622 22:18:24.580782 36972 sgd_solver.cpp:106] Iteration 47800, lr = 0.01
I0622 22:19:02.169013 36972 solver.cpp:454] Snapshotting to binary proto file snapshots/res_ide20_iter_48000.caffemodel
I0622 22:19:02.237135 36972 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/res_ide20_iter_48000.solverstate
I0622 22:19:02.268013 36972 solver.cpp:337] Iteration 48000, Testing net (#0)
I0622 22:19:08.598331 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8515
I0622 22:19:08.598376 36972 solver.cpp:404]     Test net output #1: loss = 0.727866 (* 1 = 0.727866 loss)
I0622 22:19:08.665359 36972 solver.cpp:228] Iteration 48000, loss = 0.0024778
I0622 22:19:08.665385 36972 solver.cpp:244]     Train net output #0: loss = 0.00247757 (* 1 = 0.00247757 loss)
I0622 22:19:08.665396 36972 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0622 22:19:08.665405 36972 sgd_solver.cpp:106] Iteration 48000, lr = 0.001
I0622 22:19:46.331308 36972 solver.cpp:228] Iteration 48200, loss = 0.00382942
I0622 22:19:46.331707 36972 solver.cpp:244]     Train net output #0: loss = 0.00382918 (* 1 = 0.00382918 loss)
I0622 22:19:46.331758 36972 sgd_solver.cpp:106] Iteration 48200, lr = 0.001
I0622 22:20:23.999842 36972 solver.cpp:228] Iteration 48400, loss = 0.0020095
I0622 22:20:24.000061 36972 solver.cpp:244]     Train net output #0: loss = 0.00200926 (* 1 = 0.00200926 loss)
I0622 22:20:24.000092 36972 sgd_solver.cpp:106] Iteration 48400, lr = 0.001
I0622 22:21:01.691128 36972 solver.cpp:228] Iteration 48600, loss = 0.00225682
I0622 22:21:01.691346 36972 solver.cpp:244]     Train net output #0: loss = 0.00225659 (* 1 = 0.00225659 loss)
I0622 22:21:01.691397 36972 sgd_solver.cpp:106] Iteration 48600, lr = 0.001
I0622 22:21:39.393450 36972 solver.cpp:228] Iteration 48800, loss = 0.00345225
I0622 22:21:39.393685 36972 solver.cpp:244]     Train net output #0: loss = 0.00345202 (* 1 = 0.00345202 loss)
I0622 22:21:39.393702 36972 sgd_solver.cpp:106] Iteration 48800, lr = 0.001
I0622 22:22:17.043802 36972 solver.cpp:337] Iteration 49000, Testing net (#0)
I0622 22:22:23.374259 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8521
I0622 22:22:23.374315 36972 solver.cpp:404]     Test net output #1: loss = 0.719403 (* 1 = 0.719403 loss)
I0622 22:22:23.441500 36972 solver.cpp:228] Iteration 49000, loss = 0.00253591
I0622 22:22:23.441535 36972 solver.cpp:244]     Train net output #0: loss = 0.00253568 (* 1 = 0.00253568 loss)
I0622 22:22:23.441556 36972 sgd_solver.cpp:106] Iteration 49000, lr = 0.001
I0622 22:23:01.129686 36972 solver.cpp:228] Iteration 49200, loss = 0.00314035
I0622 22:23:01.129938 36972 solver.cpp:244]     Train net output #0: loss = 0.00314012 (* 1 = 0.00314012 loss)
I0622 22:23:01.129962 36972 sgd_solver.cpp:106] Iteration 49200, lr = 0.001
I0622 22:23:38.815042 36972 solver.cpp:228] Iteration 49400, loss = 0.00203237
I0622 22:23:38.815234 36972 solver.cpp:244]     Train net output #0: loss = 0.00203214 (* 1 = 0.00203214 loss)
I0622 22:23:38.815250 36972 sgd_solver.cpp:106] Iteration 49400, lr = 0.001
I0622 22:24:16.516458 36972 solver.cpp:228] Iteration 49600, loss = 0.002132
I0622 22:24:16.516741 36972 solver.cpp:244]     Train net output #0: loss = 0.00213176 (* 1 = 0.00213176 loss)
I0622 22:24:16.516777 36972 sgd_solver.cpp:106] Iteration 49600, lr = 0.001
I0622 22:24:54.216665 36972 solver.cpp:228] Iteration 49800, loss = 0.00331538
I0622 22:24:54.216953 36972 solver.cpp:244]     Train net output #0: loss = 0.00331514 (* 1 = 0.00331514 loss)
I0622 22:24:54.216998 36972 sgd_solver.cpp:106] Iteration 49800, lr = 0.001
I0622 22:25:31.884825 36972 solver.cpp:337] Iteration 50000, Testing net (#0)
I0622 22:25:38.199887 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8521
I0622 22:25:38.199936 36972 solver.cpp:404]     Test net output #1: loss = 0.720032 (* 1 = 0.720032 loss)
I0622 22:25:38.266513 36972 solver.cpp:228] Iteration 50000, loss = 0.00248032
I0622 22:25:38.266541 36972 solver.cpp:244]     Train net output #0: loss = 0.00248009 (* 1 = 0.00248009 loss)
I0622 22:25:38.266553 36972 sgd_solver.cpp:106] Iteration 50000, lr = 0.001
I0622 22:26:15.926336 36972 solver.cpp:228] Iteration 50200, loss = 0.00297255
I0622 22:26:15.926607 36972 solver.cpp:244]     Train net output #0: loss = 0.00297231 (* 1 = 0.00297231 loss)
I0622 22:26:15.926657 36972 sgd_solver.cpp:106] Iteration 50200, lr = 0.001
I0622 22:26:53.567849 36972 solver.cpp:228] Iteration 50400, loss = 0.00201994
I0622 22:26:53.568040 36972 solver.cpp:244]     Train net output #0: loss = 0.00201971 (* 1 = 0.00201971 loss)
I0622 22:26:53.568056 36972 sgd_solver.cpp:106] Iteration 50400, lr = 0.001
I0622 22:27:31.242477 36972 solver.cpp:228] Iteration 50600, loss = 0.002062
I0622 22:27:31.242681 36972 solver.cpp:244]     Train net output #0: loss = 0.00206177 (* 1 = 0.00206177 loss)
I0622 22:27:31.242708 36972 sgd_solver.cpp:106] Iteration 50600, lr = 0.001
I0622 22:28:08.892581 36972 solver.cpp:228] Iteration 50800, loss = 0.0031954
I0622 22:28:08.892838 36972 solver.cpp:244]     Train net output #0: loss = 0.00319517 (* 1 = 0.00319517 loss)
I0622 22:28:08.892869 36972 sgd_solver.cpp:106] Iteration 50800, lr = 0.001
I0622 22:28:46.518656 36972 solver.cpp:337] Iteration 51000, Testing net (#0)
I0622 22:28:52.834434 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8522
I0622 22:28:52.834481 36972 solver.cpp:404]     Test net output #1: loss = 0.720652 (* 1 = 0.720652 loss)
I0622 22:28:52.900923 36972 solver.cpp:228] Iteration 51000, loss = 0.00241218
I0622 22:28:52.900949 36972 solver.cpp:244]     Train net output #0: loss = 0.00241194 (* 1 = 0.00241194 loss)
I0622 22:28:52.900962 36972 sgd_solver.cpp:106] Iteration 51000, lr = 0.001
I0622 22:29:30.619770 36972 solver.cpp:228] Iteration 51200, loss = 0.00284815
I0622 22:29:30.620168 36972 solver.cpp:244]     Train net output #0: loss = 0.00284792 (* 1 = 0.00284792 loss)
I0622 22:29:30.620229 36972 sgd_solver.cpp:106] Iteration 51200, lr = 0.001
I0622 22:30:08.299664 36972 solver.cpp:228] Iteration 51400, loss = 0.00197759
I0622 22:30:08.299968 36972 solver.cpp:244]     Train net output #0: loss = 0.00197735 (* 1 = 0.00197735 loss)
I0622 22:30:08.300027 36972 sgd_solver.cpp:106] Iteration 51400, lr = 0.001
I0622 22:30:46.026753 36972 solver.cpp:228] Iteration 51600, loss = 0.00200652
I0622 22:30:46.026919 36972 solver.cpp:244]     Train net output #0: loss = 0.00200629 (* 1 = 0.00200629 loss)
I0622 22:30:46.026933 36972 sgd_solver.cpp:106] Iteration 51600, lr = 0.001
I0622 22:31:23.740995 36972 solver.cpp:228] Iteration 51800, loss = 0.00308546
I0622 22:31:23.741195 36972 solver.cpp:244]     Train net output #0: loss = 0.00308522 (* 1 = 0.00308522 loss)
I0622 22:31:23.741210 36972 sgd_solver.cpp:106] Iteration 51800, lr = 0.001
I0622 22:32:01.375605 36972 solver.cpp:337] Iteration 52000, Testing net (#0)
I0622 22:32:07.690279 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8523
I0622 22:32:07.690325 36972 solver.cpp:404]     Test net output #1: loss = 0.72126 (* 1 = 0.72126 loss)
I0622 22:32:07.756448 36972 solver.cpp:228] Iteration 52000, loss = 0.00235742
I0622 22:32:07.756474 36972 solver.cpp:244]     Train net output #0: loss = 0.00235718 (* 1 = 0.00235718 loss)
I0622 22:32:07.756487 36972 sgd_solver.cpp:106] Iteration 52000, lr = 0.001
I0622 22:32:45.403384 36972 solver.cpp:228] Iteration 52200, loss = 0.00275239
I0622 22:32:45.403605 36972 solver.cpp:244]     Train net output #0: loss = 0.00275215 (* 1 = 0.00275215 loss)
I0622 22:32:45.403664 36972 sgd_solver.cpp:106] Iteration 52200, lr = 0.001
I0622 22:33:23.067271 36972 solver.cpp:228] Iteration 52400, loss = 0.00192957
I0622 22:33:23.067456 36972 solver.cpp:244]     Train net output #0: loss = 0.00192933 (* 1 = 0.00192933 loss)
I0622 22:33:23.067471 36972 sgd_solver.cpp:106] Iteration 52400, lr = 0.001
I0622 22:34:00.716022 36972 solver.cpp:228] Iteration 52600, loss = 0.00196063
I0622 22:34:00.716358 36972 solver.cpp:244]     Train net output #0: loss = 0.00196039 (* 1 = 0.00196039 loss)
I0622 22:34:00.716418 36972 sgd_solver.cpp:106] Iteration 52600, lr = 0.001
I0622 22:34:38.362658 36972 solver.cpp:228] Iteration 52800, loss = 0.00299334
I0622 22:34:38.362884 36972 solver.cpp:244]     Train net output #0: loss = 0.0029931 (* 1 = 0.0029931 loss)
I0622 22:34:38.362898 36972 sgd_solver.cpp:106] Iteration 52800, lr = 0.001
I0622 22:35:15.970562 36972 solver.cpp:337] Iteration 53000, Testing net (#0)
I0622 22:35:22.286860 36972 solver.cpp:404]     Test net output #0: accuracy = 0.8526
I0622 22:35:22.286906 36972 solver.cpp:404]     Test net output #1: loss = 0.721848 (* 1 = 0.721848 loss)
I0622 22:35:22.353698 36972 solver.cpp:228] Iteration 53000, loss = 0.00231291
I0622 22:35:22.353726 36972 solver.cpp:244]     Train net output #0: loss = 0.00231267 (* 1 = 0.00231267 loss)
I0622 22:35:22.353739 36972 sgd_solver.cpp:106] Iteration 53000, lr = 0.001
I0622 22:36:00.000924 36972 solver.cpp:228] Iteration 53200, loss = 0.00266801
I0622 22:36:00.001260 36972 solver.cpp:244]     Train net output #0: loss = 0.00266777 (* 1 = 0.00266777 loss)
I0622 22:36:00.001333 36972 sgd_solver.cpp:106] Iteration 53200, lr = 0.001
I0622 22:36:37.633317 36972 solver.cpp:228] Iteration 53400, loss = 0.00188442
I0622 22:36:37.633575 36972 solver.cpp:244]     Train net output #0: loss = 0.00188419 (* 1 = 0.00188419 loss)
I0622 22:36:37.633607 36972 sgd_solver.cpp:106] Iteration 53400, lr = 0.001
I0622 22:37:15.252398 36972 solver.cpp:228] Iteration 53600, loss = 0.00191881
I0622 22:37:15.252574 36972 solver.cpp:244]     Train net output #0: loss = 0.00191858 (* 1 = 0.00191858 loss)
I0622 22:37:15.252590 36972 sgd_solver.cpp:106] Iteration 53600, lr = 0.001
I0622 22:37:52.881147 36972 solver.cpp:228] Iteration 53800, loss = 0.00290728
I0622 22:37:52.881381 36972 solver.cpp:244]     Train net output #0: loss = 0.00290704 (* 1 = 0.00290704 loss)
I0622 22:37:52.881398 36972 sgd_solver.cpp:106] Iteration 53800, lr = 0.001
